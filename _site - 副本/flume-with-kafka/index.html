<!DOCTYPE html>
<html xmlns:wb="http://open.weibo.com/wb">
<head>
    <!--   Author: NingG   -->
    <meta charset="utf-8" />
	<meta property="wb:webmaster" content="7ea7f3d5f3edad6a" />
    <title>Flume 1.5.0.1：如何将flume聚合的数据送入Kafka | ningg.top</title>
    <meta name="author" content="NingG" />
    <meta name="renderer" content="webkit">
    <meta name="description" content=" Flume负责数据聚合，Kafka作为消息队列，需要接收Flume发来的消息  " />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">

    <link rel="stylesheet" href="/css/default.css" type="text/css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="" />
	
    <script src="/js/jquery-1.7.1.min.js" type="text/javascript"></script>
	<script src="http://tjs.sjs.sinajs.cn/open/api/js/wb.js" type="text/javascript" charset="utf-8"></script>
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
	
    <div class="home-menu">
        <div class="home-icon-con">
            <a class="home-menu-icon" href="/">NingG</a>
            <a class="home-follow" href="#" title="Contact Me">+</a>
        </div>
        <div class="home-contact">
            <a href="http://weibo.com/ggningg/" target="_blank" style="margin-left:-5px;"><img src="http://www.weibo.com/favicon.ico" alt="" width="25"/></a>
            <a href="http://www.douban.com/people/ggningg/" target="_blank" style="text-align:center;"><img src="http://www.douban.com/favicon.ico" alt="" width="22"/></a>
			<a href="http://github.com/ningg" alt="" target="_blank" style="text-align:right;"><img src="/images/icon-cube-smaller.png" width="22"/></a>
        </div>
    </div>

    <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
    body { background:#e8e8e8; }
    @media screen and (max-width: 750px){
        body { background:#fff; }
    }
    @media screen and (max-width: 1020px){
        body { background:#fff; }
    }
</style>

<div id="content">
    <div class="entry">
        <h1 class="entry-title"><a href="/flume-with-kafka" title="Flume 1.5.0.1：如何将flume聚合的数据送入Kafka">Flume 1.5.0.1：如何将flume聚合的数据送入Kafka</a></h1>
        <p class="entry-date">2014-10-24</p>
        <h2 id="section">背景</h2>

<p>Flume收集分布在不同机器上的日志信息，聚合之后，将信息送入Kafka消息队列，问题来了：如何将Flume输出的信息送入Kafka中？</p>

<p>定一个场景：flume读取apache的访问日志，然后送入Kafka中，最终消息从Kafka中取出，显示在终端屏幕上（stdout）。</p>

<h2 id="flume">Flume复习</h2>

<p>整理一下Flume的基本知识，参考来源有两个：</p>

<ul>
  <li><a href="http://flume.apache.org/documentation.html">Flume Documentation</a></li>
  <li>Book: <a href="http://files.hii-tech.com/Book/Hadoop/PacktPub.Apache.Flume.Distributed.Log.Collection.for.Hadoop.Jul.2013.pdf">apache-flume-distributed-log-collection-hadoop</a></li>
</ul>

<h3 id="section-1">几个概念</h3>

<ul>
  <li>Flume <strong>event</strong>: a unit of data flow, having a byte payload and an optional set of string attributes.（event中包含了，payload和attributes）</li>
  <li>Flume <strong>agent</strong>: a (JVM) process, that hosts the components through which events flow from an external source to the next destination(hop).（agent对应JVM process）</li>
  <li><strong>Channel</strong>:  passive store, keeps the event until it’s consumded by a Flume Sink.（Channel不会主动消费event，其等待Sink来取数据，会在本地备份Event）</li>
  <li><strong>Sink</strong>: remove the event from the channel and put it into external repository.（Sink主动从Channel中取出event）</li>
</ul>

<p><img src="/images/flume-user-guide/UserGuide_image00.png" alt="" /> </p>

<h3 id="section-2">练习</h3>

<p><strong>场景</strong>：Flume收集apache访问日志，然后，在标准终端（stdout）显示。</p>

<p><strong>分析</strong>：Flume官方文档中，已经给出了一个demo，flume从<code>localhost:port</code>收集数据，并在标准终端上显示。基于这一场景，只需要修改Source即可。</p>

<h4 id="section-3">构造实例</h4>

<p>通过参阅Flume官网，得知<code>ExecSource</code>可用于捕获命令的输出，并将输出结果按行构造event，<code>tail -F [local file]</code>命令用于查阅文件<code>[local file]</code>的新增内容；在<code>$FLUME_HOME/conf</code>目录下，新建文件<code>apache_log_scan.log</code>，内容如下：</p>

<pre><code>a1.sources = r1
a1.sinks = k1
a1.channels = c1

a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /var/log/httpd/access_log

a1.sinks.k1.type = logger

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
</code></pre>

<p>启动Flume agent，命令如下：</p>

<pre><code>[ningg@localhost flume]$ cd conf
[ningg@localhost  conf]$ sudo ../bin/flume-ng agent --conf ../conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console
...
...
 Component type: SOURCE, name: r1 started
</code></pre>

<p>然后访问一下Apache承载的网站，可以看到上面的窗口也在输出信息，即，已经在捕获Apache访问日志<code>access_log</code>的增量了。（可以另起一个窗口，通过<code>tail -F access_log</code>查看日志的实际内容）</p>

<h4 id="section-4">存在的问题</h4>

<p>通过比较Flume上sink的输出、<code>tail -F access_log</code>命令的输出，发现输出有差异：</p>

<pre><code># Flume上logger类型sink的输出
Event: { headers:{} body: 31 36 38 2E 35 2E 31 33 30 2E 31 37 35 20 2D 20 168.5.130.175 -  }

# access_log原始文件上的新增内容（长度超过上面logger sink的输出）
168.5.130.175 - - [23/Oct/2014:16:34:59 +0800] "GET /..."
</code></pre>

<p>思考：</p>

<ol>
  <li>logger类型的sink，遇到<code>[</code>字符就结束？</li>
  <li>logger类型的sink，有字符长度的限制吗？</li>
  <li>channel有长度限制？channel中存储的event是什么形式存储的？</li>
</ol>

<p>通过<code>vim access_log</code>，向文件最后添加一行内容，发现应该是logger类型的sink，对于event的长度有限制；或者，memory类型的channel对于存储的event有限制。
<strong>RE</strong>：上述问题已经解决，Logger sink输出内容不完整，详情可参考<a href="/flume-advance-logger-sink">Advanced Logger Sink</a>。</p>

<h2 id="kafka">Kafka复习</h2>

<p>下面Kafka的相关总结都参考自：</p>

<ul>
  <li><a href="http://kafka.apache.org/documentation.html">Kafka 0.8.1 Documentation</a></li>
</ul>

<h3 id="section-5">几个概念</h3>

<p><img src="/images/kafka-documentation/producer_consumer.png" alt="" /></p>

<ul>
  <li><strong>消息队列</strong>：Kafka充当消息队列，producer将message放入Kafka集群，consumer从Kafka集群中读取message；</li>
  <li><strong>内部结构</strong>：按照topic来存放message，每个topic对应一个partitioned log，其中包含多个partition，每个都是一个有序的、message队列；</li>
  <li><strong>消息存活时间</strong>：在设定的时间内，kafka始终保存所有的message，即使message已经被consume；</li>
  <li><strong>consume message</strong>：每个consumer，只需保存在log中的offset，并且这个offset完全由consumer控制，可自由调整；鉴于此，cousumer之间相互基本没有影响；</li>
</ul>

<p><img src="/images/kafka-documentation/log_anatomy.png" alt="" /></p>

<p>针对上面每个topic对应的partitioned log，其中包含了多个partition，这样设计有什么好处？</p>

<ul>
  <li>single server上，单个log的大小由文件系统限制，而采用多partition模式，虽然单个partition也受限，但partition的个数不受限制；</li>
  <li>多个partition时，每个partition都可作为一个unit，以此来支撑并发处理；</li>
  <li>partition是分布式存储的，即，某个server上的partition可能也存在其他的server上，两点好处：
    <ul>
      <li>方便不同server之间的partition共享；</li>
      <li>配置每个partition的复制份数，提升系统可靠性；</li>
    </ul>
  </li>
  <li>partition对应的server，分为两个角色：<code>leader</code>和<code>follower</code>：
    <ul>
      <li>每个partition都对应一个server担当<code>leader</code>角色：负责所有的read、write；</li>
      <li>其他server担<code>follower</code>角色：重复<code>leader</code>的操作；</li>
      <li>如果<code>leader</code>崩溃，则自动推选一个<code>follower</code>升级为<code>leader</code>；</li>
      <li>server只对其上的部分partition担当<code>leader</code>角色，方便cluster的均衡；</li>
    </ul>
  </li>
</ul>

<p>Producer产生的数据放到topic的哪个partition下？集中方式：</p>

<ul>
  <li>轮询：保证每个partition以均等的机会存储message，均衡负载；</li>
  <li>函数：根据key in the message来确定partition；</li>
</ul>

<p>Consumer读取message有两种模式：</p>

<ul>
  <li>queueing：多个consumer构成一个pool，然后，每个message只被其中一个consumer处理；</li>
  <li>publish-subscribe：向所有的consumer广播message；</li>
</ul>

<p>Kafka中通过将consumer泛化为consumer group来实现，来支持上述两种模式，关于此，详细说一下：</p>

<ul>
  <li>consumer都标记有consumer group name，每个message都发送给对应consumer group中的一个consumer instance，consumer instance可以是不同的进程，也可以分布在不同的物理机器上；</li>
  <li>若所有的consumer instances都属于同一个consume group，则为queuing轮询的均衡负载；</li>
  <li>若所有的consumer instances都属于不同的consume group，则为publish-subscribe，message广播到所有的consumer；</li>
  <li>实际场景下，topic对应为数不多的几个consumer group，即，consumer group类似<code>logical subscriber</code>；每个group中有多个consumer，目的是提升可扩展性和容错能力。</li>
</ul>

<p><img src="/images/kafka-documentation/consumer-groups.png" alt="" /></p>

<p><strong>notes(ningg)</strong>：几个问题：</p>

<ul>
  <li>consumer group是与topic对应的？还是partition对应？</li>
  <li>consumer group方式能够提升可扩展性和容错能力？</li>
</ul>

<p>Ordering guarantee，Kafka保证message按序处理，同时也保证并行处理，几点：</p>

<ul>
  <li>单个partition中的message保证按序处理，同时一个partition只能对应一个consumer instance；</li>
  <li>不同partition之间，不保证顺序处理，多个partition实现了并行处理；</li>
</ul>

<p><strong>notes(ningg)</strong>：同一个partition中的message，当其中一个message A被指派给一个consumer instance后，在message A被处理完之前，message B是否会被指派出去？<strong>RE</strong>：细节还没看，具当前的理解，应该是串行处理的，即，一个处理完后，才会发送另一个。</p>

<h3 id="section-6">小结</h3>

<p>Kafka通过 partition data by key 和 pre-partition ordering，满足了大部分需求。如果要保证所有message都顺序处理，则将topic设置为only one partition，此时，变为串行处理。</p>

<p><strong>notes(ningg)</strong>：单个partition是以什么形式存储在server上的？纯粹的文档文件？Flume的fan-in、fan-out什么含义？fan-in针对的是agent之间，fan-out针对agent内部source–channel之间？</p>

<h2 id="flumekafka-sink">Flume的Kafka sink</h2>

<p>Flume中数据送入Kafka，本质上就是一个Kafka sink。很多人都有这个需求，甚至有的还需要将Flume来读取Kafka中的数据（Kafka source）。本次使用的Flume和Kafka的详细版本信息如下：</p>

<ul>
  <li>Flume：apache-flume-1.5.0.1-bin.tar.gz</li>
  <li>Kafka：kafka_2.9.2-0.8.1.1.tgz</li>
</ul>

<h3 id="section-7">前人的工作</h3>

<p>Flume中Kafka source和Kafka sink都有人在做，整体来说有几个进展：</p>

<ul>
  <li>唯品会的工程师Frank Yao，提供了一个<a href="https://github.com/baniuyao/flume-kafka">针对Kafka 0.7.2的实现版本</a>；</li>
  <li>Github上用户thilinamb提供了一个<a href="https://github.com/thilinamb/flume-ng-kafka-sink">Kafka 0.8.1.1的实现版本</a></li>
  <li>Flume官网提到，将<a href="https://issues.apache.org/jira/browse/FLUME-2242">在Flume 1.6版本中提供对Kafka的支持</a>； </li>
</ul>

<p>现在，怎么做？打算学习thilinamb的版本，并且用起来，必要时，形成自己的版本。</p>

<p><strong>notes(ningg)</strong>：Flume官网虽然还没有发布 1.6 版本，但作为开源软件，能够提前查看针对Kafka source和sink部分的代码吗？JIRA上能不能看？</p>

<h3 id="section-8">具体实现</h3>

<p>直接参考thilinamb的<a href="https://github.com/thilinamb/flume-ng-kafka-sink">Kafka 0.8.1.1的实现版本</a>中的README。 说明：thilinamb的工程是用Maven进行管理的，可以作为<code>Existing Maven Project</code>直接导入，然后<code>mvn clean instal</code>即可。</p>

<p><img src="/images/flume-with-kafka/kafka-sink-src.png" alt="" /></p>

<p><strong>notes(ningg)</strong>：thilinamb的<a href="https://github.com/thilinamb/flume-ng-kafka-sink">工程</a>，使用maven进行管理，结构好像挺合理的，有一个parent的project，需要认真学习一下。</p>

<h3 id="flume-kafka-sink">Flume Kafka sink原理</h3>

<p>在上一部分，虽然实现了Flume中数据送入Kafka，但具体原理是什么？需要深入学习一下。</p>

<p>（TODO）</p>

<h2 id="section-9">参考来源</h2>

<ul>
  <li><a href="http://flume.apache.org/documentation.html">Flume Documentation</a></li>
  <li>Book: <a href="http://files.hii-tech.com/Book/Hadoop/PacktPub.Apache.Flume.Distributed.Log.Collection.for.Hadoop.Jul.2013.pdf">apache-flume-distributed-log-collection-hadoop</a></li>
</ul>



        <div id="disqus_container">
            <div style="margin-bottom:20px" class="right">
				<wb:share-button appkey="2306590132" addition="simple" type="button" ralateUid="2356527183"></wb:share-button>
            </div>
            <!--<a href="#" class="comment" onclick="return false;">点击查看评论</a>-->
            <div id="disqus_thread"></div>
        </div>
    </div>

	
    <div class="sidenav">
		<iframe width="100%" height="75" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=2&ptype=1&speed=0&skin=1&isTitle=0&noborder=0&isWeibo=0&isFans=0&uid=2356527183&verifier=1ccfb61e&colors=d6f3f7,ffffff,666666,0082cb,ecfbfd&dpc=1"></iframe>
    </div>

</div>

<script src="/js/post.js" type="text/javascript"></script>


	<div id="gotoTop">Top</div>


    <!--*********************************************************-->
    <!--****** 宝贝儿，看见这个时候，删掉下面的统计代码哦~ ******-->
    <!--*********************************************************-->
	<script>
	  (function(i,s,o,g,r,a,m){
		  i['GoogleAnalyticsObject']=r;i[r]=i[r] || function(){
			(i[r].q=i[r].q||[]).push(arguments)}, i[r].l=1*new Date();
			a=s.createElement(o), m=s.getElementsByTagName(o)[0];
			a.async=1;
			a.src=g;
			m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-48535193-1', 'ningg.github.io');
	  ga('send', 'pageview');
	</script>
    
	
    <script type="text/javascript">
		function gotoTop(min_height){
			$("#gotoTop").click(
				function(){$('html,body').animate({scrollTop:0},700);
			}).hover(
				function(){$(this).addClass("hover");},
				function(){$(this).removeClass("hover");
			});
			min_height ? min_height = min_height : min_height = 600;
			$(window).scroll(function(){
				
				var s = $(window).scrollTop();
				
				if( s > min_height){
					$("#gotoTop").fadeIn(100);
				}else{
					$("#gotoTop").fadeOut(200);
				};
			});
		};
		gotoTop();

        $(function(){
            $('.home-follow').click(function(e){
                e.preventDefault();

                if($('.home-contact').is(':visible')){
                    $('.home-contact').slideUp(100);
                }else{
                    $('.home-contact').slideDown(100);
                }
            });
        })

    </script>
</body>
</html>
