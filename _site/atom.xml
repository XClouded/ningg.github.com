<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
   <title>NingG.github.com</title>
   <link href="http://ningg.github.com/atom.xml" rel="self" type="application/atom+xml"/>
   <link href="http://ningg.github.com" rel="alternate" type="text/html" />
   <updated>2014-10-30T23:49:27+08:00</updated>
   <id>http://ningg.github.com</id>
   <author>
     <name></name>
     <email></email>
   </author>

   
   <entry>
     <title>CentOS 6.4下LVM的使用</title>
     <link href="http://ningg.github.com/use-lvm"/>
     <updated>2014-10-29T00:00:00+08:00</updated>
     <id>http://ningg.github.com/use-lvm</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;系统有9块盘，每个320GB，之前服务器（CentOS 6.3）上磁盘分配情况：选取一块盘作为系统盘，划分&lt;code&gt;/boot&lt;/code&gt;、&lt;code&gt;swap&lt;/code&gt;、&lt;code&gt;/&lt;/code&gt;、&lt;code&gt;/home&lt;/code&gt;；然后，将剩余的8块盘，逐个格式化，并mount到系统盘的某个目录下。现在的问题是：某系统要上线，需要一个足够大的空间来存储数据，如果使用上述的方案，每个目录最大的存储空间都只有320GB，还是不够大，今后可能面临分区扩容的问题，使用静态分区，扩容有些麻烦。而LVM（Logical Volume Management，逻辑卷管理）能够将多个磁盘/分区组合在一起，抽象为一个逻辑上的分区，即，利用LVM技术，8块盘可以组成一个2.5T大小的分区，这样问题就解决了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：上面利用LVM来管理8块盘的方案，只是初步想法，不是最终方案。&lt;/p&gt;

&lt;h2 id=&quot;lvm&quot;&gt;LVM是什么&lt;/h2&gt;

&lt;p&gt;LVM(Logical Volume Management，逻辑卷管理)，一大核心功能是：对磁盘分区进行动态管理。当前无论在Linux、类Unix以及其他Windowns操作系统上，都存在LVM管理软件。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/use-lvm/lvm-arch.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;lvm-1&quot;&gt;LVM要解决的问题&lt;/h3&gt;

&lt;p&gt;LVM要解决的典型问题：一块磁盘的空间160GB，其存满数据后，需要扩容，怎么办？传统静态分区时，需要将磁盘中近160GB的数据复制到1TB的磁盘上，然后，使用1TB的磁盘替换掉原来160GB的磁盘即可（替换：只要是挂载点替换一下就可以了）。LVM有更好的思路，来解决这个问题吗？&lt;/p&gt;

&lt;h3 id=&quot;lvm-2&quot;&gt;LVM原理简介&lt;/h3&gt;

&lt;p&gt;要解决上面磁盘空间不足时，磁盘的扩容问题，LVM提供了一个基本思路：LVM将底层的磁盘封装抽象为逻辑卷（logical volume），上层应用不直接从物理磁盘分区中读数据，而是从逻辑卷中读数据；LVM负责底层磁盘到逻辑卷的映射和管理；增加底层磁盘时，通过LVM可以为逻辑卷动态扩充容量，而这对上层应用是无影响的（透明的）。说这么多，总结一点：LVM提高了磁盘管理的灵活性。&lt;/p&gt;

&lt;h2 id=&quot;lvm-3&quot;&gt;LVM原理详解&lt;/h2&gt;

&lt;p&gt;上面简要说了一点点LVM的基本原理，吃饭要吃饱、做事要做好，OK，把LVM的原理好好理解一下。有几个概念要好好说一说。&lt;/p&gt;

&lt;h3 id=&quot;pv-physical-volume&quot;&gt;PV: Physical Volume&lt;/h3&gt;

&lt;p&gt;PV（Physical Volume），物理卷&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;物理卷在LVM系统中处于最底层。&lt;/li&gt;
  &lt;li&gt;物理卷可以是整个硬盘、硬盘上的分区或从逻辑上与磁盘分区具有同样功能的设备（如：RAID）。&lt;/li&gt;
  &lt;li&gt;物理卷是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，却包含有与LVM相关的管理参数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：为什么要有PV？直接使用物理分区不行吗？&lt;/p&gt;

&lt;h3 id=&quot;vg-volume-group&quot;&gt;VG: Volume Group&lt;/h3&gt;

&lt;p&gt;VG（Volume Group），卷组&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;卷组建立在物理卷之上，它由一个或多个物理卷组成。&lt;/li&gt;
  &lt;li&gt;卷组创建之后，可以动态地添加物理卷到卷组中，在卷组上可以创建一个或多个“LVM分区”（逻辑卷）。&lt;/li&gt;
  &lt;li&gt;一个LVM系统中可以只有一个卷组，也可以包含多个卷组。&lt;/li&gt;
  &lt;li&gt;LVM的卷组类似于非LVM系统中的物理硬盘。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lg-logical-volume&quot;&gt;LG: Logical Volume&lt;/h3&gt;

&lt;p&gt;LG（Logical Volume），逻辑卷&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;逻辑卷建立在卷组之上，它是从卷组中“切出”的一块空间。&lt;/li&gt;
  &lt;li&gt;逻辑卷创建之后，其大小可以伸缩。&lt;/li&gt;
  &lt;li&gt;LVM的逻辑卷类似于非LVM系统中的硬盘分区，在逻辑卷之上可以建立文件系统（比如，/home或者/usr等）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pe-physical-extent&quot;&gt;PE: Physical Extent&lt;/h3&gt;

&lt;p&gt;PE（Physical Extent），物理区域，&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;每一个物理卷被划分为基本单元（称为PE），具有唯一编号的PE是可以被LVM寻址的最小存储单元。&lt;/li&gt;
  &lt;li&gt;PE的大小可根据实际情况在创建物理卷时指定，默认为4 MB。&lt;/li&gt;
  &lt;li&gt;PE的大小一旦确定将不能改变，同一个卷组中的所有物理卷的PE的大小需要一致。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;le-logical-extent&quot;&gt;LE: Logical Extent&lt;/h3&gt;

&lt;p&gt;LE（Logical Extent），逻辑区域&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;逻辑区域也被划分为可被寻址的基本单位（称为LE）。&lt;/li&gt;
  &lt;li&gt;在同一个卷组中，LE的大小和PE是相同的，并且一一对应。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：PE、LE，是否与文件系统中block（逻辑块）类似？而block大，能够提升磁盘IO速度；但block过大，造成磁盘空间的浪费？&lt;/p&gt;

&lt;h3 id=&quot;vgda&quot;&gt;VGDA&lt;/h3&gt;

&lt;p&gt;和非LVM系统将包含分区信息的元数据保存在位于分区的起始位置的分区表中一样，逻辑卷以及卷组相关的元数据也是保存在位于物理卷起始处的卷组描述符区域（Volume Group Descriptor Area, VGDA）中。VGDA包括以下内容：PV描述符、VG描述符、LV描述符、和一些PE描述符。&lt;/p&gt;

&lt;p&gt;注意：/boot分区不能位于卷组中，因为引导装载程序无法从逻辑卷中读取。如果你想把/分区放在逻辑卷上，必须创建一个与卷组分离的/boot分区。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;小结&lt;/h3&gt;

&lt;p&gt;我们在创建好LV以后，我们会在 /dev 目录下看到我们的LV信息，例如 /dev/vgname/lvname， 我们每创建一个VG，其会在/dev目录下创建一个以该VG名字命名的文件夹，在该VG的基础上创建好LV以后，我们会在这个VG目录下多出一个以LV名字命名的逻辑卷。&lt;/p&gt;

&lt;p&gt;下面我们来对整个LVM的工作原理进行一个总结：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;物理磁盘/物理分区，被格式化为PV，本质：空间被划分为一个个的PE&lt;/li&gt;
  &lt;li&gt;不同的PV加入到同一个VG中，不同PV的PE全部进入到了VG的PE池内&lt;/li&gt;
  &lt;li&gt;LV基于PE创建，大小为PE的整数倍，组成LV的PE可能来自不同的物理磁盘&lt;/li&gt;
  &lt;li&gt;LV现在就直接可以格式化后挂载使用了&lt;/li&gt;
  &lt;li&gt;LV的扩充缩减实际上就是增加或减少组成该LV的PE数量，其过程不会丢失原始数据&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：在创建PV时，需要物理磁盘/物理分区提前进行格式化吗？&lt;strong&gt;RE&lt;/strong&gt;：不需要格式化的，直接创建PV就行。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/use-lvm/pv-vg-lv.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;centosdoing&quot;&gt;CentOS的推荐配置doing..&lt;/h2&gt;

&lt;p&gt;使用LVM来管理磁盘时，CentOS有没有推荐的配置？&lt;/p&gt;

&lt;p&gt;LVM只有优点吗？
LVM有没有副作用？降低磁盘IO？耗费一定的磁盘空间？LVM管理时，有没有CPU、磁盘资源的浪费？&lt;/p&gt;

&lt;p&gt;（下面还没有修改，参考来源：&lt;a href=&quot;http://hily.me/blog/2008/10/understanding-lvm/&quot;&gt;理解 LVM (Logical Volume Manager)&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;是否使用 LVM？&lt;/p&gt;

&lt;p&gt;在决定是否使用 LVM 前请先了解下 LVM 的优缺点。&lt;/p&gt;

&lt;p&gt;使用 LVM 的优势：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;文件系统可以跨多个磁盘，因此大小不会受物理磁盘的限制。&lt;/li&gt;
  &lt;li&gt;可以在系统运行状态下动态地扩展文件系统大小。&lt;/li&gt;
  &lt;li&gt;可以增加新磁盘到 LVM 的存储池中。&lt;/li&gt;
  &lt;li&gt;可以以镜像的方式冗余重要数据到多个物理磁盘上。&lt;/li&gt;
  &lt;li&gt;可以很方便地导出整个卷组，并导入到另外一台机器上。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用 LVM 的限制：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;系统、文件系统出现问题时，LVM处理起来麻烦，关键要看处理者的能力&lt;/li&gt;
  &lt;li&gt;在从卷组中移除一个磁盘时必须使用 reducevg，否则会出问题。&lt;/li&gt;
  &lt;li&gt;当卷组中的一个磁盘损坏时，整个卷组都会受影响。&lt;/li&gt;
  &lt;li&gt;不能减小文件系统大小（受文件系统类型限制）。&lt;/li&gt;
  &lt;li&gt;因为加入了额外的操作，存储性能会受影响（使用 Stripe 的情况另当别论）。&lt;/li&gt;
  &lt;li&gt;使用 LVM 将获得更好的可扩展性和可操作性，但却损失了可靠性和存储性能，总的说来就是在这两者间选择。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用要点&lt;/p&gt;

&lt;p&gt;按需分配文件系统大小，不要一次性分配太大的空间给文件系统，剩余的空间可以放在存储池中，在需要时再扩充到文件系统中。
把不同的数据放在不同的卷组中，这样在做系统升级或数据迁移操作时会比较方便。&lt;/p&gt;

&lt;h2 id=&quot;linuxlvm&quot;&gt;Linux下LVM命令&lt;/h2&gt;

&lt;p&gt;LVM要实现的如下几个功能：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;创建PV、VG、LV&lt;/li&gt;
  &lt;li&gt;向VG中增加新的PV&lt;/li&gt;
  &lt;li&gt;从VG中移除PV&lt;/li&gt;
  &lt;li&gt;动态调整LV容量&lt;/li&gt;
  &lt;li&gt;删除PV、VG、LV&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：LV本质由PE组成的，那一个LV对应的所有PE是均匀分布在PV上吗？有什么策略？&lt;/p&gt;

&lt;h3 id=&quot;pvvglv&quot;&gt;PV\VG\LV的创建、删除&lt;/h3&gt;

&lt;p&gt;来个表格吧：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;命令&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;pvcreate&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;创建PV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;pvdisplay&lt;/code&gt;/&lt;code&gt;pvs&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;查询PV详情&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;pvremove&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;删除PV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;vgcreate&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;创建VG&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;vgdisplay&lt;/code&gt;/&lt;code&gt;vgs&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;查询VG详情&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;vgremove&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;删除VG&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;lvcreate&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;基于VG创建LV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;lvdisplay&lt;/code&gt;/&lt;code&gt;lvs&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;查询LV详情&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;lvremove&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;删除LV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;mkfs&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;格式化LV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;mount&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;挂载LV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;umount&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;卸载LV&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：先删除LV，再删除VG，最后删除PV。&lt;/p&gt;

&lt;h3 id=&quot;lvdoing&quot;&gt;LV的动态调整doing…&lt;/h3&gt;

&lt;p&gt;LV的动态调整：参考&lt;a href=&quot;http://www.cnblogs.com/xiaoluo501395377/archive/2013/05/24/3097785.html&quot;&gt;LVM逻辑卷的拉伸及缩减&lt;/a&gt;，&lt;a href=&quot;http://labs.chinamobile.com/mblog/854855_181800&quot;&gt;简单理解LVM(Logical Volume Manager)的基本原理&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;参考资料&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/jimmy_zjw/article/details/8598219&quot;&gt;什么是LVM?（CentOS 5）&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/xiaoluo501395377/archive/2013/05/22/3093405.html&quot;&gt;LVM逻辑卷基本概念及LVM的工作原理&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://labs.chinamobile.com/mblog/854855_181800&quot;&gt;简单理解LVM(Logical Volume Manager)的基本原理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;杂谈&lt;/h2&gt;

&lt;p&gt;我一直坚持读第一手的资料，因此，这次我直接就想到了CentOS官网的文章；不过读起来还是有些羞涩的，第一次接触LVM，很多东西云里雾里，相反查到的几篇blog还是不错的，有配图、有简洁的表述；因此，个人感觉，对于很生疏的东西，查看网上的blog反倒是入门的好方法；有了简单的入门知识，又希望深入理解的，那再去查第一手的资料就好了。&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>Understanding LVM</title>
     <link href="http://ningg.github.com/understanding-lvm"/>
     <updated>2014-10-28T00:00:00+08:00</updated>
     <id>http://ningg.github.com/understanding-lvm</id>
     <content type="html">&lt;blockquote&gt;
  &lt;p&gt;原文地址：&lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/sn-partitioning-lvm.html&quot;&gt;Understanding LVM&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;LVM (Logical Volume Management) partitions provide a number of advantages over standard partitions. （LVM，Logical Volume Management，逻辑卷管理）：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One or more physical volumes are combined to form a volume group. （n个physical volume，组成一个volume group）&lt;/li&gt;
  &lt;li&gt;Each volume group’s total storage is then divided into one or more logical volumes.（volume group被分割为n个logical volume）&lt;/li&gt;
  &lt;li&gt;The logical volumes function much like standard partitions. （在user看来，logical volume跟standard partition一样）&lt;/li&gt;
  &lt;li&gt;LVM partitions are formatted as physical volumes. They have a file system type, such as &lt;code&gt;ext4&lt;/code&gt;, and a mount point.（logical volume有自己的file system type，以及mount point）&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;The /boot Partition and LVM&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;On most architectures, the boot loader cannot read LVM volumes. You must make a standard, non-LVM disk partition for your &lt;code&gt;/boot&lt;/code&gt; partition.（绝大多数architecture下，boot loader不能读取LVM volume；因此，需要为&lt;code&gt;/boot&lt;/code&gt;单独分区，并指定一个non-LVM的分区）&lt;/p&gt;

  &lt;p&gt;However, on System z, the &lt;code&gt;zipl&lt;/code&gt; boot loader supports &lt;code&gt;/boot&lt;/code&gt; on LVM logical volumes with linear mapping.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To understand LVM better, imagine the physical volume as a pile of &lt;code&gt;blocks&lt;/code&gt;. A block is simply a storage unit used to store data. Several piles of blocks can be combined to make a much larger pile, just as physical volumes are combined to make a volume group. The resulting pile can be subdivided into several smaller piles of arbitrary size, just as a volume group is allocated to several logical volumes.&lt;/p&gt;

&lt;p&gt;An administrator may grow or shrink logical volumes without destroying data, unlike standard disk partitions. If the physical volumes in a volume group are on separate drives or RAID arrays then administrators may also spread a logical volume across the storage devices.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：LVM有两个优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;动态调整logical volume&lt;/strong&gt;：动态的grow or shrink Logical volume，数据不会损坏；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;并发写drives&lt;/strong&gt;：如果physical volume是多个drives 或者 RAID arrays，则 a logical volume能够横跨这些storage devices，带来一个好处，向某一目录写数据时，能够向多个磁盘并发写，加快写数据的速度；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You may lose data if you shrink a logical volume to a smaller capacity than the data on the volume requires. To ensure maximum flexibility, create logical volumes to meet your current needs, and leave excess storage capacity unallocated. You may safely grow logical volumes to use unallocated space, as your needs dictate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：当将logical volume大小调整为小于其所存储数据的大小时，会丢失数据；通常，按照当前需求分配logical volume大小，其余的存储空间不分配，今后根据需要动态的增加logical volume的大小。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;LVM and the Default Partition Layout&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;By default, the installation process creates &lt;code&gt;/&lt;/code&gt; and &lt;code&gt;swap&lt;/code&gt; partitions within LVM volumes, with a separate &lt;code&gt;/boot&lt;/code&gt; partition.&lt;/p&gt;
&lt;/blockquote&gt;

</content>
   </entry>
   
   <entry>
     <title>安装CentOS 6.4</title>
     <link href="http://ningg.github.com/centos-installation"/>
     <updated>2014-10-26T00:00:00+08:00</updated>
     <id>http://ningg.github.com/centos-installation</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;1. 简介&lt;/h2&gt;

&lt;p&gt;CentOS（Community Enterprise Operating System，企业社区操作系统）是Linux发行版本之一。Red Hat Enterpris Linux（RHEL，红帽企业级Linux）依照开放源码规定，开源了每个RHEL版本的源代码，CentOS正是基于RHEL的源代码重新编译而成的[1]，并且在RHEL基础上修复了一些已知的bug，相对与其他Linux发行版本，CentOS稳定性值得信赖。当前，很多企业都在服务器上安装CentOS系统，来支撑线上应用。
CentOS与RHEL的最大区别在于：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;RHEL中包含了部分封闭源码的工具，而CentOS包含的所有工具都是开源的；&lt;/li&gt;
  &lt;li&gt;RHEL提供技术服务，以此来收费；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;值得注意的是，2014年初，CentOS宣布加入Red Hat[2]。&lt;/p&gt;

&lt;p&gt;备注：CentOS的版本与RHEL版本基本一一对应，举例，CentOS 6.4对应RHEL 6.4的源代码。&lt;/p&gt;

&lt;h2 id=&quot;centos-6&quot;&gt;2. 安装CentOS 6&lt;/h2&gt;

&lt;p&gt;说到安装Linux系统，不要着急，官网肯定有操作手册来说明这个事，嗯，CentOS应用这么广泛，帮助手册总该有吧，要不然与其身份也不相符合。很不幸，&lt;a href=&quot;http://www.centos.org/docs/&quot;&gt;CentOS的官网&lt;/a&gt;中，并没有CentOS 6的操作手册，欧，赶快查查什么原因：CentOS完全基于RHEL源码编译而来，并且版本基本一一对应，因此，直接使用RHEL的官网文档即可[3]。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;特别说明&lt;/strong&gt;：本文所有安装CentOS 6的步骤、配置，都参考自RHEL 6官方文档[5]。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;2.1.	基本设置&lt;/h3&gt;

&lt;p&gt;这一部分，主要演示几点：如何通过CD/DVD光驱来重装系统。&lt;/p&gt;

&lt;p&gt;步骤 1. 	重启系统，出现图1界面时，点击”F11”按钮，目的：设置Boot Menu。
说明：当点击完”F11”按钮之后，如图1界面最下端所示，”F11”按钮背景由黑色变为白色。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/001.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;步骤 2. 	当出现图2所示界面时，选择”1”，目标：从光驱中加载系统。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/002.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;稍等一会儿，有可能出现图3所示界面，不要管他，等一段时间即可
备注：如果长时间停留在图3界面，则敲击Enter。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/003.png&quot; alt=&quot;图 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;步骤 3. 	出现如图4时，选择“Install sytem with basic video driver”（第二项），目标：重装系统。
备注：也可选择“Install or upgrade an existing system”（第一项），但，有可能显示器画面出现倾斜异常（显卡驱动问题），因此推荐 “Install sytem with basic video driver”（第二项）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/004.png&quot; alt=&quot;&quot; /&gt;
图 4&lt;/p&gt;

&lt;p&gt;步骤 4. 	出现如图5所示界面后，通过”Tab”键，选择“Skip”选项，并使用“Space”键来确认即可。目标：在安装之前，不进行磁盘、网卡、内存等硬件设备的测试。（因为太浪费时间了）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/005.png&quot; alt=&quot;&quot; /&gt;
图 5&lt;/p&gt;

&lt;p&gt;选择”Skip”之后，可能会出现图6所示界面，稍等一会儿，会自动跳入下个页面（如图7）。等待时间：几十秒~几分钟。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/006.png&quot; alt=&quot;&quot; /&gt; 
图 6&lt;/p&gt;

&lt;p&gt;步骤 5. 	出现如图7所示页面后，点击”Next”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/007.png&quot; alt=&quot;&quot; /&gt;
图 7&lt;/p&gt;

&lt;p&gt;步骤 6. 	在如图8所示界面，选择安装CentOS过程中，页面的显示语言，当安装服务器时，建议选择“English（English）”。
备注：这一步选定哪种语言，貌似对安装系统没有影响，而实际测试发现，有些细微差异，例如，安装完系统后，系统环境变量LANG会有细微差异。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/008.png&quot; alt=&quot;&quot; /&gt;
图 8&lt;/p&gt;

&lt;p&gt;步骤 7. 	参照下图9~15，一步步安装下去即可。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/009.png&quot; alt=&quot;&quot; /&gt;
图 9&lt;/p&gt;

&lt;p&gt;图9：选择系统键盘语言，选“U.S. English”即可。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/010.png&quot; alt=&quot;&quot; /&gt;
图 10&lt;/p&gt;

&lt;p&gt;图10：选择系统安装的磁盘，选“Basic Storage Devices”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/011.png&quot; alt=&quot;&quot; /&gt; 
图 11&lt;/p&gt;

&lt;p&gt;特别说明：有可能会出现图11界面，如果没有出现，则忽略图11。&lt;/p&gt;

&lt;p&gt;图11：是否覆盖掉所有系统数据，如果是重装系统，数据已经做过备份，则直接选“Fresh Installation”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/012.png&quot; alt=&quot;&quot; /&gt;
图 12&lt;/p&gt;

&lt;p&gt;图12：设定主机名（hostname），按照要求进行设置即可。&lt;/p&gt;

&lt;p&gt;备注：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;在图11页面的左下角，也可以通过“配置网络”按钮来设定网络，但不建议在此通过页面来配置网络（因为可能碰到乱七八糟的问题），而建议安装完系统后，通过简单命令来配置网络。&lt;/li&gt;
  &lt;li&gt;也可以安装完系统后，打开文件”/etc/sysconfig/network”，修改其中HOSTNAME字段。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/013.png&quot; alt=&quot;&quot; /&gt;
图 13&lt;/p&gt;

&lt;p&gt;图13：选定时区，选定“Asia/Shanghai”即可。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/014.png&quot; alt=&quot;&quot; /&gt; 
图 14&lt;/p&gt;

&lt;p&gt;图14：设定root密码&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/015.png&quot; alt=&quot;&quot; /&gt; 
图 15：选“Use Anyway”&lt;/p&gt;

&lt;p&gt;图15：提示密码不够安全，直接点击“Use Anyway”（无论如何都使用）即可。&lt;/p&gt;

&lt;p&gt;特别说明：至此，安装并没有结束，下面“2.2磁盘分区”部分才是重点。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;2.2.	磁盘分区&lt;/h3&gt;

&lt;p&gt;从图16开始，我们将进行磁盘分区，这一部分有些配置的东西，需要认真看了。&lt;/p&gt;

&lt;p&gt;备注：在此之前，需要补充一点理论知识：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.	为什么要进行磁盘分区？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;磁盘分区两点考虑，也就是说两个好处：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;数据安全：不同磁盘分区之间相互独立，某个分区损坏，不会影响其他分区内的数据；&lt;/li&gt;
  &lt;li&gt;读写性能：读写数据时，磁盘分区对应一段连续的磁柱，由于磁柱集中，提升数据的读写效率；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.	磁盘分区要分为几个区？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;磁盘分区方案，官网建议[7]，应该包含如下几个分区：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;分区&lt;/th&gt;
      &lt;th&gt;作用&lt;/th&gt;
      &lt;th&gt;官方建议大小&lt;/th&gt;
      &lt;th&gt;此次安装使用&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;/boot&lt;/td&gt;
      &lt;td&gt;存放OS kernel，以及系统bootstrap过程要使用的其他文件&lt;/td&gt;
      &lt;td&gt;&amp;gt;250MB&lt;/td&gt;
      &lt;td&gt;500MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;swap&lt;/td&gt;
      &lt;td&gt;虚拟内存：当内存空间不足时使用此空间&lt;/td&gt;
      &lt;td&gt;至少4GB，推荐为内存的1~2倍&lt;/td&gt;
      &lt;td&gt;128GB （系统内存64GB）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;/&lt;/td&gt;
      &lt;td&gt;存放：系统安装文件&lt;/td&gt;
      &lt;td&gt;3~5GB&lt;/td&gt;
      &lt;td&gt;60GB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;/home&lt;/td&gt;
      &lt;td&gt;存放：user data \n单独分区的目标：将user data与系统文件隔离&lt;/td&gt;
      &lt;td&gt;没有&lt;/td&gt;
      &lt;td&gt;100GB（实际是sda磁盘的剩余空间）&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;步骤 8. 	在图16界面，选择“Use All Space”，同时，勾选左下的“Review and modify partitioning layout”，目标：进入磁盘分区设置页面，调整磁盘分区。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/016.png&quot; alt=&quot;&quot; /&gt;
图 16：选“Use All Space”和勾选“Review and modify partitioning layout”&lt;/p&gt;

&lt;p&gt;中间可能要等待一段时间&lt;/p&gt;

&lt;p&gt;步骤 9. 	在图17所示页面，选择要进行分区的的磁盘，通常将“Data Storage Devicess”中所有磁盘都添加到“Install Target Devices”中，添加结果如图18所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/017.png&quot; alt=&quot;&quot; /&gt; 
图 17&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/018.png&quot; alt=&quot;&quot; /&gt; 
图 18&lt;/p&gt;

&lt;p&gt;图18：将“Data Storage Devicess”中所有磁盘都添加到“Install Target Devices”后的结果。 &lt;/p&gt;

&lt;p&gt;步骤 10. 	在图19所示页面，删除磁盘sda默认的分区：LVM Volume groups下的vg_cib61、sda下sda1和sda2；删除结果如图20所示。&lt;/p&gt;

&lt;p&gt;特别说明：要删除sda2分区，需要先删除LVM Volume groups下的vg_cib61。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/019.png&quot; alt=&quot;&quot; /&gt; 
图 19&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/020.png&quot; alt=&quot;&quot; /&gt;
图 20&lt;/p&gt;

&lt;p&gt;图20：删除sda上所有分区之后的结果。 &lt;/p&gt;

&lt;p&gt;步骤 11. 	在图20页面，按照提前规划的分区方案，在sda磁盘的Free空间上，依次划分/boot、swap、/、/home共计4个分区。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/021.png&quot; alt=&quot;&quot; /&gt; 
图 21&lt;/p&gt;

&lt;p&gt;图21：选择sda下Free空间，” Create” “Standard Partition”，即可进行创建分区，具体“/boot、swap、/、/home”的分区操作，依次参考图22、图23、图24、图25。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/022.png&quot; alt=&quot;&quot; /&gt; 
图 22&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/023.png&quot; alt=&quot;&quot; /&gt;
图 23&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/024.png&quot; alt=&quot;&quot; /&gt;
图 24&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/025.png&quot; alt=&quot;&quot; /&gt;
图 25&lt;/p&gt;

&lt;p&gt;步骤 12. 	这一步是进行LVM设置，如果没有LVM创建LV的需要，请直接跳过这一步，直接参考“步骤13”。 &lt;/p&gt;

&lt;p&gt;在此之前，补充一点LVM相关的理论知识：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.	为什么要用LVM？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LVM要解决的典型问题&lt;/strong&gt;：一块磁盘的空间160GB，其存满数据后，需要扩容，怎么办？传统静态分区时，需要将磁盘中近160GB的数据复制到1TB的磁盘上，然后，使用1TB的磁盘替换掉原来160GB的磁盘。（这个是传统扩容的基本原理，还有其他的原理吗？）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LVM基本原理&lt;/strong&gt;：要解决上面磁盘空间不足时，磁盘的扩容问题，LVM提供了一个基本思路：LVM将底层的磁盘封装抽象为逻辑卷（logical volume），上层应用不直接从物理磁盘分区中读数据，而是从逻辑卷中读数据；LVM负责底层磁盘到逻辑卷的映射和管理；增加底层磁盘时，通过LVM可以为逻辑卷动态扩充容量，而这对上层应用是无影响的（透明的）。&lt;/p&gt;

&lt;p&gt;说这么多，总结一点：LVM能够将多个小磁盘抽象为一个大逻辑卷，并且支持磁盘的动态扩容，提高了磁盘管理的灵活性。&lt;/p&gt;

&lt;p&gt;图26、图27、图28、图29：展示了在sdb1、sdc1、sdd1上创建一个大小约为850GB大小的VG（命名为vg_cib61），并且在这一VG上创建一个500GB大小的LV（lv_00）的基本过程。脑袋疼，不想多说，请自行查找其他资料。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/026.png&quot; alt=&quot;&quot; /&gt; 
图 26&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/027.png&quot; alt=&quot;&quot; /&gt;
图 27&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/028.png&quot; alt=&quot;&quot; /&gt;
图 28&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/029.png&quot; alt=&quot;&quot; /&gt;
图 29&lt;/p&gt;

&lt;p&gt;图29：创建Logical Volume时，并没有设置Mount Point，因为当前并不能确定挂载目录，装完系统之后，可以通过命令进行挂载。&lt;/p&gt;

&lt;p&gt;步骤 13. 	设置完磁盘分区后，到达图30所示界面，直接点击“Next”。&lt;/p&gt;

&lt;p&gt;特别说明：如果没有在步骤12中设置LVM，则没有图30中的“LVM Volume Groups”部分。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/030.png&quot; alt=&quot;&quot; /&gt;
图 30&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/031.png&quot; alt=&quot;&quot; /&gt;
图 31：选“Write changes to disk”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/032.png&quot; alt=&quot;&quot; /&gt;
图 32&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/033.png&quot; alt=&quot;&quot; /&gt;
图 33&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/034.png&quot; alt=&quot;&quot; /&gt;
图 34：选“Basic Server”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/035.png&quot; alt=&quot;&quot; /&gt;
图 35&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/036.png&quot; alt=&quot;&quot; /&gt;
图 36&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;3.	配置网络&lt;/h2&gt;

&lt;p&gt;安装完系统之后，需要进行网络配置，目标：保证机器能够入网。&lt;/p&gt;

&lt;p&gt;通常直接修改/etc/sysconfig/network-scripts/ifcfg-eth0文件即可，此次使用的是静态配置IP方式，因此需要进行如下修改（保持ifcfg-eth0文件中其他字段不变）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ONBOOT=yes
BOOTPROTO=static
IPADDR=168.7.2.111
NETMASK=255.255.255.0
GATEWAY=168.7.2.126
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;特别说明：服务器上有eth0–eth5，共计6个网口，需要根据具体情况，修改配置文件，上例中修改的是ifcfg-eth0文件，而在其他服务器上，如果网线插在eth3口，则需要修改ifcfg-eth3文件。&lt;/p&gt;

&lt;p&gt;有个小问题，值得说一下：服务器通常带有eth0–eth5多个网口，如何将eth0~5与实际的物理网口对应起来？&lt;/p&gt;

&lt;p&gt;RE：需要借助工具：ethtool，执行命令&lt;code&gt;ethtool -p eth0&lt;/code&gt;，再去看看那排网口，会有发现的~执行Ctrl + C，即可终止此命令。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;4.	格式化磁盘并挂载&lt;/h2&gt;

&lt;p&gt;场景 1.	格式化单个磁盘，并进行挂载，命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 格式化磁盘
mkfs -t ext3 /dev/sdb1
# 新建挂载点
mkdir -p /srv/hadoop/data1
# 挂载磁盘
mount /dev/sdb1 /srv/hadoop/data1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;场景 2.	批量格式化多个磁盘，并进行挂载，本质上就是重复“场景1”，只不过使用shell脚本来实现，脚本如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in {b..k}; do mkfs -t ext3 /dev/sd${i}1; done

for i in {1..10}; do mkdir -p /srv/hadoop/data${i}; done

array=(b c d e f g h i j k)
for((i=0;i&amp;lt;${#array[@]};i++)); do mount /dev/sd${array[i]}1 /srv/hadoop/data$(($i+1)); done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;场景 3.	设置开机自动挂载磁盘&lt;/p&gt;

&lt;p&gt;上面两个场景中，都涉及到mount磁盘到某个目录，但如果系统一不小心重启了，这些磁盘就需要重新挂载。解决办法：在fstab文件中设置开机自动挂载磁盘。
通过命令：man  fstab就可以查看fstab文件每列的含义：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;th&gt;6&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;special device&amp;gt;&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;mount point&amp;gt;&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;fs type&amp;gt;&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;mount options&amp;gt;&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;dump&amp;gt;&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;fsck&amp;gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;上述/etc/fstab文件每行数据，都有6个字段，如上图所示，简要说明几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;间隔符号：不同字段之间使用 ”空格” 或者 “Tab” 键来间隔&lt;/li&gt;
  &lt;li&gt;special device：要挂载的设备，例如：/dev/sdb1;&lt;/li&gt;
  &lt;li&gt;mount point：设备挂载的目标目录；&lt;/li&gt;
  &lt;li&gt;fs type：要挂载的设备上文件系统的类型；&lt;/li&gt;
  &lt;li&gt;options：mount命令进行挂载时，输入的参数；&lt;/li&gt;
  &lt;li&gt;dump：是否要对此文件系统进行备份，0代表不做dump备份，1代表需要dump备份，2代表也需要dump备份，但2的重要程度低于1；&lt;/li&gt;
  &lt;li&gt;fsck：系统启动时，是否检测文件系统的完整性，0代表不检测，根目录/需要设置为1，其他需要开机扫描的文件系统设置为2；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;来个fstab文件的样例，朝着这个格式来做就可以：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/dev/sdb1  /srv/hadoop/data1  ext3  defaults  0  0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置完fstab文件，一定要来一条命令：&lt;code&gt;mount -a&lt;/code&gt;
含义：&lt;code&gt;Mount all filesystems (of the given types) mentioned in fstab.&lt;/code&gt;
这一命令可用于检查fstab文件中的配置是否正确。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;5.	参考来源&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.centos.org/about/&quot;&gt;CentOS简介&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.redhat.com/en/about/press-releases/red-hat-and-centos-join-forces&quot;&gt;Red Hat and CentOS Project Join Forces to Speed Open Source Innovation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://lists.centos.org/pipermail/centos/2012-November/130123.html&quot;&gt;CentOS 6 docs参考RHEL 6即可&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/&quot;&gt;RHEL官方文档&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/index.html&quot;&gt;RHEL 6官文文档“Installation Guide”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/s1-x86-bootloader.html&quot;&gt;设定bootloader&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/s2-diskpartrecommend-x86.html&quot;&gt;Recommended Partitioning Schema&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;section-6&quot;&gt;6.	附录&lt;/h2&gt;

&lt;p&gt;几个有用的命令：&lt;/p&gt;

&lt;p&gt;命令 1. 	&lt;code&gt;dmidecode -t 1&lt;/code&gt;，查看当前服务器的序列号。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# dmidecode -t 1
# dmidecode 2.11
SMBIOS 2.7 present.

Handle 0x0100, DMI type 1, 27 bytes
System Information
		Manufacturer: HP
		Product Name: ProLiant ********
		Version: Not Specified
		Serial Number: ********
		UUID: ****-****-****-****-****
		Wake-up Type: Power Switch
		SKU Number: ****-****
		Family: ProLiant
&lt;/code&gt;&lt;/pre&gt;

</content>
   </entry>
   
   <entry>
     <title>Flume 1.5.0.1 User Guide：Event Serializers</title>
     <link href="http://ningg.github.com/flume-user-guide-event-serializer"/>
     <updated>2014-10-25T00:00:00+08:00</updated>
     <id>http://ningg.github.com/flume-user-guide-event-serializer</id>
     <content type="html">&lt;p&gt;The &lt;code&gt;file_roll sink&lt;/code&gt; and the &lt;code&gt;hdfs sink&lt;/code&gt; both support the &lt;code&gt;EventSerializer&lt;/code&gt; interface. Details of the &lt;code&gt;EventSerializers&lt;/code&gt; that ship with Flume are provided below.
（Event serializer，事件序列化，）&lt;/p&gt;

&lt;h2 id=&quot;body-text-serializer&quot;&gt;Body Text Serializer&lt;/h2&gt;

&lt;p&gt;Alias: text. This interceptor writes the body of the event to an output stream without any transformation or modification. The event headers are ignored. Configuration options are as follows:&lt;/p&gt;

&lt;p&gt;Property Name	Default	Description
appendNewline	true	Whether a newline will be appended to each event at write time. The default of true assumes that events do not contain newlines, for legacy reasons.
Example for agent named a1:&lt;/p&gt;

&lt;p&gt;a1.sinks = k1
a1.sinks.k1.type = file_roll
a1.sinks.k1.channel = c1
a1.sinks.k1.sink.directory = /var/log/flume
a1.sinks.k1.sink.serializer = text
a1.sinks.k1.sink.serializer.appendNewline = false
Avro Event Serializer&lt;/p&gt;

&lt;p&gt;Alias: avro_event. This interceptor serializes Flume events into an Avro container file. The schema used is the same schema used for Flume events in the Avro RPC mechanism. This serializers inherits from the AbstractAvroEventSerializer class. Configuration options are as follows:&lt;/p&gt;

&lt;p&gt;Property Name	Default	Description
syncIntervalBytes	2048000	Avro sync interval, in approximate bytes.
compressionCodec	null	Avro compression codec. For supported codecs, see Avro’s CodecFactory docs.
Example for agent named a1:&lt;/p&gt;

&lt;p&gt;a1.sinks.k1.type = hdfs
a1.sinks.k1.channel = c1
a1.sinks.k1.hdfs.path = /flume/events/%y-%m-%d/%H%M/%S
a1.sinks.k1.serializer = avro_event
a1.sinks.k1.serializer.compressionCodec = snappy&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>Flume 1.5.0.1 User Guide：Flume Channels</title>
     <link href="http://ningg.github.com/flume-user-guide-channel"/>
     <updated>2014-10-25T00:00:00+08:00</updated>
     <id>http://ningg.github.com/flume-user-guide-channel</id>
     <content type="html">&lt;p&gt;Channels are the repositories where the events are staged on a agent. Source adds the events and Sink removes it.
（agent中events存储在channels中：source将events添加到channels，sink从channels中读取events）&lt;/p&gt;

&lt;h2 id=&quot;memory-channel&quot;&gt;Memory Channel&lt;/h2&gt;

&lt;p&gt;The events are stored in an in-memory queue with configurable max size. It’s ideal for flows that need higher throughput and are prepared to lose the staged data in the event of a agent failures. Required properties are in bold.
（events被储存在in-memory queue中，queue的大小可以设定；适用场景：高吞吐量、在agent fail时允许lose data。）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;type&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be &lt;code&gt;memory&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;capacity&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;The maximum number of events stored in the channel&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;transactionCapacity&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;The maximum number of events the channel will take from a source or give to a sink per transaction&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;keep-alive&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Timeout in seconds for adding or removing an event&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;byteCapacityBufferPercentage&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;Defines the percent of buffer between byteCapacity and the estimated total size of all events in the channel, to account for data in headers. See below.&lt;strong&gt;（什么意思？）&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;byteCapacity&lt;/td&gt;
      &lt;td&gt;see description&lt;/td&gt;
      &lt;td&gt;Maximum total bytes of memory allowed as a sum of all events in this channel. The implementation only counts the Event &lt;code&gt;body&lt;/code&gt;, which is the reason for providing the &lt;code&gt;byteCapacityBufferPercentage&lt;/code&gt; configuration parameter as well. Defaults to a computed value equal to 80% of the maximum memory available to the JVM (i.e. 80% of the -Xmx value passed on the command line). Note that if you have multiple memory channels on a single JVM, and they happen to hold the same physical events (i.e. if you are using a replicating channel selector from a single source) then those event sizes may be double-counted for channel byteCapacity purposes. Setting this value to 0 will cause this value to fall back to a hard internal limit of about 200 GB.（设置为0，则参数取值为a hard internal limit，通常为200GB；）&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：&lt;code&gt;byteCapacityBufferPercentage&lt;/code&gt;参数的含义？event是由header和body构成的，参数&lt;code&gt;byteCapacity&lt;/code&gt;约束的只是&lt;code&gt;body&lt;/code&gt;，因此，新增了&lt;code&gt;byteCapacityBufferPercentage&lt;/code&gt;参数，表示&lt;code&gt;header&lt;/code&gt;的占用空间的的比例。&lt;/p&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.channels = c1
a1.channels.c1.type = memory
a1.channels.c1.capacity = 10000
a1.channels.c1.transactionCapacity = 10000
a1.channels.c1.byteCapacityBufferPercentage = 20
a1.channels.c1.byteCapacity = 800000
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;jdbc-channel&quot;&gt;JDBC Channel&lt;/h2&gt;

&lt;p&gt;The events are stored in a persistent storage that’s backed by a database. The JDBC channel currently supports embedded Derby. This is a durable channel that’s ideal for flows where recoverability is important. Required properties are in bold.
（将events持久化存储在database中，当前JDBC channel支持embeded Derby；适用于数据流可恢复性要求较高的场景。）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;type&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be jdbc&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;db.type&lt;/td&gt;
      &lt;td&gt;DERBY&lt;/td&gt;
      &lt;td&gt;Database vendor, needs to be DERBY.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;driver.class&lt;/td&gt;
      &lt;td&gt;org.apache.derby.jdbc.EmbeddedDriver&lt;/td&gt;
      &lt;td&gt;Class for vendor’s JDBC driver&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;driver.url&lt;/td&gt;
      &lt;td&gt;(constructed from other properties)&lt;/td&gt;
      &lt;td&gt;JDBC connection URL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;db.username&lt;/td&gt;
      &lt;td&gt;“sa”&lt;/td&gt;
      &lt;td&gt;User id for db connection&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;db.password&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;password for db connection&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;connection.properties.file&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;JDBC Connection property file path&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;create.schema&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;If true, then creates db schema if not there&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;create.index&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;Create indexes to speed up lookups&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;create.foreignkey&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;transaction.isolation&lt;/td&gt;
      &lt;td&gt;“READ_COMMITTED”&lt;/td&gt;
      &lt;td&gt;Isolation level for db session READ_UNCOMMITTED, READ_COMMITTED, SERIALIZABLE, REPEATABLE_READ&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;maximum.connections&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;Max connections allowed to db&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;maximum.capacity&lt;/td&gt;
      &lt;td&gt;0 (unlimited)&lt;/td&gt;
      &lt;td&gt;Max number of events in the channel&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;sysprop.*&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;DB Vendor specific properties&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;sysprop.user.home&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Home path to store embedded Derby database&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.channels = c1
a1.channels.c1.type = jdbc
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;file-channel&quot;&gt;File Channel&lt;/h2&gt;

&lt;p&gt;（todo）&lt;/p&gt;

&lt;h2 id=&quot;spillable-memory-channel&quot;&gt;Spillable Memory Channel&lt;/h2&gt;

&lt;p&gt;The events are stored in an in-memory queue and on disk. The in-memory queue serves as the primary store and the disk as overflow. The disk store is managed using an embedded File channel. When the in-memory queue is full, additional incoming events are stored in the file channel. This channel is ideal for flows that need high throughput of memory channel during normal operation, but at the same time need the larger capacity of the file channel for better tolerance of intermittent sink side outages or drop in drain rates. The throughput will reduce approximately to file channel speeds during such abnormal situations. In case of an agent crash or restart, only the events stored on disk are recovered when the agent comes online. &lt;strong&gt;This channel is currently experimental and not recommended for use in production&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：Spillable Memory Channel当前还是试验阶段，不推荐在生产环境中使用。&lt;/p&gt;

&lt;h2 id=&quot;pseudo-transaction-channel&quot;&gt;Pseudo Transaction Channel&lt;/h2&gt;

&lt;p&gt;Warning The Pseudo Transaction Channel is only for unit testing purposes and is NOT meant for production use.
Required properties are in bold.
（&lt;strong&gt;Warning&lt;/strong&gt;：Pseudo Transaction Channel，当前用于unit testing；不要用于生产环境）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;type&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be &lt;code&gt;org.apache.flume.channel.PseudoTxnMemoryChannel&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;capacity&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;The max number of events stored in the channel&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;keep-alive&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Timeout in seconds for adding or removing an event&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;custom-channel&quot;&gt;Custom Channel&lt;/h2&gt;

&lt;p&gt;A custom channel is your own implementation of the Channel interface. A custom channel’s class and its dependencies must be included in the agent’s classpath when starting the Flume agent. The type of the custom channel is its FQCN. Required properties are in bold.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;type&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be a &lt;code&gt;FQCN&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.channels = c1
a1.channels.c1.type = org.example.MyChannel
&lt;/code&gt;&lt;/pre&gt;

</content>
   </entry>
   
   <entry>
     <title>JSON简介以及JAVA API</title>
     <link href="http://ningg.github.com/json-java-api"/>
     <updated>2014-10-24T00:00:00+08:00</updated>
     <id>http://ningg.github.com/json-java-api</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;最近做个数据采集的东西，初步决定使用JSON作为数据交换格式，OK，学习整理一下。&lt;/p&gt;

&lt;h2 id=&quot;json&quot;&gt;JSON简介&lt;/h2&gt;

&lt;p&gt;JSON（JavaScript Object Notation），轻量级的数据交换格式，易于阅读和编写，同时机器也很容易输出JSON格式、解析JSON格式。JSON是完全独立于语言的文本格式，这使其成为理想的数据交换语言。&lt;/p&gt;

&lt;p&gt;JSON中两类基本结构：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;key:value&lt;/code&gt;：键-值对，通过key来标识value；&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;array&lt;/code&gt;：有序的数组；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;JSON利用上述的两类基本结构，实现了集中基本数据类型：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Object&lt;/strong&gt;：An object is an unordered set of name/value pairs. An object begins with { (left brace) and ends with } (right brace). Each name is followed by : (colon) and the name/value pairs are separated by , (comma).
（无序的key-value对，以&lt;code&gt;{&lt;/code&gt;开头，以&lt;code&gt;}&lt;/code&gt;结尾，其内部以&lt;code&gt;,&lt;/code&gt;逗号分隔）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/json-java-api/object.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Array&lt;/strong&gt;：An array is an ordered collection of values. An array begins with &lt;code&gt;[&lt;/code&gt; (left bracket) and ends with &lt;code&gt;]&lt;/code&gt; (right bracket). Values are separated by , (comma).
（有序的value序列，以&lt;code&gt;[&lt;/code&gt;开头，以&lt;code&gt;]&lt;/code&gt;结尾，其内部以&lt;code&gt;,&lt;/code&gt;逗号分隔）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/json-java-api/array.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Value&lt;/strong&gt;：A value can be a string in double quotes, or a number, or true or false or null, or an object or an array. These structures can be nested.
（Value表示的内容比较广，既可以是”“包含起来的String，也可以是数字，或者&lt;code&gt;true&lt;/code&gt;`false&lt;code&gt;；另一方面，也可以是&lt;/code&gt;Object`或者array）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/json-java-api/value.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;String&lt;/strong&gt;：A string is a sequence of zero or more Unicode characters, wrapped in double quotes, using backslash escapes. A character is represented as a single character string. A string is very much like a C or Java string.
（&lt;code&gt;&quot;&quot;&lt;/code&gt;双引号包含起来的Unicode 字符，其中可以使用&lt;code&gt;backslash&lt;/code&gt;来标识转义字符）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/json-java-api/string.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Number&lt;/strong&gt;：A number is very much like a C or Java number, except that the octal and hexadecimal formats are not used.
（不支持octal和hexadecimal formats）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/json-java-api/number.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Whitespace can be inserted between any pair of tokens. Excepting a few encoding details, that completely describes the language.
（任何符号之间都可插入空格&lt;code&gt;whitespace&lt;/code&gt;）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：JSON中&lt;code&gt;key&lt;/code&gt;能否重复？&lt;/p&gt;

&lt;h2 id=&quot;jsonjava-api&quot;&gt;处理JSON的JAVA API&lt;/h2&gt;

&lt;p&gt;处理JSON格式数据，无非两条路：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;JDK 自带的 Java API；（官方）&lt;/li&gt;
  &lt;li&gt;第三方jar包提供的java API；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;特别说明&lt;/strong&gt;：&lt;a href=&quot;https://jcp.org/en/jsr/detail?id=353&quot;&gt;JSR 353&lt;/a&gt;指出，今后的Java SE 6以及Java EE 7中要添加API来支持JSON格式数据的解析和转换。当前个人查证，在JDK6u30中没有java API来解析JSON；Java EE 7中，已经提供了&lt;code&gt;javax.json&lt;/code&gt;包来支持解析JSON。&lt;/p&gt;

&lt;p&gt;当前项目需求，在JDK5以及之上的版本都能进行JSON字符串与JSON对象之间的转换，OK，那直接上第三方jar包得了。&lt;/p&gt;

&lt;h3 id=&quot;javajsonjar&quot;&gt;java解析JSON的第三方jar包&lt;/h3&gt;

&lt;p&gt;从[JSON 主页][介绍 JSON]可知，当前，有很多的第三方jar包：org.json、org.json.me、jsonp、&lt;a href=&quot;http://jackson.codehaus.org/&quot;&gt;Jackson Json Processor&lt;/a&gt;、&lt;a href=&quot;http://code.google.com/p/google-gson/&quot;&gt;google-gson&lt;/a&gt;、Json-lib…，有点多呀，到底选哪个呢？当前初步考虑在如下两个中选：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spring中使用的是&lt;a href=&quot;http://jackson.codehaus.org/&quot;&gt;org.codehaus.jackson&lt;/a&gt;详细版本号&lt;code&gt;1.9.13&lt;/code&gt;（后来Spring 3.2中已经支持Jackson2了）&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://code.google.com/p/google-gson/&quot;&gt;google-gson&lt;/a&gt;的官方网站打不开，不过在maven中央仓库找到了gson的&lt;a href=&quot;http://repo1.maven.org/maven2/com/google/code/gson/gson/2.2.3/&quot;&gt;jar包&lt;/a&gt;，虽然无法查看官网的文档，不过maven中央仓库的javadoc、source文件也可以用来学习。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最终决定采用gson，其基本的JSON操作，参考：&lt;a href=&quot;http://blog.csdn.net/lk_blog/article/details/7685169&quot;&gt;JSON转换利器:Gson&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;json-1&quot;&gt;解析JSON字符串的效率问题&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://ifeve.com/json-java-api/&quot;&gt;处理JSON的Java API ：JSON的简介&lt;/a&gt;中提到解析JSON的API分为两类：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对象模型API&lt;/li&gt;
  &lt;li&gt;流API&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这两种方式在原理、效率上都有差异，TODO&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;参考来源&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.json.org/json-zh.html&quot;&gt;介绍 JSON&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://ifeve.com/json-java-api/&quot;&gt;处理JSON的Java API ：JSON的简介&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jcp.org/en/jsr/detail?id=353&quot;&gt;JSR 353&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/lk_blog/article/details/7685169&quot;&gt;JSON转换利器:Gson&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>Flume 1.5.0.1：如何将flume聚合的数据送入Kafka</title>
     <link href="http://ningg.github.com/flume-with-kafka"/>
     <updated>2014-10-24T00:00:00+08:00</updated>
     <id>http://ningg.github.com/flume-with-kafka</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;Flume收集分布在不同机器上的日志信息，聚合之后，将信息送入Kafka消息队列，问题来了：如何将Flume输出的信息送入Kafka中？&lt;/p&gt;

&lt;p&gt;定一个场景：flume读取apache的访问日志，然后送入Kafka中，最终消息从Kafka中取出，显示在终端屏幕上（stdout）。&lt;/p&gt;

&lt;h2 id=&quot;flume&quot;&gt;Flume复习&lt;/h2&gt;

&lt;p&gt;整理一下Flume的基本知识，参考来源有两个：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://flume.apache.org/documentation.html&quot;&gt;Flume Documentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Book: &lt;a href=&quot;http://files.hii-tech.com/Book/Hadoop/PacktPub.Apache.Flume.Distributed.Log.Collection.for.Hadoop.Jul.2013.pdf&quot;&gt;apache-flume-distributed-log-collection-hadoop&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-1&quot;&gt;几个概念&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Flume &lt;strong&gt;event&lt;/strong&gt;: a unit of data flow, having a byte payload and an optional set of string attributes.（event中包含了，payload和attributes）&lt;/li&gt;
  &lt;li&gt;Flume &lt;strong&gt;agent&lt;/strong&gt;: a (JVM) process, that hosts the components through which events flow from an external source to the next destination(hop).（agent对应JVM process）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Channel&lt;/strong&gt;:  passive store, keeps the event until it’s consumded by a Flume Sink.（Channel不会主动消费event，其等待Sink来取数据，会在本地备份Event）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sink&lt;/strong&gt;: remove the event from the channel and put it into external repository.（Sink主动从Channel中取出event）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/flume-user-guide/UserGuide_image00.png&quot; alt=&quot;&quot; /&gt; &lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;练习&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;场景&lt;/strong&gt;：Flume收集apache访问日志，然后，在标准终端（stdout）显示。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分析&lt;/strong&gt;：Flume官方文档中，已经给出了一个demo，flume从&lt;code&gt;localhost:port&lt;/code&gt;收集数据，并在标准终端上显示。基于这一场景，只需要修改Source即可。&lt;/p&gt;

&lt;h4 id=&quot;section-3&quot;&gt;构造实例&lt;/h4&gt;

&lt;p&gt;通过参阅Flume官网，得知&lt;code&gt;ExecSource&lt;/code&gt;可用于捕获命令的输出，并将输出结果按行构造event，&lt;code&gt;tail -F [local file]&lt;/code&gt;命令用于查阅文件&lt;code&gt;[local file]&lt;/code&gt;的新增内容；在&lt;code&gt;$FLUME_HOME/conf&lt;/code&gt;目录下，新建文件&lt;code&gt;apache_log_scan.log&lt;/code&gt;，内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.sources = r1
a1.sinks = k1
a1.channels = c1

a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /var/log/httpd/access_log

a1.sinks.k1.type = logger

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动Flume agent，命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[ningg@localhost flume]$ cd conf
[ningg@localhost  conf]$ sudo ../bin/flume-ng agent --conf ../conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console
...
...
 Component type: SOURCE, name: r1 started
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后访问一下Apache承载的网站，可以看到上面的窗口也在输出信息，即，已经在捕获Apache访问日志&lt;code&gt;access_log&lt;/code&gt;的增量了。（可以另起一个窗口，通过&lt;code&gt;tail -F access_log&lt;/code&gt;查看日志的实际内容）&lt;/p&gt;

&lt;h4 id=&quot;section-4&quot;&gt;存在的问题&lt;/h4&gt;

&lt;p&gt;通过比较Flume上sink的输出、&lt;code&gt;tail -F access_log&lt;/code&gt;命令的输出，发现输出有差异：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Flume上logger类型sink的输出
Event: { headers:{} body: 31 36 38 2E 35 2E 31 33 30 2E 31 37 35 20 2D 20 168.5.130.175 -  }

# access_log原始文件上的新增内容
168.5.130.175 - - [23/Oct/2014:16:34:59 +0800] &quot;GET /...&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;思考：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;logger类型的sink，遇到&lt;code&gt;[&lt;/code&gt;字符就结束？&lt;/li&gt;
  &lt;li&gt;logger类型的sink，有字符长度的限制吗？&lt;/li&gt;
  &lt;li&gt;channel有长度限制？channel中存储的event是什么形式存储的？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过&lt;code&gt;vim access_log&lt;/code&gt;，向文件最后添加一行内容，发现应该是logger类型的sink，对于event的长度有限制；或者，memory类型的channel对于存储的event有限制。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;参考来源&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://flume.apache.org/documentation.html&quot;&gt;Flume Documentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Book: &lt;a href=&quot;http://files.hii-tech.com/Book/Hadoop/PacktPub.Apache.Flume.Distributed.Log.Collection.for.Hadoop.Jul.2013.pdf&quot;&gt;apache-flume-distributed-log-collection-hadoop&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>win下搭建Storm topology的开发调试环境</title>
     <link href="http://ningg.github.com/storm-dev-env-with-eclipse"/>
     <updated>2014-10-23T00:00:00+08:00</updated>
     <id>http://ningg.github.com/storm-dev-env-with-eclipse</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;Storm topologies，支撑multilang，不同通常使用java来编写，这样我就想在Eclipse下来编写Storm topologies，毕竟IDE能够加快开发效率。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;下面的内容，基本都是从官网看的，使用自己语言重新写了一遍，建议有追求的Coder/Engineer/Scientist，还是去看官网吧，看官网才是捷径。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section-1&quot;&gt;系统环境&lt;/h2&gt;

&lt;p&gt;今天要进行Storm topology开发的系统，基本环境：win xp(x86)操作系统；更详细的编译环境信息，通过如下方式查看：&lt;code&gt;CMD&lt;/code&gt;–&lt;code&gt;systeminfo&lt;/code&gt;，这个命令执行需要时间，10~40s，稍等一会儿，得到如下信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C:\Documents and Settings\ningg&amp;gt;systeminfo

OS 名称:      Microsoft Windows XP Professional
OS 版本:      5.1.2600 Service Pack 3 Build 2600
OS 制造商:    Microsoft Corporation
OS 构件类型:  Multiprocessor Free
系统制造商:   LENOVO
系统型号:     ThinkCentre M6400t-N000
系统类型:     X86-based PC
处理器:       安装了 1 个处理器。
       [01]: x86 Family 6 Model 58 Stepping 9 GenuineIntel ~3392 Mhz
BIOS 版本:    LENOVO - 14f0
物理内存总量: 3,546 MB
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;eclipsestorm-start&quot;&gt;eclipse下查看storm-start工程&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/storm/tree/master/examples/storm-starter&quot;&gt;storm-starter&lt;/a&gt;是Storm官网提供的一个例子，简要介绍了storm topology的编写，在&lt;a href=&quot;http://storm.apache.org/documentation/Tutorial.html&quot;&gt;storm Tutorial&lt;/a&gt;中重点讲解了这个例子；总之，一点：&lt;a href=&quot;https://github.com/apache/storm/tree/master/examples/storm-starter&quot;&gt;storm-starter&lt;/a&gt;是入门学习的典型例子。OK，我准备在Eclipse下查看&lt;a href=&quot;https://github.com/apache/storm/tree/master/examples/storm-starter&quot;&gt;storm-starter&lt;/a&gt;工程。&lt;/p&gt;

&lt;p&gt;说一下我在Eclipse下的操作步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;下载storm发行版本的源代码：&lt;a href=&quot;http://storm.apache.org/downloads.html&quot;&gt;apache-storm-0.9.2-incubating-src.zip&lt;/a&gt;，并解压；&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;File&lt;/code&gt;–&lt;code&gt;Import&lt;/code&gt;–&lt;code&gt;Existing Maven Projects&lt;/code&gt;；&lt;/li&gt;
  &lt;li&gt;选择storm源代码的&lt;code&gt;examples\storm-starter&lt;/code&gt;目录，对，然后一路next下去；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;好了，中间可能提示maven项目有错误，不要管，一直往下走。接下来说一下如何解决maven项目的bug，我导入storm-starter工程后，&lt;code&gt;pom.xml&lt;/code&gt;文件上冒了个&lt;span style=&quot;color:red&quot;&gt;红色的X&lt;/span&gt;，找到相应位置，按下&lt;code&gt;F2&lt;/code&gt;，显示出错信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Plugin execution not covered by lifecycle configuration: 
com.theoryinpractise:clojure-maven-plugin:1.3.18:compile 
(execution: compile, phase: compile)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/images/storm-dev-env-with-eclipse/pom-error.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;OK，不要管这个，直接在storm-starter工程上，&lt;code&gt;右键&lt;/code&gt;–&lt;code&gt;Run As&lt;/code&gt;–&lt;code&gt;Maven build&lt;/code&gt;，输入参数：&lt;code&gt;clean install -DskipTests=true&lt;/code&gt;；然后，&lt;code&gt;Run&lt;/code&gt;；至此，打完收工，妥妥的，结果如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/storm-dev-env-with-eclipse/build-finished.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;到这一步，就可以参照&lt;a href=&quot;http://storm.apache.org/documentation/Tutorial.html&quot;&gt;storm Tutorial&lt;/a&gt;、&lt;a href=&quot;https://github.com/apache/storm/tree/master/examples/storm-starter&quot;&gt;storm-starter&lt;/a&gt;中的说明进行一步步的操作，来熟悉Storm topology。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;疑问&lt;/strong&gt;：Eclipse下就可以直接开发、调试topology了吗？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RE&lt;/strong&gt;：是的，直接开发，&lt;a href=&quot;http://storm.apache.org/documentation/Tutorial.html&quot;&gt;storm Tutorial&lt;/a&gt;中的例子就是这样。&lt;/p&gt;

&lt;h2 id=&quot;storm&quot;&gt;本地安装Storm&lt;/h2&gt;

&lt;p&gt;下载&lt;a href=&quot;http://storm.apache.org/downloads.html&quot;&gt;Storm的binary版本&lt;/a&gt;，就两点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;把 Storm的&lt;code&gt;bin&lt;/code&gt;目录添加到&lt;code&gt;PATH&lt;/code&gt;中；&lt;/li&gt;
  &lt;li&gt;验证是否安装成功：执行&lt;code&gt;storm&lt;/code&gt;命令，查看是否提示出错；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;疑问&lt;/strong&gt;：如果只是开发Storm topology，需要在本地win xp系统上安装Storm？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RE&lt;/strong&gt;：我来告诉你吧，本地安装Storm，核心用途是：充当client，向远端Storm cluster提交编写好的topology。重新来理一下，eclipse下新建工程，maven添加storm的依赖，即可进行topology的开发；然后通过本地安装的storm，可以进行本地的test、develop；最终，通过本地安装的storm充当client，可以向storm cluster提交topology。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;疑问：上面已经可以进行Storm topology的开发了，但如果希望查看Storm源代码，特别是Clojure编写的那部分，怎么办？&lt;/p&gt;

  &lt;p&gt;关于这个问题，官网有提示：&lt;a href=&quot;http://storm.apache.org/documentation/Creating-a-new-Storm-project.html&quot;&gt;Creating a new Storm project&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section-2&quot;&gt;参考来源&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/incubator-storm/tree/master/examples/storm-starter&quot;&gt;Storm Example: storm-starter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/documentation/Setting-up-development-environment.html&quot;&gt;Storm: Setting up development environment&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/documentation/Creating-a-new-Storm-project.html&quot;&gt;Storm: Creating a new Storm project&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>Flume 1.5.0.1 User Guide：Flume Sinks</title>
     <link href="http://ningg.github.com/flume-user-guide-sink"/>
     <updated>2014-10-23T00:00:00+08:00</updated>
     <id>http://ningg.github.com/flume-user-guide-sink</id>
     <content type="html">&lt;h2 id=&quot;hdfs-sink&quot;&gt;HDFS Sink&lt;/h2&gt;

&lt;p&gt;This sink writes events into the Hadoop Distributed File System (HDFS). It currently supports creating text and sequence files. It supports compression in both file types. The files can be rolled (close current file and create a new one) periodically based on the elapsed time or size of data or number of events. It also buckets/partitions data by attributes like timestamp or machine where the event originated. The HDFS directory path may contain formatting escape sequences that will replaced by the HDFS sink to generate a directory/file name to store the events. Using this sink requires hadoop to be installed so that Flume can use the Hadoop jars to communicate with the HDFS cluster. Note that a version of Hadoop that supports the sync() call is required.
（将events写到HDFS上，当前支持text和sequence file，同时也支持两种类型文件的压缩；支持根据time、size、event number来roll file——close current file并且create a new one；）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：text？sequence file？什么含义？&lt;/p&gt;

&lt;p&gt;The following are the escape sequences supported:&lt;/p&gt;

&lt;p&gt;Alias	Description
%{host}	Substitute value of event header named “host”. Arbitrary header names are supported.
%t	Unix time in milliseconds
%a	locale’s short weekday name (Mon, Tue, …)
%A	locale’s full weekday name (Monday, Tuesday, …)
%b	locale’s short month name (Jan, Feb, …)
%B	locale’s long month name (January, February, …)
%c	locale’s date and time (Thu Mar 3 23:05:25 2005)
%d	day of month (01)
%D	date; same as %m/%d/%y
%H	hour (00..23)
%I	hour (01..12)
%j	day of year (001..366)
%k	hour ( 0..23)
%m	month (01..12)
%M	minute (00..59)
%p	locale’s equivalent of am or pm
%s	seconds since 1970-01-01 00:00:00 UTC
%S	second (00..59)
%y	last two digits of year (00..99)
%Y	year (2010)
%z	+hhmm numeric timezone (for example, -0400)
The file in use will have the name mangled to include ”.tmp” at the end. Once the file is closed, this extension is removed. This allows excluding partially complete files in the directory. Required properties are in bold.&lt;/p&gt;

&lt;p&gt;Note For all of the time related escape sequences, a header with the key “timestamp” must exist among the headers of the event (unless hdfs.useLocalTimeStamp is set to true). One way to add this automatically is to use the TimestampInterceptor.
Name	Default	Description
channel	–	 
type	–	The component type name, needs to be hdfs
hdfs.path	–	HDFS directory path (eg hdfs://namenode/flume/webdata/)
hdfs.filePrefix	FlumeData	Name prefixed to files created by Flume in hdfs directory
hdfs.fileSuffix	–	Suffix to append to file (eg .avro - NOTE: period is not automatically added)
hdfs.inUsePrefix	–	Prefix that is used for temporal files that flume actively writes into
hdfs.inUseSuffix	.tmp	Suffix that is used for temporal files that flume actively writes into
hdfs.rollInterval	30	Number of seconds to wait before rolling current file (0 = never roll based on time interval)
hdfs.rollSize	1024	File size to trigger roll, in bytes (0: never roll based on file size)
hdfs.rollCount	10	Number of events written to file before it rolled (0 = never roll based on number of events)
hdfs.idleTimeout	0	Timeout after which inactive files get closed (0 = disable automatic closing of idle files)
hdfs.batchSize	100	number of events written to file before it is flushed to HDFS
hdfs.codeC	–	Compression codec. one of following : gzip, bzip2, lzo, lzop, snappy
hdfs.fileType	SequenceFile	File format: currently SequenceFile, DataStream or CompressedStream (1)DataStream will not compress output file and please don’t set codeC (2)CompressedStream requires set hdfs.codeC with an available codeC
hdfs.maxOpenFiles	5000	Allow only this number of open files. If this number is exceeded, the oldest file is closed.
hdfs.minBlockReplicas	–	Specify minimum number of replicas per HDFS block. If not specified, it comes from the default Hadoop config in the classpath.
hdfs.writeFormat	–	Format for sequence file records. One of “Text” or “Writable” (the default).
hdfs.callTimeout	10000	Number of milliseconds allowed for HDFS operations, such as open, write, flush, close. This number should be increased if many HDFS timeout operations are occurring.
hdfs.threadsPoolSize	10	Number of threads per HDFS sink for HDFS IO ops (open, write, etc.)
hdfs.rollTimerPoolSize	1	Number of threads per HDFS sink for scheduling timed file rolling
hdfs.kerberosPrincipal	–	Kerberos user principal for accessing secure HDFS
hdfs.kerberosKeytab	–	Kerberos keytab for accessing secure HDFS
hdfs.proxyUser	 	 
hdfs.round	false	Should the timestamp be rounded down (if true, affects all time based escape sequences except %t)
hdfs.roundValue	1	Rounded down to the highest multiple of this (in the unit configured using hdfs.roundUnit), less than current time.
hdfs.roundUnit	second	The unit of the round down value - second, minute or hour.
hdfs.timeZone	Local Time	Name of the timezone that should be used for resolving the directory path, e.g. America/Los_Angeles.
hdfs.useLocalTimeStamp	false	Use the local time (instead of the timestamp from the event header) while replacing the escape sequences.
hdfs.closeTries	0	Number of times the sink must try to close a file. If set to 1, this sink will not re-try a failed close (due to, for example, NameNode or DataNode failure), and may leave the file in an open state with a .tmp extension. If set to 0, the sink will try to close the file until the file is eventually closed (there is no limit on the number of times it would try).
hdfs.retryInterval	180	Time in seconds between consecutive attempts to close a file. Each close call costs multiple RPC round-trips to the Namenode, so setting this too low can cause a lot of load on the name node. If set to 0 or less, the sink will not attempt to close the file if the first attempt fails, and may leave the file open or with a ”.tmp” extension.
serializer	TEXT	Other possible options include avro_event or the fully-qualified class name of an implementation of the EventSerializer.Builder interface.
serializer.*	 	 &lt;/p&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.channels = c1
a1.sinks = k1
a1.sinks.k1.type = hdfs
a1.sinks.k1.channel = c1
a1.sinks.k1.hdfs.path = /flume/events/%y-%m-%d/%H%M/%S
a1.sinks.k1.hdfs.filePrefix = events-
a1.sinks.k1.hdfs.round = true
a1.sinks.k1.hdfs.roundValue = 10
a1.sinks.k1.hdfs.roundUnit = minute
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above configuration will round down the timestamp to the last 10th minute. For example, an event with timestamp 11:54:34 AM, June 12, 2012 will cause the hdfs path to become /flume/events/2012-06-12/1150/00.&lt;/p&gt;

&lt;h2 id=&quot;logger-sink&quot;&gt;Logger Sink&lt;/h2&gt;

&lt;p&gt;Logs event at INFO level. Typically useful for &lt;code&gt;testing&lt;/code&gt;/&lt;code&gt;debugging&lt;/code&gt; purpose. Required properties are in bold.
（将INFO以上几倍的event都记录下来，Logger Sink主要用于test和dubug）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;channel&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;type&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be &lt;code&gt;logger&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.channels = c1
a1.sinks = k1
a1.sinks.k1.type = logger
a1.sinks.k1.channel = c1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：&lt;code&gt;logger&lt;/code&gt;类型的Sink，有长度限制吗？&lt;/p&gt;

&lt;h2 id=&quot;avro-sink&quot;&gt;Avro Sink&lt;/h2&gt;

&lt;p&gt;This sink forms one half of Flume’s tiered collection support. Flume events sent to this sink are turned into Avro events and sent to the configured hostname / port pair. The events are taken from the configured Channel in batches of the configured batch size. Required properties are in bold.&lt;/p&gt;

&lt;p&gt;Property Name	Default Description	 
channel	–	 
type	–	The component type name, needs to be avro.
hostname	–	The hostname or IP address to bind to.
port	–	The port # to listen on.
batch-size	100	number of event to batch together for send.
connect-timeout	20000	Amount of time (ms) to allow for the first (handshake) request.
request-timeout	20000	Amount of time (ms) to allow for requests after the first.
reset-connection-interval	none	Amount of time (s) before the connection to the next hop is reset. This will force the Avro Sink to reconnect to the next hop. This will allow the sink to connect to hosts behind a hardware load-balancer when news hosts are added without having to restart the agent.
compression-type	none	This can be “none” or “deflate”. The compression-type must match the compression-type of matching AvroSource
compression-level	6	The level of compression to compress event. 0 = no compression and 1-9 is compression. The higher the number the more compression
ssl	false	Set to true to enable SSL for this AvroSink. When configuring SSL, you can optionally set a “truststore”, “truststore-password”, “truststore-type”, and specify whether to “trust-all-certs”.
trust-all-certs	false	If this is set to true, SSL server certificates for remote servers (Avro Sources) will not be checked. This should NOT be used in production because it makes it easier for an attacker to execute a man-in-the-middle attack and “listen in” on the encrypted connection.
truststore	–	The path to a custom Java truststore file. Flume uses the certificate authority information in this file to determine whether the remote Avro Source’s SSL authentication credentials should be trusted. If not specified, the default Java JSSE certificate authority files (typically “jssecacerts” or “cacerts” in the Oracle JRE) will be used.
truststore-password	–	The password for the specified truststore.
truststore-type	JKS	The type of the Java truststore. This can be “JKS” or other supported Java truststore type.
maxIoWorkers	2 * the number of available processors in the machine	The maximum number of I/O worker threads. This is configured on the NettyAvroRpcClient NioClientSocketChannelFactory.&lt;/p&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;p&gt;a1.channels = c1
a1.sinks = k1
a1.sinks.k1.type = avro
a1.sinks.k1.channel = c1
a1.sinks.k1.hostname = 10.10.10.10
a1.sinks.k1.port = 4545&lt;/p&gt;

&lt;h2 id=&quot;thrift-sink&quot;&gt;Thrift Sink&lt;/h2&gt;

&lt;p&gt;This sink forms one half of Flume’s tiered collection support. Flume events sent to this sink are turned into Thrift events and sent to the configured hostname / port pair. The events are taken from the configured Channel in batches of the configured batch size. Required properties are in bold.&lt;/p&gt;

&lt;p&gt;Property Name	Default	Description
channel	–	 
type	–	The component type name, needs to be thrift.
hostname	–	The hostname or IP address to bind to.
port	–	The port # to listen on.
batch-size	100	number of event to batch together for send.
connect-timeout	20000	Amount of time (ms) to allow for the first (handshake) request.
request-timeout	20000	Amount of time (ms) to allow for requests after the first.
connection-reset-interval	none	Amount of time (s) before the connection to the next hop is reset. This will force the Thrift Sink to reconnect to the next hop. This will allow the sink to connect to hosts behind a hardware load-balancer when news hosts are added without having to restart the agent.&lt;/p&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;p&gt;a1.channels = c1
a1.sinks = k1
a1.sinks.k1.type = thrift
a1.sinks.k1.channel = c1
a1.sinks.k1.hostname = 10.10.10.10
a1.sinks.k1.port = 4545&lt;/p&gt;

&lt;h2 id=&quot;irc-sink&quot;&gt;IRC Sink&lt;/h2&gt;

&lt;p&gt;The IRC sink takes messages from attached channel and relays those to configured IRC destinations. Required properties are in bold.&lt;/p&gt;

&lt;p&gt;Property Name	Default	Description
channel	–	 
type	–	The component type name, needs to be irc
hostname	–	The hostname or IP address to connect to
port	6667	The port number of remote host to connect
nick	–	Nick name
user	–	User name
password	–	User password
chan	–	channel
name	 	 
splitlines	–	(boolean)
splitchars	n	line separator (if you were to enter the default value into the config file, then you would need to escape the backslash, like this: “\n”)&lt;/p&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;p&gt;a1.channels = c1
a1.sinks = k1
a1.sinks.k1.type = irc
a1.sinks.k1.channel = c1
a1.sinks.k1.hostname = irc.yourdomain.com
a1.sinks.k1.nick = flume
a1.sinks.k1.chan = #flume&lt;/p&gt;

&lt;h2 id=&quot;file-roll-sink&quot;&gt;File Roll Sink&lt;/h2&gt;

&lt;p&gt;Stores events on the local filesystem. Required properties are in bold.
（将event存储到local FS上）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;channel&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;type&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be &lt;code&gt;file_roll&lt;/code&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;sink.directory&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The directory where files will be stored&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;sink.rollInterval&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;Roll the file every 30 seconds. Specifying 0 will disable rolling and cause all events to be written to a single file.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;sink.serializer&lt;/td&gt;
      &lt;td&gt;TEXT&lt;/td&gt;
      &lt;td&gt;Other possible options include &lt;code&gt;avro_event&lt;/code&gt; or the FQCN of an implementation of &lt;code&gt;EventSerializer.Builder&lt;/code&gt; interface.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;batchSize&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：FQCN: Fully-Qualified Class Name，全限定类名，包含package的class名称；txn：Transaction，事务。下面几个疑问：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;roll the file？是指对文件重命名存储吗？生成新文件？可以通过源代码进行学习；&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;sink.serializer&lt;/code&gt;什么含义？&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;batchSize&lt;/code&gt;什么含义？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.channels = c1
a1.sinks = k1
a1.sinks.k1.type = file_roll
a1.sinks.k1.channel = c1
a1.sinks.k1.sink.directory = /var/log/flume
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;null-sink&quot;&gt;Null Sink&lt;/h2&gt;

&lt;p&gt;Discards all events it receives from the channel. Required properties are in bold.
（丢弃所有event）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;channel&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;type&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be &lt;code&gt;null&lt;/code&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;batchSize&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.channels = c1
a1.sinks = k1
a1.sinks.k1.type = null
a1.sinks.k1.channel = c1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;hbasesinks&quot;&gt;HBaseSinks&lt;/h2&gt;

&lt;p&gt;（todo）&lt;/p&gt;

&lt;h2 id=&quot;morphlinesolrsink&quot;&gt;MorphlineSolrSink&lt;/h2&gt;

&lt;p&gt;（todo）&lt;/p&gt;

&lt;h2 id=&quot;elasticsearchsink&quot;&gt;ElasticSearchSink&lt;/h2&gt;

&lt;p&gt;（todo）&lt;/p&gt;

&lt;h2 id=&quot;custom-sink&quot;&gt;Custom Sink&lt;/h2&gt;

&lt;p&gt;A custom sink is your own implementation of the &lt;code&gt;Sink&lt;/code&gt; interface. A custom sink’s class and its dependencies must be included in the agent’s classpath when starting the Flume agent. The type of the custom sink is its FQCN. Required properties are in bold.
（通过实现Sink接口，可以定制自己的custom；需要在启动Flume agent时，将自定义的Sink和其depedencies添加到classpath中）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;channel&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;type&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be your &lt;code&gt;FQCN&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：FQCN是什么？Fully-Qualified Class Name，全限定类名。&lt;/p&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.channels = c1
a1.sinks = k1
a1.sinks.k1.type = org.example.MySink
a1.sinks.k1.channel = c1
&lt;/code&gt;&lt;/pre&gt;

</content>
   </entry>
   
   <entry>
     <title>Storm：Creating a new Storm project</title>
     <link href="http://ningg.github.com/storm-creating-a-new-strom-project"/>
     <updated>2014-10-22T00:00:00+08:00</updated>
     <id>http://ningg.github.com/storm-creating-a-new-strom-project</id>
     <content type="html">&lt;blockquote&gt;
  &lt;p&gt;原文地址：&lt;a href=&quot;http://storm.apache.org/documentation/Creating-a-new-Storm-project.html&quot;&gt;Creating a new Storm project&lt;/a&gt;，本文使用&lt;code&gt;英文原文+中文注释&lt;/code&gt;方式来写。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This page outlines how to set up a Storm project for development. The steps are:
（本文重点：介绍如何设置一个Storm project用于开发。）&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Add Storm jars to classpath（把storm的jar添加到classpath中）&lt;/li&gt;
  &lt;li&gt;If using multilang, add multilang dir to classpath（如果用了multilang，将dir添加到classpath中）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Follow along to see how to set up the &lt;a href=&quot;http://github.com/nathanmarz/storm-starter&quot;&gt;storm-starter&lt;/a&gt; project in Eclipse.&lt;/p&gt;

&lt;h2 id=&quot;add-storm-jars-to-classpath&quot;&gt;Add Storm jars to classpath&lt;/h2&gt;

&lt;p&gt;You’ll need the Storm jars on your classpath to develop Storm topologies. Using &lt;a href=&quot;http://storm.apache.org/documentation/Maven.html&quot;&gt;Maven&lt;/a&gt; is highly recommended. &lt;a href=&quot;https://github.com/nathanmarz/storm-starter/blob/master/m2-pom.xml&quot;&gt;Here’s an example&lt;/a&gt; of how to setup your pom.xml for a Storm project. If you don’t want to use Maven, you can include the jars from the Storm release on your classpath.
（推荐使用Maven方式，将Storm的jar包添加到classpath中）&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://github.com/nathanmarz/storm-starter&quot;&gt;storm-starter&lt;/a&gt; uses &lt;a href=&quot;http://github.com/technomancy/leiningen&quot;&gt;Leiningen&lt;/a&gt; for build and dependency resolution. You can install leiningen by downloading &lt;a href=&quot;https://raw.github.com/technomancy/leiningen/stable/bin/lein&quot;&gt;this script&lt;/a&gt;, placing it on your path, and making it executable. To retrieve the dependencies for Storm, simply run &lt;code&gt;lein deps&lt;/code&gt; in the project root.
（storm-starter project用了Leiningen来构建和进行依赖管理的，因此，下载Leiningen到本地，保证其可以执行，然后到project的根目录，执行&lt;code&gt;lein deps&lt;/code&gt;命令，来获取Storm的依赖）&lt;/p&gt;

&lt;p&gt;To set up the classpath in Eclipse, create a new Java project, include &lt;code&gt;src/jvm/&lt;/code&gt; as a source path, and make sure all the jars in &lt;code&gt;lib/&lt;/code&gt; and &lt;code&gt;lib/dev/&lt;/code&gt; are in the Referenced Libraries section of the project.
（创建java project，将&lt;code&gt;src/jvm/&lt;/code&gt;设置为source path，并将&lt;code&gt;lib/&lt;/code&gt;和&lt;code&gt;lib/dev/&lt;/code&gt;添加到build path中）&lt;/p&gt;

&lt;h2 id=&quot;if-using-multilang-add-multilang-dir-to-classpath&quot;&gt;If using multilang, add multilang dir to classpath&lt;/h2&gt;

&lt;p&gt;If you implement spouts or bolts in languages other than Java, then those implementations should be under the &lt;code&gt;multilang/resources/&lt;/code&gt; directory of the project. For Storm to find these files in local mode, the &lt;code&gt;resources/&lt;/code&gt; dir needs to be on the classpath. You can do this in Eclipse by adding &lt;code&gt;multilang/&lt;/code&gt; as a source folder. You may also need to add &lt;code&gt;multilang/resources&lt;/code&gt; as a source directory.
（使用multilang编写spout和bolt时，需要将实际的源代码放在&lt;code&gt;multilang/resources/&lt;/code&gt;目录）&lt;/p&gt;

&lt;p&gt;For more information on writing topologies in other languages, see &lt;a href=&quot;http://storm.apache.org/documentation/Using-non-JVM-languages-with-Storm.html&quot;&gt;Using non-JVM languages with Storm&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To test that everything is working in Eclipse, you should now be able to &lt;code&gt;Run&lt;/code&gt; the &lt;code&gt;WordCountTopology.java&lt;/code&gt; file. You will see messages being emitted at the console for 10 seconds.&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;参考来源&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/&quot;&gt;Apache Storm&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/documentation/Rationale.html&quot;&gt;Apache Storm: Documentation Rationale&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
 
</feed>
