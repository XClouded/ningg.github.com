<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
   <title>NingG.github.com</title>
   <link href="http://ningg.github.com/atom.xml" rel="self" type="application/atom+xml"/>
   <link href="http://ningg.github.com" rel="alternate" type="text/html" />
   <updated>2014-07-21T18:29:14+08:00</updated>
   <id>http://ningg.github.com</id>
   <author>
     <name></name>
     <email></email>
   </author>

   
   <entry>
     <title>HDFS:Hadoop Distributed File System简介</title>
     <link href="http://ningg.github.com/hdfs-intro"/>
     <updated>2014-07-14T00:00:00+08:00</updated>
     <id>http://ningg.github.com/hdfs-intro</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;最近要做一件事：调研远端节点向HDFS上传/下载文件的方法，并确定一个高效率的方案，这个最终方案初步确定了WebHDFS REST API方式，不过一些HDFS内部的实现细节/原理，自己很想一窥究竟，OK，既然有这份心情，那就走起，趁热打铁、一鼓作气。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;文件系统&lt;/h2&gt;

&lt;p&gt;为了实现多个应用可以并发的向存储介质上写入信息，出现了文件（File）这一概念，即把信息以一种单元（File，文件）的形式存储在介质上。文件是一个命名的、存储在设备上的信息的线性字节流。对文件的管理，包括文件的逻辑组成结构、命名、操作（读、写、删除）、权限管理、具体实现（如何组织存储区域），称为&lt;code&gt;文件系统&lt;/code&gt;（FileSystem，FS）。&lt;/p&gt;

&lt;p&gt;总结一下，文件系统需要解决文件相关的几个问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;怎么找到文件？（文件的命名）&lt;/li&gt;
  &lt;li&gt;可以对文件进行哪些操作？（读、写、删除、复制等）&lt;/li&gt;
  &lt;li&gt;哪些人可以对这个文件进行操作？（权限管理）&lt;/li&gt;
  &lt;li&gt;为保证上面的功能，并且，兼顾文件读写等操作的效率，逻辑上，一个文件可以划分为几个部分？（逻辑组成结构）&lt;/li&gt;
  &lt;li&gt;说一千道一万，上面这些东西，如何在物理磁盘上实现？（具体实现）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;无结构的文件 vs. 结构化的文件&lt;/p&gt;

&lt;p&gt;无结构的文件：大部分文件系统，不关系文件里保存的数据，把文件内容作为无结构的字节序列保存。也有一些文件系统支持结构化的文件，以记录为单位组织信息，免去文件系统使用者将“原始的”字节流转换成记录流的麻烦。&lt;/p&gt;

&lt;p&gt;一个文件，通常包含：文件名和文件数据，还包括，创建日期、文件长度、引用计数等额外信息，通常将这些额外项，称为文件属性，也称文件元数据。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;目录与目录树&lt;/h3&gt;

&lt;p&gt;如何找到一个文件呢？为了能够高效地找到文件，引入了“目录”这一概念。“目录”，又称“文件夹”，就是一个虚拟容器，其内部可能包含着一组文件和其他的目录（子目录）。目录和子目录，就形成了一个层次结构，称为目录树。&lt;/p&gt;

&lt;p&gt;为什么要有目录？没有行不行？没有目录可以，但是文件命名就比较麻烦，因为没有目录，所有的文件都不能同名，哪怕是简单的 &lt;code&gt;index.html&lt;/code&gt;、&lt;code&gt;default.css&lt;/code&gt;等文件也都只能有一个，所以说，本质上，目录实现了文件命名空间的分割，不同命名空间内，可以有同名文件存在。&lt;/p&gt;

&lt;p&gt;不同物理磁盘上，格式化得到的多个文件系统，可以相互挂载（嫁接），例如两个文件系统 FS1 和 FS2 ，将 FS2 挂载到 FS1 的 &lt;code&gt;/home&lt;/code&gt; 目录下，则，可以通过 &lt;code&gt;/home/user1&lt;/code&gt;
访问原来 FS2 上的 &lt;code&gt;/user1&lt;/code&gt; 目录。有一点需要说明的是：原来 FS1 目录 &lt;code&gt;/home&lt;/code&gt; 下的所有内容，都被隐藏而无法访问了，但是将 FS2 从 FS1 上卸载之后，仍能正常访问。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;文件系统的实现&lt;/h3&gt;

&lt;h2 id=&quot;section-4&quot;&gt;常见问题&lt;/h2&gt;

&lt;h3 id=&quot;section-5&quot;&gt;小文件个数多&lt;/h3&gt;

&lt;p&gt;HDFS支持超大文件（几百MB、几百GB、甚至TB=1024GB、PB=1024TB的文件），是通过将数据分布在数据节点（DataNode），并且将文件的元数据（目录树结构、文件-数据块索引等信息）存放在名字节点（NameNode）上，来实现的。名字节点（NameNode）的内存大小，决定了HDFS可以保存的文件数量；虽然现在内存数量比较大，但大量的小文件仍然严重影响名字节点（NameNode）的性能。&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;参考来源&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;《Hadoop技术内幕：深入解析Hadoop Common和HDFS架构的设计和实现原理》&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>maven使用入门</title>
     <link href="http://ningg.github.com/maven-intro"/>
     <updated>2014-07-04T00:00:00+08:00</updated>
     <id>http://ningg.github.com/maven-intro</id>
     <content type="html">&lt;blockquote&gt;
  &lt;p&gt;题记：&lt;a href=&quot;http://www.infoq.com/cn/minibooks/maven-in-action&quot;&gt;《Maven实战（迷你版）》&lt;/a&gt;这本书写的太好了，我忍不住把其中的内容又敲一遍。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;今天在GitHub上找了一个java语言编写的HDFS client，其使用Maven来进行工程的管理和构建；作为Maven工程导入Eclipse，提示pom.xml相关错误近10条。&lt;/p&gt;

&lt;p&gt;好吧，pom.xml是Maven的配置文件，看来Maven逃脱不了关系了。（之前，多次接触/使用Maven，不过都没有整理资料，导致每次使用都需要重新学习，如此反复，浪费时间，引以为戒，故有此博客）。&lt;/p&gt;

&lt;p&gt;备注：准备购买书籍，《Maven实战》&lt;/p&gt;

&lt;p&gt;要学东西，需要先找些比较可靠严谨的书籍，大概搜索了一下，&lt;a href=&quot;http://www.juvenxu.com/mvn-in-action/&quot;&gt;《Maven实战》&lt;/a&gt;这本书的评价较高，那就他了。 一两天内，也无法拿到纸质版的书籍，索性在InfoQ上找了一个&lt;a href=&quot;http://www.infoq.com/cn/minibooks/maven-in-action&quot;&gt;《Maven实战（迷你版）》&lt;/a&gt;。 &lt;/p&gt;

&lt;h3 id=&quot;maven&quot;&gt;Maven是什么？能做什么？&lt;/h3&gt;

&lt;p&gt;在开始正式介绍之前，还总结一下Maven到底能做什么吧，所谓学以致用，还是希望能够在今后的开发中把Maven用起来的。&lt;/p&gt;

&lt;p&gt;Maven能做什么？&lt;/p&gt;

&lt;h2 id=&quot;maven-1&quot;&gt;Maven的安装与配置&lt;/h2&gt;

&lt;h3 id=&quot;maven-2&quot;&gt;Maven的安装&lt;/h3&gt;

&lt;p&gt;从Maven官网下载软件，根据官方文档安装即可。基本步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;下载并解压文件；&lt;/li&gt;
  &lt;li&gt;添加环境变量：$M2_HOME=Maven安装目录，并将$M2_HOME/bin添加到$PATH。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;补充：安装软件，就不可避免会遇到软件版本升级问题，现有的较成熟的方案：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;win环境下，升级新版本的软件后，直接修改环境变量，指向新版本目录即可；&lt;/li&gt;
  &lt;li&gt;Linux环境下，升级软件版本之后，修改环境变量；除此之外，Linux下，还有更简便的办法：在软件安装目录下，新建一个符号链接文件，环境变量指向此文件，软件升级后，只需更新此符号链接文件即可。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Linux下，使用符号链接文件，来作为软件升级方案：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#新建符号链接apache-maven，指向apache-maven-3.0文件
ln -s apache-maven-3.0 apache-maven

#在配置文件~./bashrc中，添加环境变量
export M2_HOME=/home/devp/apache-maven
export PATH=$PATH:$M2_HOME/bin

#升级软件时，更新符号连接文件apache-maven
rm apache-maven
ln -s apache-maven-3.1 apache-maven
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;section-1&quot;&gt;安装目录分析&lt;/h3&gt;

&lt;p&gt;前文简要说明了Maven的安装与升级步骤，现在我们简要分析一下Maven的安装文件。&lt;/p&gt;

&lt;h4 id=&quot;m2home&quot;&gt;安装目录：M2_HOME&lt;/h4&gt;

&lt;p&gt;前面的讲解中，我们都是将环境变量M2_HOME指向Maven的安装目录，本文之后所有使用M2_HOME的地方都代表了该安装目录，让我们看一下该目录的安装结构和内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;|--bin
| 	|--m2.conf
|	|--mvn
|	|--mvnDebug
|
|--boot
| 	|--plexus-classworlds-xxx.jar
| 	
|--conf
|	|--settings.xml
|	|--logging
|		|--simplelogger.properties
|
|--lib
|	|--... ...
|
|--LICENSE
|--NOTICE
|--README.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;bin&lt;/strong&gt;：该目录包含了mvn运行的脚本，用来配置java命令，准备好classpath和相关的java命令参数，然后执行java命令。其中包含了mvn和mvnDebug两类脚本，打开来查看，就会看到mvnDebug只是比mvn多一条MAVEN_DEBUG_OPTS配置，作用就是在运行Maven时开启debug，方便调试Maven自身。此外，该目录还包含m2.conf文件，这是classworlds的配置文件，如果有必要，下文会对其进行介绍。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;boot&lt;/strong&gt;：以Maven 3.2.2为例，其中只包含了一个jar包plexus-classworlds-2.5.1.jar。这是一个类加载器框架，相对于默认的java类加载器，它提供了丰富的语法以方便配置，Maven使用该框架加载自己的类库。更多关于classworlds的信息请参考&lt;a href=&quot;http://classworlds.codehaus.org&quot;&gt;http://classworlds.codehaus.org&lt;/a&gt;。 对于普通的Maven用户，不必关心这一文件。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;conf&lt;/strong&gt;：该目录包含了一个非常重要的配置文件settings.xml，直接修改此文件，能够在机器上全局定制Maven的行文。一般情况下，我们更偏向于复制该文件到 &lt;code&gt;~/.m2/&lt;/code&gt; 目录下（此处 &lt;code&gt;~&lt;/code&gt; 代表用户目录），然后修改该配置文件，在用户范围内定制Maven行为。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;lib&lt;/strong&gt;：该目录包含了Maven运行所需的各类java类库，Maven本身是分模块开发的，因此用户能够看到诸如：maven-compact-3.2.2.jar、maven-core-3.2.2.jar、maven-model-3.2.2.jar等文件，此外这里含包含了一些Maven用到的第三方依赖，例如：guava-14.0.1.jar、commons-cli-1.2.jar等。（对于Maven2来说，该目录只包含一个如maven-2.2.1-uber.jar的文件，它是由原本相互独立的jar文件的Maven模块以及依赖的第三方类库拆解后，重新合并而成的）。可以说，这个目录才是真正的Maven。&lt;/p&gt;

&lt;p&gt;其他几个文件的简介：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LICENSE：记录了Maven使用的软件许可证，Apache License Version 2.0。&lt;/li&gt;
  &lt;li&gt;NOTICE：记录了Maven的发行机构。&lt;/li&gt;
  &lt;li&gt;README.txt：包含了Maven的简要介绍、安装步骤以及参考资料的链接。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;m2&quot;&gt;本地仓库：~/.m2目录&lt;/h4&gt;

&lt;p&gt;安装完Maven之后，运行命令&lt;code&gt;mvn help:system&lt;/code&gt; ，该命令打印出所有的Java系统属性和环境变量，这些信息对我们日常的编程工作很有帮助。这条命令执行之后，可以看到Maven会下载maven-help-plugin，包括pom文件和jar文件，这些文件都被存储在本地仓库中。&lt;/p&gt;

&lt;p&gt;打开当前登录用户的主目录（即，用户目录），下文使用&lt;code&gt;~&lt;/code&gt; 来表示用户目录。在用户目录下，可以看到 &lt;code&gt;.m2&lt;/code&gt; 目录。默认情况下，该文件夹下放置了Maven本地仓库：&lt;code&gt;.m2/repository&lt;/code&gt; 。所有的Maven构建（artifact）都被存储在本仓库中，以方便重用。我们可以在&lt;code&gt;~/.m2/repository/org/apache/maven/plugins/maven-help-plugins/&lt;/code&gt; 目录下，找到刚才下载的pom文件和jar文件（两文件缺一不可）。Maven根据几套规则来确定任何一个构建（artifact）在仓库中的位置。特别说明：由于Maven仓库是通过简单文件系统透明地展示给Maven用户的，有时候可以绕过Maven直接查看或修改仓库文件，在遇到疑难问题时，这往往十分有用。&lt;/p&gt;

&lt;h3 id=&quot;http&quot;&gt;配置HTTP代理&lt;/h3&gt;

&lt;p&gt;有时候公司处于安全考虑，要求通过安全认证的代理访问因特网。这就要求设置Maven通过HTTP代理方式，来访问外网的仓库，以下载所需的资源。&lt;/p&gt;

&lt;p&gt;确认当前代理可用，然后编辑 &lt;code&gt;~\.m2\settings.xml&lt;/code&gt; 文件（如果没有这一文件，就将&lt;code&gt;$M2_HOME\conf\settings.xml&lt;/code&gt; 复制过来）。添加代理配置如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;proxies&amp;gt;
	&amp;lt;!-- proxy
	 | Specification for one proxy, to be used in connecting to the network.
	 |--&amp;gt;
	&amp;lt;proxy&amp;gt;
	  &amp;lt;id&amp;gt;optional&amp;lt;/id&amp;gt;
	  &amp;lt;active&amp;gt;true&amp;lt;/active&amp;gt;
	  &amp;lt;protocol&amp;gt;http&amp;lt;/protocol&amp;gt;
	  &amp;lt;!-- 
	  &amp;lt;username&amp;gt;proxyuser&amp;lt;/username&amp;gt;
	  &amp;lt;password&amp;gt;proxypass&amp;lt;/password&amp;gt;
	  --&amp;gt;
	  &amp;lt;host&amp;gt;proxy.host.net&amp;lt;/host&amp;gt;
	  &amp;lt;port&amp;gt;80&amp;lt;/port&amp;gt;
	  &amp;lt;nonProxyHosts&amp;gt;local.net|some.host.com&amp;lt;/nonProxyHosts&amp;gt;
	&amp;lt;/proxy&amp;gt;
&amp;lt;/proxies&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上述代理的配置方式十分简单，porxies下可以配置多个proxy，如果声明了多个proxy元素，默认第一个proxy被激活，否则active值为true表示被激活。当代理服务需要认证时，需要配置username和password。nonProxyHosts元素用于指定哪些主机名不需要代理，可以使用 &lt;code&gt;|&lt;/code&gt; 来分隔多个主机名。此外，该配置也支持通配符，例如，*.google.com表示所有以google.com结尾的域名访问都不通过代理。&lt;/p&gt;

&lt;h3 id=&quot;eclipsemaven&quot;&gt;安装Eclipse的Maven插件&lt;/h3&gt;

&lt;p&gt;对于一个稍微大一点的项目来说，没有IDE是不可想象的，还好很多IDE都有Maven的插件。&lt;/p&gt;

&lt;p&gt;Eclipse平台下，插件名称：m2eclipse，我下载的Eclispe版本中，默认已经安装了此插件，因此，本文不暂讨论此问题。&lt;/p&gt;

&lt;h3 id=&quot;maven-3&quot;&gt;Maven安装最佳实践&lt;/h3&gt;

&lt;p&gt;本节介绍一些，Maven安装过程中不是必须的，但却比较使用的建议。&lt;/p&gt;

&lt;h4 id=&quot;settingsxml&quot;&gt;配置用户范围的settings.xml&lt;/h4&gt;

&lt;p&gt;Maven用户可以选择配置 &lt;code&gt;$M2_HOME/settings.xml&lt;/code&gt; 或者 &lt;code&gt;~/.m2/settings.xml&lt;/code&gt; 。前者是全局范围的配置，整台机器上的所有用户都会受这一配置的影响，而后者是用户范围的，只有当前用户会收到该配置的影响。&lt;/p&gt;

&lt;p&gt;推荐使用用户范围的配置，避免影响其他用户的配置，另一方面，也便于Maven升级：直接修改conf 目录下的settings.xml文件，这样每次升级时，都需要复制该文件，而如果使用.m2/settings.xml，则升级时，不需要触动settings.xml文件。&lt;/p&gt;

&lt;h4 id=&quot;idemaven&quot;&gt;不使用IDE内嵌的Maven&lt;/h4&gt;

&lt;p&gt;无论Eclipse还是NetBeans，当我们集成Maven时，都会安装一个内嵌的Maven：一方面，这个Maven通常比较新，但不一定很稳定；另一方面，通常我们还需要使用Maven的命令行方式，如果两个Maven版本不同的话，可能造成项目构建过程不一致，这也是我们不希望看到的。因此，建议单独下载安装一个Maven，并将恰配置到IDE中。&lt;/p&gt;

&lt;p&gt;Eclipse下，配置Maven：&lt;code&gt;Windows&lt;/code&gt;–&lt;code&gt;Preferences&lt;/code&gt;–&lt;code&gt;Maven&lt;/code&gt;–&lt;code&gt;Installations&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;常见错误&lt;/h3&gt;

&lt;p&gt;这一节，记录一些可能会遇到的问题，以及解决办法。&lt;/p&gt;

&lt;h4 id=&quot;maven-project&quot;&gt;创建/导入 Maven Project&lt;/h4&gt;

&lt;p&gt;错误详情：&lt;/p&gt;

&lt;p&gt;An internal error occurred during: “Updating Maven Project”. Lorg/codehaus/plexus/archiver/jar/JarArchiver;&lt;/p&gt;

&lt;p&gt;解决办法：在pom.xml中&lt;build&gt;&lt;plugins&gt;下添加&lt;/plugins&gt;&lt;/build&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;plugin&amp;gt;
	&amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;maven-jar-plugin&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;2.4&amp;lt;/version&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重新更新&lt;code&gt;Maven Project...&lt;/code&gt;（默认快捷键：&lt;code&gt;Alt + F5&lt;/code&gt;）。&lt;/p&gt;

&lt;p&gt;参考：&lt;a href=&quot;http://stackoverflow.com/questions/14491298/an-internal-error-occurred-during-updating-maven-dependencies&quot;&gt;stackoverflow&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;eclipsemavenjar&quot;&gt;Eclipse环境下，Maven报错找不到某些jar包&lt;/h4&gt;

&lt;p&gt;如果命令行方式下，使用&lt;code&gt;mvn&lt;/code&gt;的命令编译没有问题，而使用Eclipse时，&lt;code&gt;mvn install&lt;/code&gt;等命令出现问题，则,解决办法：在pom.xml中指定project,build,plugins内添加plugin，设置成与命令行条件下&lt;code&gt;mvn&lt;/code&gt;调用的plugin保持一致。&lt;a href=&quot;http://blog.csdn.net/imlmy/article/details/8268293&quot;&gt;参考1&lt;/a&gt;、&lt;a href=&quot;http://blog.csdn.net/huang86411/article/details/17548481&quot;&gt;参考2&lt;/a&gt;，当然还有另一种办法：&lt;a href=&quot;http://central.maven.org/maven2/org/apache/maven/plugins/&quot;&gt;手动下载jar和pom&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;疑问：在POM中 &lt;code&gt;&amp;lt;project&amp;gt; &amp;lt;dependencies&amp;gt;&lt;/code&gt; 下添加 &lt;code&gt;&amp;lt;dependency&amp;gt;&lt;/code&gt;元素 和 &lt;code&gt;&amp;lt;project&amp;gt; &amp;lt;build&amp;gt; &amp;lt;plugins&amp;gt;&lt;/code&gt; 下添加 &lt;code&gt;&amp;lt;plugin&amp;gt;&lt;/code&gt; 元素，有差异吗？有什么差异？备注：当前调试结果，可得有差异。&lt;/p&gt;

&lt;p&gt;如果当前使用了代理等方式导致网络连接局部受限，造成命令行方式 &lt;code&gt;mvn&lt;/code&gt;能够正常下载依赖的jar包，但在Eclipse环境下，无法下载所需的项目的依赖包，可以在命令行方式下，先进行下载，然后，在Eclipse下进行更新、运行即可。&lt;/p&gt;

&lt;p&gt;思考：Maven已经在settings.xml中配置了代理，那么，在Eclipse中开发调试Maven工程时，需要再配置Eclipse的代理吗？&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;入门实例&lt;/h2&gt;

&lt;p&gt;在此之前，需要安装配置好Maven，如果要在Eclipse下建立Maven工程，则需要安装配置Eclipse下的Maven的插件。具体信息，参考：&lt;a href=&quot;/download/maven/Maven+in+action.pdf&quot;&gt;《Maven实战（迷你版）》&lt;/a&gt;中第一章 Maven的安装与配置。&lt;/p&gt;

&lt;h3 id=&quot;pom&quot;&gt;编写POM&lt;/h3&gt;

&lt;p&gt;Maven项目的核心是：pom.xml文件。POM:(Project Object Model，项目对象模型)定义了项目的基本信息：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;项目如何构建（源文件编译、复制、打包）；&lt;/li&gt;
  &lt;li&gt;项目所需的依赖（个个依赖的项目内部之间的依赖关系）；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;现在我们新建一个Hello World项目，并编写一个最简单的pom.xml文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
		 xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
		 xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 
				http://maven.apache.org/maven-v4_0_0.xsd&quot;&amp;gt;
	
	&amp;lt;!-- POM模型的版本，对于Maven2和Maven3只能是4.0.0 --&amp;gt;
	&amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;
	
	&amp;lt;!-- groupId,artifactId,version 唯一定位项目（任何jar、pom、war） --&amp;gt;
	&amp;lt;!-- 定义project属于哪个组 --&amp;gt;
	&amp;lt;!-- 例如，公司为mycom，项目为myapp，则groupId：com.mycom.myapp --&amp;gt;
	&amp;lt;groupId&amp;gt;com.github.ningg.mvnbook&amp;lt;/groupId&amp;gt;
	
	&amp;lt;!-- 定义project在组内的代号，例如，你可能会为不同的子项目(模块)分配artifactId，
	例如，myapp组下，myapp-util,myapp-domain,myapp-domain --&amp;gt;
	&amp;lt;artifactId&amp;gt;hello-world&amp;lt;/artifactId&amp;gt;
	
	&amp;lt;!-- 定义当前artifact的版本，SNAPSHOT:快照，说明项目仍在开发中，当前还不稳定 --&amp;gt;
	&amp;lt;version&amp;gt;1.0-SNAPSHOT&amp;lt;/version&amp;gt;
	
	&amp;lt;!-- 声明一个别名，用户可理解的别名，不是必须的，但为方便交流，推荐每个POM --&amp;gt;
	&amp;lt;name&amp;gt;Maven Hello World Project&amp;lt;/name&amp;gt;
	
	&amp;lt;properties&amp;gt;
		&amp;lt;!-- 告知Maven进行复制、编译等操作时，使用的编码方式 --&amp;gt;
		&amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;
	&amp;lt;/properties&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;代码第一行是XML头，指定版本和编码方式。project是所有pom.xml的根元素，它还声明了一些命名空间和xsd（XML Schemas Definition，XML结构定义）元素，虽然这些属性是非必须的，但它们能够让第三方工具（如IDE中的XML编辑器）帮助我们快速编译POM。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;编写主代码&lt;/h3&gt;

&lt;p&gt;项目主代码与测试代码不同。项目主代码会被打包到最终发布的构件中（例如jar包），而测试代码只在运行测试的时候使用，不会被打包发布。
默认情况下，Maven假设项目的主代码位于src/main/java目录下，我们遵循Maven的约定，创建该目录，并在该项目下创建文件com/github/ningg/mvnbook/helloworld/HelloWorld.java，其内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package com.github.ningg.mvnbook.helloworld;

public class HelloWorld {

	public String sayHello(){
		return &quot;Hello Maven&quot;;
	}
	
	public static void main(String[] args){
		System.out.println(new HelloWorld().sayHello());
	}
	
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;补充说明如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;95%情况下，应将项目主代码放在src/main/java/目录下（Maven默认的约定），这样无需额外配置，Maven会自动搜索该项目主代码。&lt;/li&gt;
  &lt;li&gt;Java类的包名（package），应该与POM中定义的groupId和artifactId相吻合，例如，本例中的com.github.ningg.mvnbook.helloworld，这样代码结构清晰，符合基本逻辑，方便搜索构件或者java类。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;section-5&quot;&gt;进行编译&lt;/h3&gt;

&lt;p&gt;运行命令&lt;code&gt;mvn clean compile&lt;/code&gt;，则输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;E:\reference\blogOfGit\maven-intro\hello-world&amp;gt;mvn clean compile
[INFO] Scanning for projects...
[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] Building Maven Hello World Project 1.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO]
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hello-world ---
[INFO] Deleting E:\reference\blogOfGit\maven-intro\hello-world\target
[INFO]
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hello-world ---
[INFO] Using &#39;UTF-8&#39; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory E:\reference\blogOfGit\maven-intro\hello-world\src\main\resources
[INFO]
[INFO] --- maven-compiler-plugin:2.5.1:compile (default-compile) @ hello-world ---
[INFO] Compiling 1 source file to E:\reference\blogOfGit\maven-intro\hello-world\target\classes
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 0.828 s
[INFO] Finished at: 2014-07-01T20:46:45+08:00
[INFO] Final Memory: 6M/15M
[INFO] ------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;说明：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;从输出信息上可以看出，Maven具体包含3个操作：clean、resources、compile&lt;/li&gt;
  &lt;li&gt;clean：清理目录target/；&lt;/li&gt;
  &lt;li&gt;resources：（本实例中，没有定义项目资源，暂时略过）；&lt;/li&gt;
  &lt;li&gt;compile：编译项目主代码，默认输出到target/目录下；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;说明：上文提到的3个操作，对应了Maven的插件以及插件目标，例如：clean操作，实际上是maven-clean-plugin:2.5插件的clean目标；（Maven插件的编写是很重要的一个方向）&lt;/p&gt;

&lt;p&gt;至此，Maven在没有修改pom.xml配置的情况下，就进行了项目的清理和编译任务，在下文中，将继续编写一些测试单元代码并让Maven自动化测试。&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;编写测试代码&lt;/h3&gt;

&lt;p&gt;为保持项目结构清晰，主代码与测试代码分别在独立的目录中，前文提到过，主代码在src/main/java/目录下，对应的测试代码的目录是src/test/java/。因此，在编写代码前，应先创建这两个目录。&lt;/p&gt;

&lt;p&gt;在java世界中，JUnit是事实上的单元测试标准。要使用JUnit需要在项目的配置文件中添加一个JUnit依赖，修改项目POM如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;dependencies&amp;gt;
	&amp;lt;dependency&amp;gt;
		&amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
		&amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
		&amp;lt;version&amp;gt;4.7&amp;lt;/version&amp;gt;
		&amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
	&amp;lt;/dependency&amp;gt;
&amp;lt;/dependencies&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在project元素下，添加了dependencies元素，该元素下可以包含多个dependency元素，用与声明项目所需的依赖，这里我们添加的是(groupId,artifactId,version)为(junit,junit,4.7)的project，有了这段声明，Maven会自动下载junit-4.7.jar包。你可能会问，Maven从哪里下载这个jar呢？实际上，没有使用Maven时，我们需要自己去JUnit官网下载这个jar；而使用了Maven，它会自动访问自己的中央仓库(http://repo1.maven.org/maven2/)，下载所需要的文件，我们也可以自己访问这个中央仓库，打开junit/junit/4.7/路径，就能看到junit-4.7.pom和junit-4.7.jar。&lt;/p&gt;

&lt;p&gt;上述POM代码中，还设置了scope=test，其表示当前依赖仅对测试代码有效，换句话说，测试代码中import junit代码是正确的，而主代码中如果使用import junit就会编译出错。如果不设定scope，默认scope=compile，表示该依赖对主代码和测试代码都有效。&lt;/p&gt;

&lt;p&gt;配置好了测试依赖，就可以编写测试代码了，前面HelloWorld类中，需要测试sayHello()方法的返回值是否为“Hello Maven”。在src/test/java目录下创建文件，内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package com.github.ningg.mvnbook.helloworld;

import static org.junit.Assert.assertEquals;
import org.junit.Test;

public class HelloWorldTest {

	@Test
	public void testSayHello(){
		HelloWorld helloWorld = new HelloWorld();
		String result = helloWorld.sayHello();
		assertEquals(&quot;Hello Maven&quot;, result);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;（&lt;strong&gt;注意&lt;/strong&gt;：Eclipse集成开发环境下，在src/main/java/以及src/test/java/目录下编写java文件时，如何使用代码提示，特别是，很多jar的依赖都在pom.xml中配置的，当前工程暂时看不到jar包，import jar包都会提示出错。）&lt;/p&gt;

&lt;p&gt;典型的单元测试，包含3个步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;准备测试类及数据；&lt;/li&gt;
  &lt;li&gt;执行要测试的行为；&lt;/li&gt;
  &lt;li&gt;检查结果；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上述测试代码中，我们首先初始化一个要测试的HelloWorld实例，接着执行该实例的sayHello()方法并将结果保存到result变量中，最后使用JUnit框架的Assert类检查结果是否为我们期望的“Hello Maven”。在JUnit 3中，约定所有需要执行测试的方法都以test开头，这里我们使用JUnit 4，但我们仍遵守这一约定，在JUnit中，需要执行的测试方法都以@Test进行标注。&lt;/p&gt;

&lt;p&gt;测试代码编写完成之后，调用Maven执行测试，运行命令：&lt;code&gt;mvn clean test&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;E:\reference\blogOfGit\maven-intro\hello-world&amp;gt;mvn clean test
[INFO] Scanning for projects...
[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] Building Maven Hello World Project 1.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO]

...
Downloading: http://repo.maven.apache.org/maven2/junit/junit/4.7/junit-4.7.pom
Downloaded: http://repo.maven.apache.org/maven2/junit/junit/4.7/junit-4.7.pom (2 KB at 0.7 KB/sec)
Downloading: http://repo.maven.apache.org/maven2/junit/junit/4.7/junit-4.7.jar
Downloaded: http://repo.maven.apache.org/maven2/junit/junit/4.7/junit-4.7.jar (227 KB at 87.0 KB/sec)
...

[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ hello-world ---
[INFO] Deleting E:\reference\blogOfGit\maven-intro\hello-world\target
[INFO]
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ hello-world ---
[INFO] Using &#39;UTF-8&#39; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory E:\reference\blogOfGit\maven-intro\hello-world\src\main\resources
[INFO]
[INFO] --- maven-compiler-plugin:2.5.1:compile (default-compile) @ hello-world ---
[INFO] Compiling 1 source file to E:\reference\blogOfGit\maven-intro\hello-world\target\classes
[INFO]
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ hello-world ---
[INFO] Using &#39;UTF-8&#39; encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory E:\reference\blogOfGit\maven-intro\hello-world\src\test\resources
[INFO]
[INFO] --- maven-compiler-plugin:2.5.1:testCompile (default-testCompile) @ hello-world ---
[INFO] Compiling 1 source file to E:\reference\blogOfGit\maven-intro\hello-world\target\test-classes
[INFO]
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ hello-world ---
[INFO] Surefire report directory: E:\reference\blogOfGit\maven-intro\hello-world\target\surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.github.ningg.mvnbook.helloworld.HelloWorldTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.016 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1.359 s
[INFO] Finished at: 2014-07-01T21:41:33+08:00
[INFO] Final Memory: 7M/16M
[INFO] ------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从输出结果可以看出，执行&lt;code&gt;mvn clean test&lt;/code&gt;时，Maven实际执行了:&lt;code&gt;clean:clean&lt;/code&gt;,&lt;code&gt;resources:resources&lt;/code&gt;,&lt;code&gt;compiler:compile&lt;/code&gt;,&lt;code&gt;resources:testResources&lt;/code&gt;,&lt;code&gt;compiler:testCompile&lt;/code&gt;,&lt;code&gt;surefire:test&lt;/code&gt;。详细来说，Maven在执行测试（test）之前，会先执行：目录清理、主资源处理、主代码编译、测试资源处理、测试代码编译、执行测试等过程，这是Maven声明周期的一个特性，本文后续部分会详细介绍Maven的生命周期。（注：surefire是执行测试的插件，其运行测试用例，并输出测试报告。）&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;打包和运行&lt;/h3&gt;

&lt;p&gt;项目进行编译、测试之后，下一步就是打包（package）。Hello World项目的POM中没有设置打包类型，默认为jar；执行命令：&lt;code&gt;mvn clean package&lt;/code&gt;进行打包，可以看到如下输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;... ...

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.github.ningg.mvnbook.helloworld.HelloWorldTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.016 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0

[INFO]
[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ hello-world ---
[INFO] Building jar: E:\reference\blogOfGit\maven-intro\hello-world\target\hello-world-1.0-SNAPSHOT.jar
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1.531 s
[INFO] Finished at: 2014-07-01T22:00:37+08:00
[INFO] Final Memory: 7M/17M
[INFO] ------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;类似的，Maven在打包之前，会执行编译、测试等操作。这里我们看到jar:jar负责打包，实际上，就是jar插件的jar目标，将项目主代码打包成为一个名为hello-world-1.0-SNAPSHOT.jar的文件，该文件也位于target/目录下，它是根据artifactId-version.jar规则进行命名的，如有需要，可以使用finalName来定义文件名称。&lt;/p&gt;

&lt;p&gt;至此，我们得到了最终的jar包，如有需要，可以将这个jar包复制到其他项目的classpath中，从而使用HelloWorld类。但是，如何才能让其他Maven项目直接引用这个jar包呢？我们需要一个安装步骤，执行&lt;code&gt;mvn clean install&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;... ...

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.github.ningg.mvnbook.helloworld.HelloWorldTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.031 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0

[INFO]
[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ hello-world ---
[INFO]
[INFO] --- maven-install-plugin:2.4:install (default-install) @ hello-world ---
[INFO] Installing E:\reference\blogOfGit\maven-intro\hello-world\target\hello-world-1.0-SNAPSHOT.jar to C:\Documents and
 Settings\Luious\.m2\repository\com\github\ningg\mvnbook\hello-world\1.0-SNAPSHOT\hello-world-1.0-SNAPSHOT.jar
[INFO] Installing E:\reference\blogOfGit\maven-intro\hello-world\pom.xml to C:\Documents and Settings\Luious\.m2\reposit
ory\com\github\ningg\mvnbook\hello-world\1.0-SNAPSHOT\hello-world-1.0-SNAPSHOT.pom
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1.219 s
[INFO] Finished at: 2014-07-01T22:11:04+08:00
[INFO] Final Memory: 5M/15M
[INFO] ------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从输出结果可知，在jar:jar之后，Maven又执行了install:install，其将当前项目的jar包以及其POM配置文件，安装到了Maven的本地库中(~/.m2/repository/)。前文讲述JUnit的POM及jar下载的时候，我们说只有构件被下载到本地仓库后，才能由所有Maven项目使用类似，只有将Hello World的构件安装到本地仓库后，
其他Maven项目才能使用它。&lt;/p&gt;

&lt;p&gt;我们已经尝试使用了Maven的主要命令：&lt;code&gt;mvn clean compile&lt;/code&gt;,&lt;code&gt;mvn clean test&lt;/code&gt;,&lt;code&gt;mvn clean package&lt;/code&gt;,&lt;code&gt;mvn clean install&lt;/code&gt;。
执行test之前会先执行compile，执行package之前会先执行test，执行install之前会先执行package。至此，我们已经知道这些命令是用来干什么的了，可以在其他任何Maven项目中执行这些命令。&lt;/p&gt;

&lt;p&gt;重要提示：到目前为止，我们还没有运行Hello World项目，不要忘了HelloWorld类可能有一个main方法。默认打包生成的jar包并不能直接运行其中的main方法，因为带有main方法的类信息不会添加到manifest中（我们可以打开jar文件中的META-INF/MANIFEST.MF文件，将无法看到Main-Class一行）。为了生成可执行的jar文件，我们需要借助maven-shade-plugin，配置该插件如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;build&amp;gt;
 &amp;lt;plugins&amp;gt;
  &amp;lt;plugin&amp;gt;
   &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
   &amp;lt;artifactId&amp;gt;maven-shade-plugin&amp;lt;/artifactId&amp;gt;
   &amp;lt;version&amp;gt;1.2.1&amp;lt;/version&amp;gt;
   &amp;lt;executions&amp;gt;
		&amp;lt;execution&amp;gt;
		&amp;lt;phase&amp;gt;package&amp;lt;/phase&amp;gt;
		&amp;lt;goals&amp;gt;
			&amp;lt;goal&amp;gt;shade&amp;lt;/goal&amp;gt;
		&amp;lt;/goals&amp;gt;
		&amp;lt;configuration&amp;gt;
			&amp;lt;transformers&amp;gt;
			&amp;lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&amp;gt;
				&amp;lt;mainClass&amp;gt;com.github.ningg.mvnbook.helloworld.HelloWorld&amp;lt;/mainClass&amp;gt;
			&amp;lt;/transformer&amp;gt;
			&amp;lt;/transformers&amp;gt;
		&amp;lt;/configuration&amp;gt;
		&amp;lt;/execution&amp;gt;
   &amp;lt;/executions&amp;gt;
  &amp;lt;/plugin&amp;gt;
 &amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的plugin元素在POM中的相对位置应该在 &lt;code&gt;&amp;lt;project&amp;gt;&amp;lt;build&amp;gt;&amp;lt;plugins&amp;gt;&lt;/code&gt; 下面。其中我们配置，&lt;code&gt;mainClass&lt;/code&gt; 为 &lt;code&gt;com.github.ningg.mvnbook.helloworld.HelloWorld&lt;/code&gt; ，项目在打包时，会将该信息放在MANIFEST中。执行完 &lt;code&gt;mvn clean package&lt;/code&gt; 之后，在target/目录下，我们可以看到 &lt;code&gt;hello-world-1.0-SNAPSHOT.jar&lt;/code&gt; 
和 &lt;code&gt;original-hello-world-1.0-SNAPSHOT.jar&lt;/code&gt;，前者是带有Main-class信息的可运行jar，后者是原始的jar，打开 &lt;code&gt;hello-world-1.0-SNAPSHOT.jar&lt;/code&gt; 的 &lt;code&gt;META-INF/MANIFEST.MF&lt;/code&gt;，可以看到 &lt;code&gt;Main-class&lt;/code&gt; 信息。&lt;/p&gt;

&lt;p&gt;我们在项目根目录中执行该jar文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;E:\...\hello-world&amp;gt;java -jar target/hello-world-1.0-SNAPSHOT.jar
Hello Maven
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;（&lt;strong&gt;注意&lt;/strong&gt;：java命令行的使用方法，jar包等知识的补充）&lt;/p&gt;

&lt;p&gt;控制台输出：Hello Maven，这正是我们所期望的。&lt;/p&gt;

&lt;p&gt;本小节介绍了一个Hello World实例，侧重点是Maven而非Java代码，介绍了POM，Maven项目结构，以及如何编译、测试、打包、发布、运行。&lt;/p&gt;

&lt;h3 id=&quot;archetype&quot;&gt;使用Archetype生成项目骨架&lt;/h3&gt;

&lt;p&gt;Hello World项目中有一些Maven的约定：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;pom.xml在项目的根目录；&lt;/li&gt;
  &lt;li&gt;主代码在src/main/java/目录下；&lt;/li&gt;
  &lt;li&gt;测试代码在src/test/java/目录下；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我们称这些基本的目录结构和pom.xml文件内容为项目的骨架。每次创建项目都要手动创建项目骨架，会让程序员不高兴，为此，Maven提供了Archetype以帮助我们快速勾勒出项目骨架。&lt;/p&gt;

&lt;p&gt;以Hello World为例，我们使用maven archetype来创建该项目的骨架，新建一个Maven项目目录。&lt;/p&gt;

&lt;p&gt;如果是Maven3，简单运行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mvn archetype:generate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;（如果是Maven2，请参考：&lt;a href=&quot;/download/maven/Maven+in+action.pdf&quot;&gt;《Maven实战（迷你版）》&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;实际上，我们运行的是maven-archetype-plugin插件，其输入格式是：groupId:artifactId:version:goal，注意冒号的分隔。紧接着，我们会看到很长的输出，有很多可用的archetype供我们选择，包括注明的Appfuse项目、JPA项目的archetype等等。每一个archetype前面都会对应一个编号，同时命令行会提示一个默认的编号，对应archetype为maven-archetype-quickstart，直接回车选择该archetype，紧接着Maven会提示我们输入要创建的项目的groupId,artifactId,version以及包名（package，默认与groupId和artifactId保持对应关系），具体如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Define value for property &#39;groupId&#39;: : com.github.ningg.mvnbook
Define value for property &#39;artifactId&#39;: : hello-world-archetype
Define value for property &#39;version&#39;:  1.0-SNAPSHOT: :
Define value for property &#39;package&#39;:  com.github.ningg.mvnbook: : com.github.ningg.mvnbook.helloworldarchetype
Confirm properties configuration:
groupId: com.github.ningg.mvnbook
artifactId: hello-world-archetype
version: 1.0-SNAPSHOT
package: com.github.ningg.mvnbook.helloworldarchetype
 Y: : Y
[INFO] ----------------------------------------------------------------------------
[INFO] Using following parameters for creating project from Old (1.x) Archetype: maven-archetype-quickstart:RELEASE
[INFO] ----------------------------------------------------------------------------
[INFO] Parameter: groupId, Value: com.github.ningg.mvnbook
[INFO] Parameter: packageName, Value: com.github.ningg.mvnbook.helloworldarchetype
[INFO] Parameter: package, Value: com.github.ningg.mvnbook.helloworldarchetype
[INFO] Parameter: artifactId, Value: hello-world-archetype
[INFO] Parameter: basedir, Value: E:\reference\blogOfGit\maven-intro
[INFO] Parameter: version, Value: 1.0-SNAPSHOT
[INFO] project created from Old (1.x) Archetype in dir: E:\reference\blogOfGit\maven-intro\hello-world-archetype
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS

...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行完毕之后，在当前目录下会生成一个hello-world-archetype目录，其下是一个完整的项目骨架。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;特别说明&lt;/strong&gt;：如果你有很多项目拥有类似的项目骨架（项目结构和配置文件），你可以一劳永逸的开发自己的archetype，然后在项目中使用自定义的archetype来快速生成项目骨架。（具体请参考：&lt;a href=&quot;/download/maven/Maven+in+action.pdf&quot;&gt;《Maven实战（迷你版）》&lt;/a&gt;）&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>Notepad++快捷键</title>
     <link href="http://ningg.github.com/npp-shortcuts"/>
     <updated>2014-07-01T00:00:00+08:00</updated>
     <id>http://ningg.github.com/npp-shortcuts</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;notepad++ 用来编辑文档，总感觉不顺手，例如：多行同时编辑、剪切当前行、删除当前光标至行尾等都是手动操作。今天安装了Sublime Text 2，准备替代Notepad++，原因：听说Sublime提供了强大的快捷操作。&lt;/p&gt;

&lt;p&gt;转念一想，不对啊，难道Notepad++没有强大的快捷操作吗？可能是自己不知道，而不是Notepad++没有。&lt;/p&gt;

&lt;h2 id=&quot;notepad&quot;&gt;notepad++快捷键&lt;/h2&gt;

&lt;h3 id=&quot;section-1&quot;&gt;快捷键查找\设置&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;Settings&lt;/code&gt; – &lt;code&gt;Shortcut Mapper...&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;常用快捷键&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;快捷键&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;tab&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;插入，缩进&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;shift + tab&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;删除，缩进&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + J&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;合并，多行&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + D&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;复制，并粘贴，当前行&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + L&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;删除，当前行&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + T&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;上移，当前行&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + G&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;光标定位，指定行&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + BackSpace&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;删除，光标前单词&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + Delete&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;删除，光标后单词&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + u&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;转换，小写字母&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + shift + u&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;转化，大写字母&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + b&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;定位，匹配的括号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + alt + b&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;选中，匹配括号间的内容&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;F11&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;全屏显示&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + tab&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;下一个文档&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;alt + shift + up/down&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;编辑，多行&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + shift + up/down&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;上移/下移，当前行&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</content>
   </entry>
   
   <entry>
     <title>Linux下查看进程的内存占用</title>
     <link href="http://ningg.github.com/linux-top"/>
     <updated>2014-06-23T00:00:00+08:00</updated>
     <id>http://ningg.github.com/linux-top</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;最近几天，服务器使用&lt;code&gt;free -g&lt;/code&gt;来查看当前内存使用情况时，会发现内存空间几乎被完全占用了，如何能查看是哪个进程的问题？自己使用&lt;code&gt;top&lt;/code&gt;进来，看着不断刷新的监控数据，也无法找出哪个进程占用的内存最多，有位哥们儿建议：你按内存占用来排序，这样就直观看出来了。&lt;/p&gt;

&lt;h2 id=&quot;top&quot;&gt;top简介&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;top&lt;/strong&gt; - display Linux tasks&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;The  top  program  provides a dynamic real-time view of a running system.  It can display system summary information as
well as a list of tasks currently being managed by the Linux kernel.  The types of system summary information shown and
the  types,  order  and size of information displayed for tasks are all user configurable and that configuration can be
made persistent across restarts.&lt;/li&gt;
    &lt;li&gt;The program provides a limited interactive interface for process manipulation as well as a much more  extensive  interface for personal configuration  –  encompassing every aspect of its operation.  And while top is referred to throughout this document, you are free to name the program anything you wish.  That new name, possibly an alias, will then  be reflected on top’s display and used when reading and writing a configuration file.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;top-1&quot;&gt;top使用&lt;/h2&gt;

&lt;p&gt;输入&lt;code&gt;top&lt;/code&gt;命令之后，可以继续进行如下操作，依次来获取想要的信息。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;输入&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;h&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;获取帮助信息  or &lt;code&gt;?&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;q&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;退出top监控页面 or &lt;code&gt;ctrl + c&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;u&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;某一用户启动的所有进程&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;c&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;显示/取消，进程执行的详细信息，在COMMAND字段显示&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;k&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;kill指定PID的进程&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;O&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;排序，设置排序字段；&lt;code&gt;n&lt;/code&gt;:Mem，&lt;code&gt;k&lt;/code&gt;:CPU&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;R&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;倒序；即，如果原来按从小到大排序，则，变为从大到小排序&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;Z&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;设置窗口颜色配置方案&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;W&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;保存当前top命令的设置&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;思考&lt;/strong&gt;：top命令显示的监控信息，是如何计算出来的？是使用&lt;code&gt;/proc&lt;/code&gt;目录下的文件吗？&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>markdown入门介绍</title>
     <link href="http://ningg.github.com/introduction-to-markdown"/>
     <updated>2014-06-04T00:00:00+08:00</updated>
     <id>http://ningg.github.com/introduction-to-markdown</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;几个问题：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;markdown产生之前，没有markdown；随着时间推进，为什么会有markdown？&lt;/li&gt;
    &lt;li&gt;markdown能解决什么问题？这个问题之前没有解决办法吗？&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;书写WEB页面大都需要写HTML语法的页面，有很多类似&lt;code&gt;&amp;lt;h1&amp;gt;&lt;/code&gt;、 &lt;code&gt;&amp;lt;\h1&amp;gt;&lt;/code&gt;、 &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;、 &lt;code&gt;&amp;lt;\div&amp;gt;&lt;/code&gt;、 &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt;等的标签。&lt;/p&gt;

&lt;p&gt;有些WEB开发人员，厌倦了写HTML标签，同时，用文本编辑器查看HTML页面，内容读起来不简洁、看不出层次感。总结一下，就是两个需求：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;HTML页面写起来要简单；&lt;em&gt;（易写）&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;用文本编辑器查看，读起来要简洁；&lt;em&gt;（易读）&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;为实现”&lt;strong&gt;1.HTML页面易写&lt;/strong&gt;“这一功能，就不能再直接写HTML页面了，怎么办？重新定义一种易写的文本书写格式，然后，用个程序，将其转换为HTML页面。&lt;em&gt;（你看，HTML页面是否变得容易写了？）&lt;/em&gt;
同时，为了实现”&lt;strong&gt;2.文本易读&lt;/strong&gt;“这一功能，要求重新定义的文本书写格式具备格式简洁、层次清晰等特点。&lt;/p&gt;

&lt;p&gt;在这一背景下，markdown产生了。&lt;/p&gt;

&lt;h2 id=&quot;markdown&quot;&gt;markdown是什么？&lt;/h2&gt;

&lt;p&gt;markdown到底是什么？最原始介绍在这儿&lt;a href=&quot;http://daringfireball.net/projects/markdown/&quot; title=&quot;original markdown introduction&quot;&gt;markdown&lt;/a&gt; ，markdown有两层含义：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;一种文本格式：简洁的文本书写格式；&lt;em&gt;（易写、易读）&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;一种软件&lt;em&gt;（又称，解析引擎）&lt;/em&gt;：将markdown格式的文件，转换为HTML页面；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/images/introduction-to-markdown/markdown-and-html.png&quot; alt=&quot;markdown-and-html&quot; /&gt;&lt;/p&gt;

&lt;p&gt;看到上面图示，有人会问，markdown能够转换为HTML文档，那么，HTML文档能否转换为markdown格式文档呢？我x，你说呢，两种文档之间有映射关系，当然可以相互转换了，参考工具&lt;a href=&quot;http://www.aaronsw.com/2002/html2text/&quot;&gt;html2text&lt;/a&gt;。 &lt;/p&gt;

&lt;h2 id=&quot;notepadmarkdown&quot;&gt;Notepad++上配置markdown&lt;/h2&gt;

&lt;p&gt;GitHub上已经有人公开了Notepad++支持markdown语法的配置文件&lt;a href=&quot;https://github.com/thomsmits/markdown_npp&quot;&gt;markdown of Notepad++&lt;/a&gt;， 尝试用了一下，其中提到的&lt;a href=&quot;https://raw.github.com/thomsmits/markdown_npp/master/debug_theme/userDefineLang.xml&quot;&gt;debug theme&lt;/a&gt; 风格感觉不错。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;：一个bug需要调整，当markdown文档内url包含1个&lt;code&gt;_&lt;/code&gt;时，下文的显示样式错乱，需要在&lt;a href=&quot;https://raw.github.com/thomsmits/markdown_npp/master/debug_theme/userDefineLang.xml&quot;&gt;debug theme&lt;/a&gt; 格式定义文件中，将Delimiters中的&lt;code&gt;_&lt;/code&gt;字符删除即可。&lt;/p&gt;

&lt;h2 id=&quot;githubmarkdown&quot;&gt;GitHub上使用markdown&lt;/h2&gt;

&lt;p&gt;markdown有不同的解析引擎，GitHub上，应该使用哪一个？对此，GitHub帮助文档上有&lt;a href=&quot;https://help.github.com/articles/migrating-your-pages-site-from-maruku&quot;&gt;详细介绍&lt;/a&gt;， 简要介绍如下：&lt;/p&gt;

&lt;p&gt;2012年10月之前，GitHub Pages上使用&lt;a href=&quot;https://github.com/bhollis/maruku/&quot;&gt;Maruku&lt;/a&gt;作为markdown文档的解析引擎，来生成最终的HTML页面。&lt;/p&gt;

&lt;p&gt;2012年10月之后，Maruku官网声明：&lt;a href=&quot;http://benhollis.net/blog/2013/10/20/maruku-is-obsolete/&quot;&gt;Maruku项目将终止&lt;/a&gt; ，因此，GitHub建议使用&lt;a href=&quot;http://kramdown.gettalong.org/&quot; title=&quot;kramdown&quot;&gt;kramdown&lt;/a&gt;来替代&lt;a href=&quot;https://github.com/bhollis/maruku/&quot;&gt;Maruku&lt;/a&gt;。&lt;em&gt;（本blog使用的就是&lt;a href=&quot;http://kramdown.gettalong.org/&quot; title=&quot;kramdown&quot;&gt;kramdown&lt;/a&gt;解析引擎）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;：下文的基本语法，主要是&lt;a href=&quot;http://kramdown.gettalong.org/&quot; title=&quot;kramdown&quot;&gt;kramdown&lt;/a&gt;解析引擎支持的markdown语法。&lt;em&gt;（甚至有些语法，不是标准markdown语法，而是kramdown的扩展语法）&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;更新&lt;/strong&gt;：GitHub现在使用&lt;a href=&quot;https://help.github.com/articles/github-flavored-markdown&quot;&gt;GitHub Flavored Markdown&lt;/a&gt; 的Markdown语法，其在标准的&lt;a href=&quot;http://daringfireball.net/projects/markdown/&quot; title=&quot;original markdown introduction&quot;&gt;markdown&lt;/a&gt;语法上，进行了一些改进。&lt;/p&gt;

&lt;h2 id=&quot;doing&quot;&gt;基本语法(doing…)&lt;/h2&gt;

&lt;p&gt;对于标准markdown的语法规则，&lt;a href=&quot;http://daringfireball.net/projects/markdown/&quot; title=&quot;original markdown introduction&quot;&gt;markdown官网&lt;/a&gt;已经有了完善的介绍，当然也有中文版的&lt;a href=&quot;http://wowubuntu.com/markdown/&quot;&gt;markdown语法(简体中文)&lt;/a&gt; 。&lt;/p&gt;

&lt;p&gt;本文这一部分，主要是针对&lt;a href=&quot;http://kramdown.gettalong.org/&quot; title=&quot;kramdown&quot;&gt;kramdown&lt;/a&gt;解析引擎来说的，建议阅读官网的介绍：&lt;a href=&quot;http://kramdown.gettalong.org/syntax.html&quot;&gt;语法规则细则&lt;/a&gt; 和&lt;a href=&quot;http://kramdown.gettalong.org/quickref.html&quot;&gt;快速查询手册&lt;/a&gt; 。&lt;em&gt;（为什么介绍kramdown支持的语法？因为我在GitHub上指定的是kramdown解析引擎）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;下文将对自己常用到的语法，进行简要介绍，以备查阅。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;链接&lt;/h3&gt;

&lt;p&gt;包括：图片、文档、其他网页链接；&lt;/p&gt;

&lt;p&gt;如何约束图片的大小？&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;代码&lt;/h3&gt;

&lt;h3 id=&quot;section-3&quot;&gt;公式&lt;/h3&gt;

&lt;h3 id=&quot;section-4&quot;&gt;表格&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/introduction-to-markdown/chinese-carrier.jpg&quot; alt=&quot;chinese-carrier&quot; /&gt;
&lt;img src=&quot;/images/introduction-to-markdown/markdown-to-html.jpg&quot; alt=&quot;markdown-to-html&quot; /&gt;&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>磁盘和文件系统</title>
     <link href="http://ningg.github.com/computer-system-disk"/>
     <updated>2014-05-20T00:00:00+08:00</updated>
     <id>http://ningg.github.com/computer-system-disk</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;最近在服务器间传送文件，需要监控磁盘IO和网络IO，确定哪一个是瓶颈，并且找出服务器之间&lt;code&gt;高效传输文件&lt;/code&gt;的方案。&lt;/p&gt;

&lt;p&gt;更细节一些的：例如，提高磁盘的转速、改进磁盘接口，当前环境下，哪个有效？&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;磁盘&lt;/h2&gt;

&lt;p&gt;（本文关注的是旋转磁盘，固态硬盘不包含在内。）&lt;/p&gt;

&lt;p&gt;开篇有个疑问：要想在服务器间&lt;code&gt;高效地传输文件&lt;/code&gt;，首先要弄明白的是：文件在哪？好，文件不是凭空想想的，而是实实在在存储在物理介质上的，当前主要是存储于磁盘中。&lt;/p&gt;

&lt;p&gt;几个小常识：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;硬盘尺寸：台式机3.5英寸，笔记本尺寸2.5英寸；&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-2&quot;&gt;物理结构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/computer-system-disk/true-disk.jpg&quot; alt=&quot;true-disk&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上图可以看出，磁盘物理上，包含如下几个部分：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;盘片：通常包含两个&lt;code&gt;盘面&lt;/code&gt;，上面覆盖了磁性物质，用于记录数据；&lt;/li&gt;
  &lt;li&gt;磁头：每个&lt;code&gt;盘面&lt;/code&gt;对应一个磁头，读取&lt;code&gt;盘面&lt;/code&gt;上的数据；&lt;/li&gt;
  &lt;li&gt;主轴马达：带动盘片转动；&lt;/li&gt;
  &lt;li&gt;机械手臂：调整磁头位置；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;备注：所有磁头，任何时刻，都在同一&lt;code&gt;磁柱&lt;/code&gt;上。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;逻辑结构&lt;/h3&gt;

&lt;p&gt;磁盘有一个指标叫作&lt;code&gt;磁盘容量&lt;/code&gt;，它标识了一个磁盘可以存储多少个字节；那好，一个字节过来了，应该存储在哪个地方？&lt;em&gt;（类比，一位新兵到了，应该到部队中哪个地方去？）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;为避免混乱，方便管理，需要为磁盘设计一个组织方式。&lt;em&gt;（类比，部队被划分为一个个基本单元：&lt;code&gt;班&lt;/code&gt;，几个&lt;code&gt;班&lt;/code&gt;构成一个&lt;code&gt;排&lt;/code&gt;，几个&lt;code&gt;排&lt;/code&gt;构成一个&lt;code&gt;连&lt;/code&gt;……）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/computer-system-disk/disk-layer-structure.png&quot; alt=&quot;disk-layer-structure&quot; /&gt;&lt;/p&gt;

&lt;p&gt;磁盘的组织方式如上图所示，简要说明如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;磁盘最小的物理单元为&lt;code&gt;扇区&lt;/code&gt;(sector)，扇区的大小是固定的，通常为 512 bytes；&lt;/li&gt;
  &lt;li&gt;同一个&lt;code&gt;盘面&lt;/code&gt;上，同一圆圈上的所有&lt;code&gt;扇区&lt;/code&gt;组成一个&lt;code&gt;磁道&lt;/code&gt;(track)，又称&lt;code&gt;磁轨&lt;/code&gt;；&lt;/li&gt;
  &lt;li&gt;所有&lt;code&gt;盘面&lt;/code&gt;上，在对应位置的所有&lt;code&gt;磁道&lt;/code&gt;组成一个&lt;code&gt;磁柱&lt;/code&gt;(cylinder)；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;将上面的磁盘组织方式对应到实际物理磁盘上，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/computer-system-disk/disk-logic-structure.png&quot; alt=&quot;disk-logic-structure&quot; /&gt;&lt;/p&gt;

&lt;p&gt;补充说明：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;现在有的磁盘的&lt;code&gt;扇区&lt;/code&gt;大小为 4096 bytes;&lt;/li&gt;
  &lt;li&gt;通常，每个&lt;code&gt;磁道&lt;/code&gt;上&lt;code&gt;扇区&lt;/code&gt;个数相同，则，外圈的磁道上，扇区分布稀疏。为提升盘片的利用率，产生了&lt;code&gt;多区记录技术&lt;/code&gt;(multiple zone recording)：相邻的几个磁柱被分割为一个记录区（recording zone），一个记录区中，每个磁柱的每个磁道拥有相同数量的扇区，扇区数由记录区中最里侧的磁道来决定。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;section-4&quot;&gt;接口&lt;/h3&gt;

&lt;p&gt;为了读取磁盘中数据，需要一根排线，将磁盘连到电脑上；磁盘连接排线的地方叫接口，接口的传输速度限制了读取磁盘的最大速度。常见的磁盘接口，有IDE、SATA、SCSI。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IDE接口&lt;/strong&gt;：Integrated Drive Electronics，集成电路设备，具有如下特点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;排线较宽；&lt;/li&gt;
  &lt;li&gt;Ultra 133，即理论速度 133MB/s&lt;/li&gt;
  &lt;li&gt;每条IDE排线，可接2个IDE接口设备，分为master和slave，需要设置跳针；&lt;/li&gt;
  &lt;li&gt;常用于个人电脑；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;SATA接口&lt;/strong&gt;：Serial ATA，具有如下特点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;插槽比IDE小；&lt;/li&gt;
  &lt;li&gt;每条SATA排线，仅能连接一个SATA接口设备；&lt;/li&gt;
  &lt;li&gt;SATA-1理论速度：150MB/s，SATA-2理论速度：300MB/s，最近的SATA-3理论速度：600MB/s；&lt;/li&gt;
  &lt;li&gt;常用于个人电脑；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;SCSI接口&lt;/strong&gt;：Small Computer System Interface，小型计算机系统接口，具有如下特点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;对应磁盘上，有一个处理器，节省主板上CPU资源；&lt;/li&gt;
  &lt;li&gt;SCSI-3 Ultra 320的理论速度：320MB/s，Ultra 640的理论速度：640MB/s；&lt;/li&gt;
  &lt;li&gt;常用于服务器、工作站；&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;section-5&quot;&gt;筛选磁盘注意事项&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;接口类型：IDE？SATA？SCSI？主板上插槽是否支持？&lt;/li&gt;
  &lt;li&gt;容量：2T？500G？&lt;/li&gt;
  &lt;li&gt;转速：7200转/min？5400转/min？&lt;/li&gt;
  &lt;li&gt;磁盘缓冲内存大小：磁盘上此机制，加速文件读取速率；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;备注：建议每次正常关机，这样磁盘的机械手臂会回到原位。&lt;em&gt;（当前已有技术使得磁盘停止旋转后，机械手臂自动回到原位）&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;查看磁盘详情&lt;/h3&gt;

&lt;p&gt;（查看步骤）&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;读写磁盘耗时&lt;/h3&gt;

&lt;p&gt;读写磁盘所需时间，较为专业的称呼是&lt;code&gt;磁盘访问时间&lt;/code&gt;，其主要分为：寻道时间、旋转时间、传送时间，具体如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;寻道时间，&lt;code&gt;seek time&lt;/code&gt;：机械手臂摆动，将磁头定位到目标扇区所在的磁道上，其耗时是ms级的；&lt;/li&gt;
  &lt;li&gt;旋转时间，&lt;code&gt;rotational time&lt;/code&gt;：磁头定位到磁道后，需要等待目标扇区的第一个bit旋转到磁头下；&lt;/li&gt;
  &lt;li&gt;传送时间，&lt;code&gt;transfer time&lt;/code&gt;：磁头从目标扇区第一个bit扫描到最后一个bit所需时间；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;备注：旋转磁盘的访问时间是ms级别的。&lt;/p&gt;

&lt;h3 id=&quot;section-8&quot;&gt;查询磁盘参数&lt;/h3&gt;

&lt;p&gt;（出厂参数）&lt;/p&gt;

&lt;h3 id=&quot;io&quot;&gt;磁盘IO的基本过程&lt;/h3&gt;

&lt;p&gt;（DMA）&lt;/p&gt;

&lt;h3 id=&quot;section-9&quot;&gt;测试磁盘读写速度&lt;/h3&gt;

&lt;p&gt;（doing…）&lt;/p&gt;

&lt;h2 id=&quot;section-10&quot;&gt;磁盘格式化&lt;/h2&gt;

&lt;p&gt;一块新磁盘放在我面前，怎么往上面写文件呢？要想使用，需要先把磁盘内部的东西整理一下，即进行格式化。具体磁盘格式化包括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;低级格式化：又称，低阶格式化，&lt;/li&gt;
  &lt;li&gt;分区：&lt;/li&gt;
  &lt;li&gt;高级格式化：又称，高阶格式化，&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;section-11&quot;&gt;#&lt;/h2&gt;

&lt;h3 id=&quot;section-12&quot;&gt;磁盘分区&lt;/h3&gt;

&lt;h3 id=&quot;section-13&quot;&gt;磁盘格式化&lt;/h3&gt;

&lt;h2 id=&quot;section-14&quot;&gt;文件系统&lt;/h2&gt;

&lt;h2 id=&quot;section-15&quot;&gt;参考资料&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;深入理解计算机系统&lt;/li&gt;
  &lt;li&gt;鸟哥私房菜（基础篇）第三版&lt;/li&gt;
  &lt;li&gt;Disk formatting WIKI&lt;a href=&quot;http://en.wikipedia.org/wiki/Disk_formatting&quot;&gt;http://en.wikipedia.org/wiki/Disk_formatting&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

</content>
   </entry>
   
   <entry>
     <title>小记：杂乱就理一理</title>
     <link href="http://ningg.github.com/personal-think-20140517"/>
     <updated>2014-05-17T00:00:00+08:00</updated>
     <id>http://ningg.github.com/personal-think-20140517</id>
     <content type="html">&lt;p&gt;最近一段时间感触很多，年轻气盛？年富力强？浮躁？&lt;/p&gt;

&lt;p&gt;不管是什么情绪，避免给一件事情贴上单一的标签，画地为牢不好，嗯，是这样，要避免过多的依赖之前的经验，破旧才能立新。&lt;/p&gt;

&lt;p&gt;既然不想贴单一的标签，那同时贴上多个标签？NO，NO，我不喜欢复杂。&lt;em&gt;（什么？你说这个本来就是复杂的，要实事求是，面对事实？面你妹，在我看来就是很简单，这就是事实，如果你看起来复杂，那是你的事，你要面对事实）。&lt;/em&gt;嗯，那就把当前的情绪/氛围，称作那种情绪（&lt;code&gt;the emotion&lt;/code&gt;）吧，说破了天也不过是情绪的一种。&lt;/p&gt;

&lt;p&gt;最近想做的事情特别多，那就列一下吧：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;学习web 前端技术，包括JavaScript、HTML5、CSS3、JQuery；&lt;em&gt;（之前只是用什么查什么，没有整体上的理解）。&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;学习Node.JS；&lt;/li&gt;
  &lt;li&gt;系统学习计算机的基本理论，主要是&lt;a href=&quot;http://book.douban.com/subject/5333562/&quot;&gt;《深入理解计算机系统》&lt;/a&gt; 这本书；&lt;/li&gt;
  &lt;li&gt;移动端APP开发：主要是Andorid；&lt;/li&gt;
  &lt;li&gt;微信公共帐号开发；&lt;em&gt;（昨天在&lt;a href=&quot;http://bbs.byr.cn&quot;&gt;http://bbs.byr.cn&lt;/a&gt;上看到的）&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;网络安全技术：&lt;a href=&quot;/download/web-security/阿里巴巴集团web安全标准Ver1.4.doc&quot;&gt;《阿里巴巴集团web安全标准ver1.4》&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;数据库引擎的基本原理：&lt;a href=&quot;http://db.cs.berkeley.edu/papers/fntdb07-architecture.pdf&quot;&gt; Architecture of a Database System&lt;/a&gt; 或者&lt;a href=&quot;/download/database/fntdb07-architecture.pdf&quot;&gt;本地下载&lt;/a&gt;， &lt;a href=&quot;http://www.h2database.com/html/mvstore.html&quot;&gt;H2数据库的MVStore存储引擎&lt;/a&gt;，&lt;a href=&quot;http://book.douban.com/subject/6847455/&quot;&gt;《高可用MySQL》&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;UI设计&lt;/li&gt;
  &lt;li&gt;找个女朋友&lt;em&gt;（这个，要认真对待）&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;还有的，今后再补上；&lt;em&gt;（我x，想做的事也忒多了点吧；想做这么多？为啥？是为了满足自己装B需求么？本质上就一条，看我啥都会？别说，还真有点这么个原因，这个动机大概占2/3）&lt;/em&gt;，还有一个原因是，自己毕竟算是计算机科班出身，而且这两年也准备从事软件研发的工作，需要有些系统的知识，例如，&lt;a href=&quot;http://book.douban.com/subject/5333562/&quot;&gt;《深入理解计算机系统》&lt;/a&gt; 这本书。&lt;/p&gt;

&lt;p&gt;这两年自己逐渐有个感触：参考资料找对了，事情就成了一半；混乱的书籍、博客、论坛，解决问题、开拓思路还可以，但要系统学习，还需要依照经典书籍、一手官方文档。&lt;/p&gt;

&lt;p&gt;想想自己也是能够坚持的人，&lt;em&gt;（有几件事能够佐证，在此不表），&lt;/em&gt;做事情，需要认准方向，然后持续的付出时间，这样就妥了。&lt;/p&gt;

&lt;p&gt;想想xxx的几句话：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;求学而不是求得&lt;/li&gt;
  &lt;li&gt;选中后期难度大的，吃苦努力提高自身能力&lt;/li&gt;
  &lt;li&gt;唯一好的是知识，唯一坏的是无知&lt;/li&gt;
  &lt;li&gt;认准方向，用心去做&lt;/li&gt;
  &lt;li&gt;要自信、不要急、慢慢来，在一个方向上积累&lt;/li&gt;
  &lt;li&gt;随遇而安&lt;/li&gt;
  &lt;li&gt;欲速则不达&lt;/li&gt;
  &lt;li&gt;大器晚成&lt;/li&gt;
  &lt;li&gt;大巧不工&lt;/li&gt;
  &lt;li&gt;行百里者半九十&lt;/li&gt;
  &lt;li&gt;千里之堤溃于蚁穴&lt;/li&gt;
  &lt;li&gt;为腹不为目&lt;/li&gt;
  &lt;li&gt;知行合一&lt;/li&gt;
  &lt;li&gt;所担心的坏事必然发生&lt;/li&gt;
  &lt;li&gt;一专多能&lt;/li&gt;
  &lt;li&gt;利见大人&lt;/li&gt;
  &lt;li&gt;厚积薄发&lt;/li&gt;
  &lt;li&gt;情深不寿&lt;/li&gt;
  &lt;li&gt;强极必辱&lt;/li&gt;
  &lt;li&gt;道不同不相为谋&lt;/li&gt;
  &lt;li&gt;叶公好龙&lt;/li&gt;
  &lt;li&gt;道可道非恒道&lt;/li&gt;
  &lt;li&gt;天地不仁&lt;/li&gt;
  &lt;li&gt;圣人不仁&lt;/li&gt;
  &lt;li&gt;很多喜欢的事情只是因自己擅长，让自己觉得此方面比别人发展快，有成就感，乐意往此发展&lt;/li&gt;
  &lt;li&gt;人应该做什么事情时，不能因为不会不擅长而逃避，否则你在什么上面偷懒逃避，什么上就会出问题&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section&quot;&gt;20140701&lt;/h2&gt;

&lt;p&gt;有一点坚持的东西：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;选定自己坚持的东西；&lt;/li&gt;
  &lt;li&gt;选定自己坚持的东西的同时，要顺势而为，不要随心所欲；&lt;/li&gt;
  &lt;li&gt;花时间用心整理，要有积累；&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>S.M.A.R.T.经验</title>
     <link href="http://ningg.github.com/smarter-experience"/>
     <updated>2014-05-13T00:00:00+08:00</updated>
     <id>http://ningg.github.com/smarter-experience</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;事情背景&lt;/h2&gt;

&lt;p&gt;今天读了月光博客上的一篇文章&lt;a href=&quot;http://www.williamlong.info/archives/3849.html&quot;&gt;《通过SMART法则进行网站策划》&lt;/a&gt;， 里面提到网站前期策划，是影响网站能否做成的重要原因之一，这大概就是&lt;strong&gt;谋事在人&lt;/strong&gt;的意思，展开来说，做其他事情能否也借鉴S.M.A.R.T.经验？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/smarter-experience/smart-bike.jpg&quot; alt=&quot;bike&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;smart&quot;&gt;S.M.A.R.T.经验&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;SMART Criteria&lt;/code&gt;，&lt;code&gt;S.M.A.R.T.&lt;/code&gt; 标准\原则，但我更愿意将其翻译为：&lt;code&gt;S.M.A.R.T.&lt;/code&gt;经验，因为其提出者也指出S.M.A.R.T.不是万能的，这样将其称为&lt;code&gt;经验&lt;/code&gt;，用于提示自己这个东西使用的时候要慎重。&lt;em&gt;（尽信书不如无书）&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;是什么？&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/SMART_criteria&quot;&gt;SMART criteria&lt;/a&gt;， wiki上说的很清楚了，SMART经验，可用于指导设定目标，是个好工具，鼓励个人成长过程中使用。&lt;em&gt;（另，项目管理、员工绩效管理也有采用；插一下嘴，个人感觉，对普通员工，上行下效还是比较有用，如果这个真的对自己成长有利，也可以推荐给员工，甚至亲自为员工提供指导，这样的效果要比，找讲企业文化的人来给员工培训直接、有效；另一方面，如果这个东西，自己都不愿意用，反倒想在员工中推广，我只想说：糊弄鬼呢？）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;SMART，也有一个拓展版本SMARTER，其实是几个单词的首字母缩写：&lt;em&gt;（下面只是其中一个版本）&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Specific&lt;/li&gt;
  &lt;li&gt;Meassurable&lt;/li&gt;
  &lt;li&gt;Assignable&lt;/li&gt;
  &lt;li&gt;Realistic&lt;/li&gt;
  &lt;li&gt;Time-related&lt;/li&gt;
  &lt;li&gt;Evaluated&lt;/li&gt;
  &lt;li&gt;Reviewed&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/smarter-experience/smart.jpg&quot; alt=&quot;smart&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;个人理解&lt;/h3&gt;

&lt;p&gt;别人的引导很有用，而自己的思考更深刻、重要。对于SMARTER，当前个人有一点理解：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;要点&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;个人理解&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Specific&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;要做的事情需要明确：整体什么事情，分为几个模块/部分，都有什么可量化的要求&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Meassurable&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;事情进展，能够衡量：事情进展到哪一步了？还需要多久？&lt;em&gt;（时间纬度，可以采用小步快跑，快速迭代方式，分阶段，先来一期，画个轮廓——对事情整体上把握）&lt;/em&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Assignable&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;事情，可以找到合适的人来做，即，谁来做哪一块事情？&lt;em&gt;（对于个人而言，做事的就是自己；有机会时，用心体会\尝试任务分派）&lt;/em&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Realistic&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;事情能够完成吗？需要哪些人力、物力资源？人力、物力，分别要用到哪一部分？&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Time-related&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;事情严格时间限制，每一阶段都有截至日期&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Evaluated&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;评估当前进展，重新描绘当初设立的目标&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Reviewed&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;回顾已完成的部分，总结经验、教训&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;小结&lt;/strong&gt;，上面哒哒哒说了这么多，总结一下，设立目标有几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;目标明确，分解、量化，整体轮廓清晰；&lt;em&gt;（做什么？）&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;现有资源清晰、资源分配合理；&lt;em&gt;（怎么做？）&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;小步快跑、快速迭代，控制事情推进速度；&lt;em&gt;（做到哪了？）&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;阶段评估\思考当前进展\问题，及时改进\改善；&lt;em&gt;（做得更好）&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;smart-1&quot;&gt;SMART经验的利弊&lt;/h3&gt;

&lt;p&gt;利：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;设定的目标清晰、直观、易理解；&lt;/li&gt;
  &lt;li&gt;容易执行（因为明确指导要在每一步做什么）；&lt;/li&gt;
  &lt;li&gt;能直观看到事情进展；&lt;em&gt;（本来想说，把握事情进展，转念一想，多用通俗的词）&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;特别注意：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;目标是设想，执行才能看到结果，应侧重执行，避免束缚在目标的设定上&lt;em&gt;（明确的目标，需要依照执行情况，进行调整）&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;明确的目标对于短期进展，很有效；而长期的事情，一个抽象的目标，如同信念一般，很重要；&lt;em&gt;（长期的事情，发展曲折，多有变化，甚至做事的人的期望也会有变化）&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/smarter-experience/valley.jpg&quot; alt=&quot;valley&quot; /&gt;&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>同工不同酬，有什么神本事？</title>
     <link href="http://ningg.github.com/million-dollar-handcuffs"/>
     <updated>2014-05-12T00:00:00+08:00</updated>
     <id>http://ningg.github.com/million-dollar-handcuffs</id>
     <content type="html">&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;英文原文：&lt;a href=&quot;http://www.aminariana.com/essays/million-dollar-handcuffs&quot;&gt;What kind of jobs do the software engineers who earn $500K a year do?&lt;/a&gt; &lt;/li&gt;
    &lt;li&gt;Winston中文(繁体)译文：&lt;a href=&quot;http://winston-zh.attlin.com/2014/03/50.html&quot;&gt;同工不同酬？年薪 50 萬美金的工程師到底作哪些工作啊？&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;itwriter中文(简体)译文：&lt;a href=&quot;http://news.cnblogs.com/n/207596/&quot;&gt;同工不同酬，年薪 50 万美金的工程师到底有什么神本事？&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;他们究竟是作哪些事情，或是拥有哪些技术，让他们如此值钱？这些东西有办法用『学』吗？&lt;/p&gt;

&lt;p&gt;这位叫 Amin Ariana 的创业家就上 &lt;a href=&quot;http://www.quora.com/What-kind-of-jobs-do-the-software-engineers-who-earn-500k-per-year-do&quot;&gt;Quora 写了一则被赞到破表的回答&lt;/a&gt; ，我自己非常同意，也受到很多启发，因此跟 Amin 联络，获得允许，分享他的文章如下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/million-dollar-handcuffs/lg2.jpg&quot; alt=&quot;lg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;以下正文开始&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;声明：我之前也是 Google 的员工，但是我的回答不代表 Google 的观点。&lt;/p&gt;

&lt;p&gt;首先，这问题问得有点奇怪，有点误导人，好像只要工程师做了哪几点，或是获得哪些技能以后，就可以挂到年薪 50 万的保证。其实 Business Insider 那边说得很清楚了，50 万美金其实是薪水跟股票的总和。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;高昂报酬背后的条件：贡献不同等级的能力&lt;/h2&gt;

&lt;p&gt;要了解高昂报酬背后的条件，我先先来打个比方。&lt;/p&gt;

&lt;p&gt;假设你是村子里面非常重要的，负责水源供给的劳工。我们分为：一类劳工，与二类劳工。&lt;/p&gt;

&lt;p&gt;一类劳工会拎起一到两个水桶，冲到水源旁边，装满它们，把他们两个挑回来。水大概够 20 个人喝，如此一来有水喝的村民就皆大欢喜了。这个劳工挑水的过程可能会喝掉一些水，然后回到村中，他也可能可以分一些水回家作他的报酬。&lt;/p&gt;

&lt;p&gt;二类劳工不太理所谓『公平分水』的概念，他会拿起一把铲子，带上一只水杯，然后忽然间就消失了。他跑到水源处，挖一条可以通到村庄的小溪，希望可以把水源引过来。每当他拖着疲惫的身躯，拎着空杯子回到村庄的时候，总会引起一阵失望，但是不知道为什么那村中的长老相信他，相信他在做的事情（还丢根骨头给他啃，让他不会饿肚子）。&lt;/p&gt;

&lt;p&gt;某天，他直挺挺的站在村庄前面，他身后白涔涔地流躺着一条饮用水的小溪。这条小溪立刻把一类专门经营『水快递』的劳工赶出市场，他们只好转行，加入别的团队。这个二类劳工呢，看他对这条小溪拥有多少的控制权，一般而言，他有小溪很大部分的拥有权。&lt;/p&gt;

&lt;p&gt;后来村庄决定要把小溪整个买下来，整进整个村庄的供水系统，于是村庄拿了他们一部分的财产去换，比如说土地啊什么的，这个二类劳工于是瞬间升级变成地主了。&lt;/p&gt;

&lt;p&gt;村子里面的媒体注意到村子给这个二类劳工的薪水奇高，别村的人根本挖不动他（他应该是有跟村子签订协议，比如要在村子里留两年，才能领完全额的报酬之类的），于是出了一篇报导，写得好像别村出高价挖角，却因为村子给的薪水太好，以致于这个二类劳工根本不会考虑。&lt;/p&gt;

&lt;p&gt;这时候，一类劳工看了媒体报导，觉得村子亏待他们，同工不同酬，心生不满。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;沙滩上的掘渠者：冒险精神创造差异，创造高报酬&lt;/h2&gt;

&lt;p&gt;来说说一个真实的故事吧。&lt;/p&gt;

&lt;p&gt;今年跨年的时候，我跑去 Monterey Bay 玩，沙滩上有个年轻人在挖洞，我饶有兴致地站在高处看，我太太欣赏着沙滩的美景，其他人根本不在意这个年轻人的举动，没有人理他。我指着他转头跟太太说：「你等着看，30 分钟以后，周遭的所有人都会加入，帮这个年轻人挖」。&lt;/p&gt;

&lt;p&gt;30分钟以后，他挖出了一条小渠道，从他沙滩上的城堡直挺挺的延伸到海边有水的地方，希望把海水引入渠道，注入他的护城河。那渠道还不够深，海水还进不来，于是年轻人忙着加深河道。又过了5分钟，原本站在旁边看热闹的小孩们开始加入，动手帮忙。10 分钟以后，周遭的机个大人也开始挖掘。15 分钟以后，一个腼腆的，拎着相机的外国人也投入帮忙。60 分钟之内，这位二类劳工影响了 15 个一类劳工自愿投入，一起把海水引入护城河。&lt;/p&gt;

&lt;p&gt;文章开头的照片就是我当时照的，永久地纪念我对个人力量的赌注。那个拿着紫色桶子的家伙就是渠道的创造者，不过照片上看不出来就是了。&lt;/p&gt;

&lt;p&gt;新闻报导总是很喜欢忽略很多真实的细节，这篇年薪 50 万的报导就忽略掉『汗水并不等价』这个部分。二类劳工愿意突破现状，孤独地，有时候可能还要挨饿一小段时间来引入村子赖以维生的水源，一类劳工则是用自己完成的工作与技能去交换薪水，两者最主要的差异是冒险，而且不保证一定会回收。&lt;/p&gt;

&lt;p&gt;村子里有远见的那群人可以说都是二类劳工（在 Goolge 里面领高薪的那群），他们筚路蓝缕，以启山林，连结了村庄的水源。这些拿很多股票的家伙大概是下列其中一种：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;在 Goolge 当初创立时，就已经负责创造其核心价值的那群人。&lt;/li&gt;
    &lt;li&gt;自己业余的时候玩玩自己的专案（side project），然后公司觉得超级有用，也是很有价值的那群人。（译注：Gmaill 其实就是这样从 Side Project 长成现在 Goolge 核心产品的。）&lt;/li&gt;
    &lt;li&gt;自己开新创公司，被 Google 买进来的（比较少拉）不知道为什么有办法成为某种核心科技或是技能的唯一提供者。&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;除此之外，这种待遇大都是凭空想像出来的，用来卖很多很多 Business Insider 的文章（以台湾的例子来说，就是商周，还有今周刊那些 XD）。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;价值 190 亿美金的不录取通知&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;每颗心都会歌唱，只是唱得不完整，直到另一颗心跟着附和。 —— 柏拉图&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;多谢大家的热情支持，本文在 Quora 上面已经累积了 12 万则浏览，Quora 真是太屌了。&lt;/p&gt;

&lt;p&gt;我收到很多评论，有一部分跟我说上列的故事很难应用到他们的生活中，另一部分的评论问到跟公司谈判股权的技巧，希望要到 50 万美金收入的方式，其他的评论则说我这篇文章根本没有回答到他的问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;大部分的评论者都是一类劳工，还在想怎么作才能炒高自己的市场价值，获得更高的『收入』。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;那我再来说个故事吧，一个发生在上列文章出来一个礼拜之内的故事，希望这次会具体一点，比较好懂。&lt;/p&gt;

&lt;p&gt;被 Twitter、Facebook 拒绝，但创业后被 Facebook 以 190 亿美金收购&lt;/p&gt;

&lt;p&gt;2009 年 5 月，有个一类劳工应聘 Twitter ，但是他被拒绝了，于是 2009 年 8 月，他又跑去 Facebook 应聘，他也被拒绝了，怎么办？他决定自己出来试试看，挑起二类劳工的大樑，从『增进人类沟通』的水源处，挖起那条之前拒绝他一类服务的那两间公司都非常需要的小溪。&lt;/p&gt;

&lt;p&gt;一路走来，他与跟他一起挖小溪的朋友影响了 55 人加入团队，一起努力，村中的长老也丢了些骨头给他，一开始只有 25 万美元，接下来 8 百万美元，眼看着小溪越来越成功，红杉创投到后来注入 5000 万美元的资金。&lt;/p&gt;

&lt;p&gt;我写这篇文章的 3 小时前， CNN 刚刚报导他们二类劳工的作品被 Facebook 以 190 亿美金收购（你没听错， 190 亿美元）。&lt;/p&gt;

&lt;p&gt;Facebook 买了 Whatsapp。而帮 Facebook 挖了五年小溪的 Brian Acton ，正式成为 Facebook 的股东，正是那个当初拒绝他工作申请的 Facebook 。&lt;/p&gt;

&lt;p&gt;在他开挖之前（开 Whatsapp 公司之前），他曾经写下了这两条推特讯息：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Got denied by Twitter HQ. That’s ok. Would have been a long commute.&lt;/li&gt;
    &lt;li&gt;Facebook turned me down. It was a great opportunity to connect with some fantastic people. Looking forward to life’s next adventure.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;你觉得那 55 个人有需要去跟 Facebook 谈判，要 50 万美金的薪水吗？还是你觉得当那些人获利了结，要从 Facebook 出走时， Facebook 会砸下重金，并拿出股票来留人？&lt;/p&gt;

&lt;p&gt;二类劳工不会去比较，或是谈判薪水，因为他们不是在出卖他们的劳力给村庄（公司），他们卖的是被低估的财富，那些出价的村庄没有别的选择，只能拿出相对于这些财富的数字，这些二类劳工端出来的财富，可以让村庄与自己双双受益（你看看 Facebook 往上冲的股价就知道）。&lt;/p&gt;

&lt;p&gt;你可以想想，要卖掉你挖通的水源时，有没有哪个村庄愿意坐在谈判桌的另一边。当村庄决定买水的时候，薪水条中多出来的几个零，都不过是基本条件罢了。&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>Pig入门5h</title>
     <link href="http://ningg.github.com/use-pig"/>
     <updated>2014-05-10T00:00:00+08:00</updated>
     <id>http://ningg.github.com/use-pig</id>
     <content type="html">&lt;p&gt;&lt;strong&gt;致谢&lt;/strong&gt;：本篇博客转载至codelast的博客&lt;a href=&quot;http://www.codelast.com/?p=3621&quot;&gt;Apache Pig的一些基础概念及用法总结&lt;/a&gt; ；在此，对codelast致敬，其分享精神温暖人心。&lt;em&gt;(本文会在codelast原博客的基础上陆续做一些调整)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;下面开始学习Pig。&lt;/p&gt;

&lt;h2 id=&quot;pig&quot;&gt;Pig学习要点&lt;/h2&gt;

&lt;h3 id=&quot;section&quot;&gt;数据结构&lt;/h3&gt;

&lt;p&gt;数据结构，名字听起来好像很高大上，什么含义？其本质，是要表示数据是什么形式存储的，使用不同形式/结构存储的数据，在不同操作下的效率千差万别。&lt;/p&gt;

&lt;p&gt;关系（relation）、包（bag）、元组（tuple）、字段（field）、数据（data）的关系&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一个关系（relation）是一个包（bag），更具体地说，是一个外部的包（outer bag）。&lt;/li&gt;
  &lt;li&gt;一个包（bag）是一个元组（tuple）的集合。在pig中表示数据时，用大括号{}括起来的东西表示一个包——无论是在教程中的实例演示，还是在pig交互模式下的输出，都遵循这样的约定，请牢记这一点，因为不理解的话就会对数据结构的掌握产生偏差。&lt;/li&gt;
  &lt;li&gt;一个元组（tuple）是若干字段（field）的一个有序集合（ordered set）。在pig中表示数据时，用小括号()括起来的东西表示一个元组。&lt;/li&gt;
  &lt;li&gt;一个字段（field）是一块数据（data）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;针对上面几个概念，解释几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“元组”这个词很抽象，你可以把它想像成关系型数据库表中的一行，它含有一个或多个字段，其中，每一个字段可以是任何数据类型，并且可以有或者没有数据。&lt;/li&gt;
  &lt;li&gt;“关系”可以比喻成关系型数据库的一张表，而上面说了，“元组”可以比喻成数据表中的一行，那么这里有人要问了，在关系型数据库中，同一张表中的每一行都有固定的字段数，pig中的“关系”与“元组”之间，是否也是这样的情况呢？不是的。“关系”并不要求每一个“元组”都含有相同数量的字段，并且也不会要求各“元组”中在相同位置处的字段具有相同的数据类型（太随意了，是吧？）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-1&quot;&gt;一个实例&lt;/h3&gt;

&lt;p&gt;一个计算多维度组合下的平均值的实际例子&lt;/p&gt;

&lt;p&gt;为了帮助大家理解pig的一个基本的数据处理流程，我造了一些简单的数据来举个例子——
假设有数据文件：a.txt（各数值之间是以tab分隔的）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost pig]$ cat a.txt 
a 1 2 3 4.2 9.8
a 3 0 5 3.5 2.1
b 7 9 9 - -
a 7 9 9 2.6 6.2
a 1 2 5 7.7 5.9
a 1 2 3 1.4 0.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;问题如下：怎样求出在第2、3、4列的所有组合的情况下，最后两列的平均值分别是多少？
例如，第2、3、4列有一个组合为（1，2，3），即第一行和最后一行数据。对这个维度组合来说，最后两列的平均值分别为：
（4.2+1.4）/2＝2.8
（9.8+0.2）/2＝5.0
而对于第2、3、4列的其他所有维度组合，都分别只有一行数据，因此最后两列的平均值其实就是它们自身。
特别地，组合（7，9，9）有两行记录：第三、四行，但是第三行数据的最后两列没有值，因此它不应该被用于平均值的计算，也就是说，在计算平均值时，第三行是无效数据。所以（7，9，9）组合的最后两列的平均值为 2.6 和 6.2。
我们现在用pig来算一下，并且输出最终的结果。
先进入本地调试模式（pig -x local），再依次输入如下pig代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;a.txt&#39; AS (col1:chararray, col2:int, col3:int, col4:int, col5:double, col6:double);
B = GROUP A BY (col2, col3, col4);
C = FOREACH B GENERATE group, AVG(A.col5), AVG(A.col6);
DUMP C;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pig输出结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;((1,2,3),2.8,5.0)
((1,2,5),7.7,5.9)
((3,0,5),3.5,2.1)
((7,9,9),2.6,6.2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个结果对吗？手工算一下就知道是对的。&lt;/p&gt;

&lt;p&gt;下面，我们依次来看看每一句pig代码分别得到了什么样的数据。
①加载 a.txt 文件，并指定每一列的数据类型分别为 chararray（字符串），int，int，int，double，double。同时，我们还给予了每一列别名，分别为 col1，col2，……，col6。这个别名在后面的数据处理中会用到——如果你不指定别名，那么在后面的处理中，就只能使用索引（$0，$1，……）来标识相应的列了，这样可读性会变差，因此，在列固定的情况下，还是指定别名的好。
将数据加载之后，保存到变量A中，A的数据结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A: {col1: chararray,col2: int,col3: int,col4: int,col5: double,col6: double}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，A是用大括号括起来的东西。根据本文前面的说法，A是一个包（bag）。
这个时候，A与你想像中的样子应该是一致的，也就是与前面打印出来的 a.txt 文件的内容是一样的，还是一行一行的类似于“二维表”的数据。&lt;/p&gt;

&lt;p&gt;②按照A的第2、3、4列，对A进行分组。pig会找出所有第2、3、4列的组合，并按照升序进行排列，然后将它们与对应的包A整合起来，得到如下的数据结构：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;B: {group: (col2: int,col3: int,col4: int),A: {col1: chararray,col2: int,col3: int,col4: int,col5: double,col6: double}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，A的第2、3、4列的组合被pig赋予了一个别名：group，这很形象。同时我们也观察到，B的每一行其实就是由一个group和若干个A组成的——注意，是若干个A。这里之所以只显示了一个A，是因为这里表示的是数据结构，而不表示具体数据有多少组。
实际的数据为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;((1,2,3),{(a,1,2,3,4.2,9.8),(a,1,2,3,1.4,0.2)})
((1,2,5),{(a,1,2,5,7.7,5.9)})
((3,0,5),{(a,3,0,5,3.5,2.1)})
((7,9,9),{(b,7,9,9,,),(a,7,9,9,2.6,6.2)})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，与前面所说的一样，组合（1，2，3）对应了两行数据，组合（7，9，9）也对应了两行数据。
这个时候，B的结构就不那么明朗了，可能与你想像中有一点不一样了。&lt;/p&gt;

&lt;p&gt;③计算每一种组合下的最后两列的平均值。
根据上面得到的B的数据，你可以把B想像成一行一行的数据（只不过这些行不是对称的），FOREACH 的作用是对 B 的每一行数据进行遍历，然后进行计算。
GENERATE 可以理解为要生成什么样的数据，这里的 group 就是上一步操作中B的第一项数据（即pig为A的第2、3、4列的组合赋予的别名），所以它告诉了我们：在数据集 C 的每一行里，第一项就是B中的group——类似于（1，2，5）这样的东西）。
而 AVG(A.col5) 这样的计算，则是调用了pig的一个求平均值的函数 AVG，用于对 A 的名为 col5 的列求平均值。前文说了，在加载数据到A的时候，我们已经给每一列起了个别名，col5就是倒数第二列。
到这里，可能有人要迷糊了：难道 AVG(A.col5) 不是表示对 A 的col5这一列求平均值吗？也就是说，在遍历B（FOREACH B）的每一行时候，计算结果都是相同的啊！
事实上并不是这样。我们遍历的是B，我们需要注意到，B的数据结构中，每一行数据里，一个group对应的是若干个A，因此，这里的 A.col5，指的是B的每一行中的A，而不是包含全部数据的那个A。拿B的第一行来举例：
((1,2,3),{(a,1,2,3,4.2,9.8),(a,1,2,3,1.4,0.2)})
遍历到B的这一行时，要计算AVG(A.col5)，pig会找到 (a,1,2,3,4.2,9.8) 中的4.2，以及(a,1,2,3,1.4,0.2)中的1.4，加起来除以2，就得到了平均值。
同理，我们也知道了AVG(A.col6)是怎么算出来的。但还有一点要注意的：对(7,9,9)这个组，它对应的数据(b,7,9,9,,)里最后两列是无值的，这是因为我们的数据文件对应位置上不是有效数字，而是两个“-”，pig在加载数据的时候自动将它置为空了，并且计算平均值的时候，也不会把这一组数据考虑在内（相当于忽略这组数据的存在）。
到了这里，我们不难理解，为什么C的数据结构是这样的了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C: {group: (col2: int,col3: int,col4: int),double,double}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;④DUMP C就是将C中的数据输出到控制台。如果要输出到文件，需要使用：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;STORE C INTO &#39;output&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样pig就会在当前目录下新建一个“output”目录（该目录必须事先不存在），并把结果文件放到该目录下。&lt;/p&gt;

&lt;p&gt;请想像一下，如果要实现相同的功能，用Java或C++写一个Map-Reduce应用程序需要多少时间？可能仅仅是写一个build.xml或者Makefile，所需的时间就是写这段pig代码的几十倍了！
正因为pig有如此优势，它才得到了广泛应用。&lt;/p&gt;

&lt;p&gt;（3）怎样统计数据行数
在SQL语句中，要统计表中数据的行数，很简单：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT COUNT(*) FROM table_name WHERE condition
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在pig中，也有一个COUNT函数，在pig手册中，对COUNT函数有这样的说明：&lt;/p&gt;

&lt;p&gt;Computes the number of elements in a bag.
假设要计算数据文件a.txt的行数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost pig]$ cat a.txt 
a 1 2 3 4.2 9.8
a 3 0 5 3.5 2.1
b 7 9 9 - -
a 7 9 9 2.6 6.2
a 1 2 5 7.7 5.9
a 1 2 3 1.4 0.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;你是否可以这样做呢：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;a.txt&#39; AS (col1:chararray, col2:int, col3:int, col4:int, col5:double, col6:double);
B = COUNT(*);
DUMP B;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;答案是：绝对不行。pig会报错。pig手册中写得很明白：&lt;/p&gt;

&lt;p&gt;Note: You cannot use the tuple designator (&lt;em&gt;) with COUNT; that is, COUNT(&lt;/em&gt;) will not work.
那么，这样对某一列计数行不行呢：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;B = COUNT(A.col2);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;答案是：仍然不行。pig会报错。
这就与我们想像中的“正确做法”有点不一样了：我为什么不能直接统计一个字段的数目有多少呢？刚接触pig的时候，一定非常疑惑这样明显“不应该出错”的写法为什么行不通。
要统计A中含col2字段的数据有多少行，正确的做法是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;a.txt&#39; AS (col1:chararray, col2:int, col3:int, col4:int, col5:double, col6:double);
B = GROUP A ALL;
C = FOREACH B GENERATE COUNT(A.col2);
DUMP C;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果：&lt;/p&gt;

&lt;p&gt;(6)
表明有6行数据。
如此麻烦？没错。这是由pig的数据结构决定的。&lt;/p&gt;

&lt;p&gt;在这个例子中，统计COUNT(A.col2)和COUNT(A)的结果是一样的，但是，如果col2这一列中含有空值：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost pig]$ cat a.txt 
a 1 2 3 4.2 9.8
a   0 5 3.5 2.1
b 7 9 9 - -
a 7 9 9 2.6 6.2
a 1 2 5 7.7 5.9
a 1 2 3 1.4 0.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;则以下pig程序及执行结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;a.txt&#39; AS (col1:chararray, col2:int, col3:int, col4:int, col5:double, col6:double);
grunt&amp;gt; B = GROUP A ALL;
grunt&amp;gt; C = FOREACH B GENERATE COUNT(A.col2);
grunt&amp;gt; DUMP C;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(5)
可见，结果为5行。那是因为你LOAD数据的时候指定了col2的数据类型为int，而a.txt的第二行数据是空的，因此数据加载到A以后，有一个字段就是空的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; DUMP A;
(a,1,2,3,4.2,9.8)
(a,,0,5,3.5,2.1)
(b,7,9,9,,)
(a,7,9,9,2.6,6.2)
(a,1,2,5,7.7,5.9)
(a,1,2,3,1.4,0.2) 在COUNT的时候，null的字段不会被计入在内，所以结果是5。
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
  &lt;p&gt;The COUNT function follows syntax semantics and ignores nulls. What this means is that a tuple in the bag will not be counted if the first field in this tuple is NULL. If you want to include NULL values in the count computation, use COUNT_STAR.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;（4）FLATTEN操作符的作用
这个玩意一开始还是挺让我费解的。从字面上看，flatten就是“弄平”的意思，但是在对一个pig的数据结构操作时，flatten到底是“弄平”了什么，又有什么作用呢？
我们还是采用前面的a.txt数据文件来说明：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost pig]$ cat a.txt 
a 1 2 3 4.2 9.8
a 3 0 5 3.5 2.1
b 7 9 9 - -
a 7 9 9 2.6 6.2
a 1 2 5 7.7 5.9
a 1 2 3 1.4 0.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果我们按照前文的做法，计算多维度组合下的最后两列的平均值，则：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;a.txt&#39; AS (col1:chararray, col2:int, col3:int, col4:int, col5:double, col6:double);
grunt&amp;gt; B = GROUP A BY (col2, col3, col4);
grunt&amp;gt; C = FOREACH B GENERATE group, AVG(A.col5), AVG(A.col6);
grunt&amp;gt; DUMP C;
((1,2,3),2.8,5.0)
((1,2,5),7.7,5.9)
((3,0,5),3.5,2.1)
((7,9,9),2.6,6.2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，输出结果中，每一行的第一项是一个tuple（元组），我们来试试看 FLATTEN 的作用：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;a.txt&#39; AS (col1:chararray, col2:int, col3:int, col4:int, col5:double, col6:double);
grunt&amp;gt; B = GROUP A BY (col2, col3, col4);
grunt&amp;gt; C = FOREACH B GENERATE FLATTEN(group), AVG(A.col5), AVG(A.col6);
grunt&amp;gt; DUMP C;
(1,2,3,2.8,5.0)
(1,2,5,7.7,5.9)
(3,0,5,3.5,2.1)
(7,9,9,2.6,6.2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看到了吗？被 FLATTEN 的group本来是一个元组，现在变成了扁平的结构了。按照pig文档的说法，FLATTEN用于对元组（tuple）和包（bag）“解嵌套”（un-nest）：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The FLATTEN operator looks like a UDF syntactically, but it is actually an operator that changes the structure of tuples and bags in a way that a UDF cannot. Flatten un-nests tuples as well as bags. The idea is the same, but the operation and result is different for each type of structure.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;For tuples, flatten substitutes the fields of a tuple in place of the tuple. For example, consider a relation that has a tuple of the form (a, (b, c)). The expression GENERATE $0, flatten($1), will cause that tuple to become (a, b, c).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;所以我们就看到了上面的结果。
在有的时候，不“解嵌套”的数据结构是不利于观察的，输出这样的数据可能不利于外围数程序的处理（例如，pig将数据输出到磁盘后，我们还需要用其他程序做后续处理，而对一个元组，输出的内容里是含括号的，这就在处理流程上又要多一道去括号的工序），因此，FLATTEN提供了一个让我们在某些情况下可以清楚、方便地分析数据的机会。&lt;/p&gt;

&lt;p&gt;（5）关于GROUP操作符
在上文的例子中，已经演示了GROUP操作符会生成什么样的数据。在这里，需要说得更理论一些：&lt;/p&gt;

&lt;p&gt;用于GROUP的key如果多于一个字段（正如本文前面的例子），则GROUP之后的数据的key是一个元组（tuple），否则它就是与用于GROUP的key相同类型的东西。
GROUP的结果是一个关系（relation），在这个关系中，每一组包含一个元组（tuple），这个元组包含两个字段：（1）第一个字段被命名为“group”——这一点非常容易与GROUP关键字相混淆，但请区分开来。该字段的类型与用于GROUP的key类型相同。（2）第二个字段是一个包（bag），它的类型与被GROUP的关系的类型相同。&lt;/p&gt;

&lt;p&gt;（6）把数据当作“元组”（tuple）来加载
还是假设有如下数据：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost pig]$ cat a.txt 
a 1 2 3 4.2 9.8
a 3 0 5 3.5 2.1
b 7 9 9 - -
a 7 9 9 2.6 6.2
a 1 2 5 7.7 5.9
a 1 2 3 1.4 0.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果我们按照以下方式来加载数据：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;a.txt&#39; AS (col1:chararray, col2:int, col3:int, col4:int, col5:double, col6:double); 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么得到的A的数据结构为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; DESCRIBE A;
A: {col1: chararray,col2: int,col3: int,col4: int,col5: double,col6: double}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你要把A当作一个元组（tuple）来加载：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;a.txt&#39; AS (T : tuple (col1:chararray, col2:int, col3:int, col4:int, col5:double, col6:double));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是想要得到这样的数据结构：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; DESCRIBE A;
A: {T: (col1: chararray,col2: int,col3: int,col4: int,col5: double,col6: double)}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么，上面的方法将得到一个空的A：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; DUMP A;
()
()
()
()
()
()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那是因为数据文件a.txt的结构不适合于这样加载成元组（tuple）。&lt;/p&gt;

&lt;p&gt;如果有数据文件b.txt：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost pig]$ cat b.txt 
(a,1,2,3,4.2,9.8)
(a,3,0,5,3.5,2.1)
(b,7,9,9,-,-)
(a,7,9,9,2.6,6.2)
(a,1,2,5,7.7,5.9)
(a,1,2,3,1.4,0.2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;则使用上面所说的加载方法及结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;b.txt&#39; AS (T : tuple (col1:chararray, col2:int, col3:int, col4:int, col5:double, col6:double));
grunt&amp;gt; DUMP A;
((a,1,2,3,4.2,9.8))
((a,3,0,5,3.5,2.1))
((b,7,9,9,,))
((a,7,9,9,2.6,6.2))
((a,1,2,5,7.7,5.9))
((a,1,2,3,1.4,0.2))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，加载的数据的结构确实被定义成了元组（tuple）。&lt;/p&gt;

&lt;p&gt;（7）在多维度组合下，如何计算某个维度组合里的不重复记录的条数
以数据文件 c.txt 为例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost pig]$ cat c.txt 
a 1 2 3 4.2 9.8 100
a 3 0 5 3.5 2.1 200
b 7 9 9 - - 300
a 7 9 9 2.6 6.2 300
a 1 2 5 7.7 5.9 200
a 1 2 3 1.4 0.2 500
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;问题：如何计算在第2、3、4列的所有维度组合下，最后一列不重复的记录分别有多少条？例如，第2、3、4列有一个维度组合是（1，2，3），在这个维度维度下，最后一列有两种值：100 和 500，因此不重复的记录数为2。同理可求得其他的记录条数。
pig代码及输出结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;c.txt&#39; AS (col1:chararray, col2:int, col3:int, col4:int, col5:double, col6:double, col7:int);
grunt&amp;gt; B = GROUP A BY (col2, col3, col4);
grunt&amp;gt; C = FOREACH B {D = DISTINCT A.col7; GENERATE group, COUNT(D);};
grunt&amp;gt; DUMP C;
((1,2,3),2)
((1,2,5),1)
((3,0,5),1)
((7,9,9),1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们来看看每一步分别生成了什么样的数据：
①LOAD不用说了，就是加载数据；
②GROUP也不用说了，和前文所说的一样。GROUP之后得到了这样的数据：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; DUMP B;
((1,2,3),{(a,1,2,3,4.2,9.8,100),(a,1,2,3,1.4,0.2,500)})
((1,2,5),{(a,1,2,5,7.7,5.9,200)})
((3,0,5),{(a,3,0,5,3.5,2.1,200)})
((7,9,9),{(b,7,9,9,,,300),(a,7,9,9,2.6,6.2,300)})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实到这里，我们肉眼就可以看出来最后要求的结果是什么了，当然，必须要由pig代码来完成，要不然怎么应对海量数据？&lt;/p&gt;

&lt;p&gt;③这里的 FOREACH 与前面有点不一样，这就是所谓的“嵌套的FOREACH”。第一次看到这种写法，肯定会觉得很奇怪。先看一下用于去重的DISTINCT关键字的说明：&lt;/p&gt;

&lt;p&gt;Removes duplicate tuples in a relation.
然后再解释一下：FOREACH 是对B的每一行进行遍历，其中，B的每一行里含有一个包（bag），每一个包中含有若干元组（tuple）A，因此，FOREACH 后面的大括号里的操作，其实是对所谓的“内部包”（inner bag）的操作（详情请参看FOREACH的说明），在这里，我们指定了对A的col7这一列进行去重，去重的结果被命名为D，然后再对D计数（COUNT），就得到了我们想要的结果。
④输出结果数据，与前文所述的差不多。
这样就达成了我们的目的。从总体上说，刚接触pig不久的人会觉得这些写法怪怪的，就是扭不过来，但是要坚持，时间长了，连倒影也会让你觉得是正的了。&lt;/p&gt;

&lt;p&gt;（8）如何将关系（relation）转换为标量（scalar）
在前文中，我们要统计符合某些条件的数据的条数，使用了COUNT函数来计算，但在COUNT之后，我们得到的还是一个关系（relation），而不是一个标量的数字，如何把一个关系转换为标量，从而可以在后续处理中便于使用呢？
具体请看这个链接。&lt;/p&gt;

&lt;p&gt;（9）pig中如何使用shell进行辅助数据处理
pig中可以嵌套使用shell进行辅助处理，下面，就以一个实际的例子来说明。
假设我们在某一步pig处理后，得到了类似于下面 b.txt 中的数据：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost pig]$ cat b.txt 
1 5 98  = 7
34  8 6 3 2
62  0 6 = 65
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;问题：如何将数据中第4列中的“=”符号全部替换为9999？
pig代码及输出结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;b.txt&#39; AS (col1:int, col2:int, col3:int, col4:chararray, col5:int);
grunt&amp;gt; B = STREAM A THROUGH `awk &#39;{if($4 == &quot;=&quot;) print $1&quot;\t&quot;$2&quot;\t&quot;$3&quot;\t9999\t&quot;$5; else print $0}&#39;`;
grunt&amp;gt; DUMP B;
(1,5,98,9999,7)
(34,8,6,3,2)
(62,0,6,9999,65)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们来看看这段代码是如何做到的：
①加载数据，这个没什么好说的。
②通过“STREAM … THROUGH …”的方式，我们可以调用一个shell语句，用该shell语句对A的每一行数据进行处理。此处的shell逻辑为：当某一行数据的第4列为“=”符号时，将其替换为“9999”；否则就照原样输出这一行。
③输出B，可见结果正确。&lt;/p&gt;

&lt;p&gt;（10）向pig脚本中传入参数
假设你的pig脚本输出的文件是通过外部参数指定的，则此参数不能写死，需要传入。在pig中，使用传入的参数如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;STORE A INTO &#39;$output_dir&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;则这个“output_dir”就是个传入的参数。在调用这个pig脚本的shell脚本中，我们可以这样传入参数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pig -param output_dir=&quot;/home/my_ourput_dir/&quot; my_pig_script.pig
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里传入的参数“output_dir”的值为“/home/my_output_dir/”。&lt;/p&gt;

&lt;p&gt;（11）就算是同样一段pig代码，多次计算所得的结果也有可能是不同的
例如用AVG函数来计算平均值时，同样一段pig代码，多次计算所得的结果中，小数点的最后几位也有可能是不相同的（当然也有可能相同），大概是因为精度的原因吧。不过，一般来说小数点的最后几位已经不重要了。例如我对一个数据集进行处理后，小数点后13位才开始有不同，这样的精度完全足够了。&lt;/p&gt;

&lt;p&gt;（12）如何编写及使用自定义函数（UDF）
请看这个链接：《Apache Pig中文教程（进阶）》&lt;/p&gt;

&lt;p&gt;（13）什么是聚合函数（Aggregate Function）
在pig中，聚合函数就是那些接受一个输入包（bag），返回一个标量（scalar）值的函数。COUNT函数就是一个例子。&lt;/p&gt;

&lt;p&gt;（14）COGROUP做了什么
与GROUP操作符一样，COGROUP也是用来分组的，不同的是，COGROUP可以按多个关系中的字段进行分组。
还是以一个实例来说明，假设有以下两个数据文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost pig]$ cat a.txt 
uidk  12  3
hfd 132 99
bbN 463 231
UFD 13  10
 
[root@localhost pig]$ cat b.txt 
908 uidk  888
345 hfd 557
28790 re  00000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在我们用pig做如下操作及得到的结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;a.txt&#39; AS (acol1:chararray, acol2:int, acol3:int);
grunt&amp;gt; B = LOAD &#39;b.txt&#39; AS (bcol1:int, bcol2:chararray, bcol3:int);
grunt&amp;gt; C = COGROUP A BY acol1, B BY bcol2;
grunt&amp;gt; DUMP C;
(re,{},{(28790,re,0)})
(UFD,{(UFD,13,10)},{})
(bbN,{(bbN,463,231)},{})
(hfd,{(hfd,132,99)},{(345,hfd,557)})
(uidk,{(uidk,12,3)},{(908,uidk,888)})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每一行输出的第一项都是分组的key，第二项和第三项分别都是一个包（bag），其中，第二项是根据前面的key找到的A中的数据包，第三项是根据前面的key找到的B中的数据包。
来看看第一行输出：“re”作为group的key时，其找不到对应的A中的数据，因此第二项就是一个空的包“{}”，“re”这个key在B中找到了对应的数据（28790    re    00000），因此第三项就是包{(28790,re,0)}。
其他输出数据也类似。&lt;/p&gt;

&lt;p&gt;（15）安装pig后，运行pig命令时提示“Cannot find hadoop configurations in classpath”等错误的解决办法
pig安装好后，运行pig命令时提示以下错误：&lt;/p&gt;

&lt;p&gt;ERROR org.apache.pig.Main - ERROR 4010: Cannot find hadoop configurations in classpath (neither hadoop-site.xml nor core-site.xml was found in the classpath).If you plan to use local mode, please put -x local option in command line
显而易见，提示找不到与hadoop相关的配置文件。所以我们需要把hadoop安装目录下的“conf”子目录添加到系统环境变量PATH中：
修改 /etc/profile 文件，添加：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export HADOOP_HOME=/usr/local/hadoop
export PIG_CLASSPATH=$HADOOP_HOME/conf
 
PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$PIG_CLASSPATH:$PATH
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后重新加载 /etc/profile 文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;source /etc/profile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;（16）piggybank是什么东西&lt;/p&gt;

&lt;p&gt;Pig also hosts a UDF repository called piggybank that allows users to share UDFs that they have written.
说白了就是Apache把大家写的自定义函数放在一块儿，起了个名字，就叫做piggybank。你可以把它理解为一个SVN代码仓库。具体请看这里。&lt;/p&gt;

&lt;p&gt;（17）UDF的构造函数会被调用几次
你可能会想在UDF的构造函数中做一些初始化的工作，例如创建一些文件，等等。但是你不能假设UDF的构造函数只被调用一次，因此，如果你要在构造函数中做一些只能做一次的工作，你就要当心了——可能会导致错误。&lt;/p&gt;

&lt;p&gt;（18）LOAD数据时，如何一次LOAD多个目录下的数据
例如，我要LOAD两个HDFS目录下的数据：/abc/2010 和 /abc/2011，则我们可以这样写LOAD语句：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;/abc/201{0,1}&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;（19）怎样自己写一个UDF中的加载函数(load function)
请看这个链接：《Apache Pig中文教程（进阶）》&lt;/p&gt;

&lt;p&gt;（20）重载(overloading)一个UDF
请看这个链接：《Apache Pig中文教程（进阶）》。&lt;/p&gt;

&lt;p&gt;（21）pig运行不起来，提示“org.apache.hadoop.ipc.Client - Retrying connect to server: 
请看这个链接：《Apache Pig中文教程（进阶）》&lt;/p&gt;

&lt;p&gt;（22）用含有null的字段来GROUP，结果会如何
假设有数据文件 a.txt 内容为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1 2 5
1   3
1 3 
6 9 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，每两列数据之间是用tab分割的，第二行的第2列、第三行的第3列没有内容（也就是说，加载到Pig里之后，对应的数据会变成null），如果把这些数据按第1、第2列来GROUP的话，第1、2列中含有null的行会被忽略吗？
来做一下试验：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;a.txt&#39; AS (col1:int, col2:int, col3:int);
B = GROUP A BY (col1, col2);
DUMP B;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;((1,2),{(1,2,5)})
((1,3),{(1,3,)})
((1,),{(1,,3)})
((6,9),{(6,9,8)})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的结果（第三行）可见，原数据中第1、2列里含有null的行也被计入在内了，也就是说，GROUP操作是不会忽略null的，这与COUNT有所不同（见本文前面的部分）。&lt;/p&gt;

&lt;p&gt;（23）如何统计数据中某些字段的组合有多少种
假设有如下数据：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost]# cat a.txt 
1 3 4 7
1 3 5 4
2 7 0 5
9 8 6 6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在我们要统计第1、2列的不同组合有多少种，对本例来说，组合有三种：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1 3
2 7
9 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是说我们要的答案是3。
用Pig怎么计算？&lt;/p&gt;

&lt;p&gt;先写出全部的Pig代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;a.txt&#39; AS (col1:int, col2:int, col3:int, col4:int);
B = GROUP A BY (col1, col2); 
C = GROUP B ALL;
D = FOREACH C GENERATE COUNT(B); 
DUMP D;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后再来看看这些代码是如何计算出上面的结果的：
①第一行代码加载数据，没什么好说的。
②第二行代码，得到第1、2列数据的所有组合。B的数据结构为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; DESCRIBE B;
B: {group: (col1: int,col2: int),A: {col1: int,col2: int,col3: int,col4: int}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;把B DUMP出来，得到：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;((1,3),{(1,3,4,7),(1,3,5,4)})
((2,7),{(2,7,0,5)})
((9,8),{(9,8,6,6)})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;非常明显，(1,3)，(2,7)，(9,8)的所有组合已经被排列出来了，这里得到了若干行数据。下一步我们要做的就是统计这样的数据一共有多少行，也就得到了第1、2列的组合有多少组。
③第三和第四行代码，就实现了统计数据行数的功能。参考本文前面部分的“怎样统计数据行数”一节。就明白这两句代码是什么意思了。
这里需要特别说明的是：
a)为什么倒数第二句代码中是COUNT(B)，而不是COUNT(group)？
我们是对C进行FOREACH，所以要先看看C的数据结构：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; DESCRIBE C;
C: {group: chararray,B: {group: (col1: int,col2: int),A: {col1: int,col2: int,col3: int,col4: int}}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，你可以把C想像成一个map的结构，key是一个group，value是一个包（bag），它的名字是B，这个包中有N个元素，每一个元素都对应到②中所说的一行。根据②的分析，我们就是要统计B中元素的个数，因此，这里当然就是COUNT(B)了。
b)COUNT函数的作用是统计一个包（bag）中的元素的个数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;COUNT
Computes the number of elements in a bag.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从C的数据结构看，B是一个bag，所以COUNT函数是可以用于它的。
如果你试图把COUNT应用于一个非bag的数据结构上，会发生错误，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;java.lang.ClassCastException: org.apache.pig.data.BinSedesTuple cannot be cast to org.apache.pig.data.DataBag
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是把Tuple传给COUNT函数时发生的错误。&lt;/p&gt;

&lt;p&gt;（24）两个整型数相除，如何转换为浮点型，从而得到正确的结果
这个问题其实很傻，或许不用说你也知道了：假设有int a = 3 和 int b = 2两个数，在大多数编程语言里，a/b得到的是1，想得到正确结果1.5的话，需要转换为float再计算。在Pig中其实和这种情况一样，下面就拿几行数据来做个实验：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat a.txt 
3 2
4 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在Pig中：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;a.txt&#39; AS (col1:int, col2:int);                  
grunt&amp;gt; B = FOREACH A GENERATE col1/col2;
grunt&amp;gt; DUMP B;
(1)
(0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，不加类型转换的计算结果是取整之后的值。
那么，转换一下试试：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;a.txt&#39; AS (col1:int, col2:int);
grunt&amp;gt; B = FOREACH A GENERATE (float)(col1/col2);
grunt&amp;gt; DUMP B;
(1.0)
(0.0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样转换还是不行的，这与大多数编程语言的结果一致——它只是把取整之后的数再转换为浮点数，因此当然是不行的。&lt;/p&gt;

&lt;p&gt;正确的做法应该是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;a.txt&#39; AS (col1:int, col2:int); 
grunt&amp;gt; B = FOREACH A GENERATE (float)col1/col2;  
grunt&amp;gt; DUMP B;
(1.5)
(0.8)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;或者这样也行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;a.txt&#39; AS (col1:int, col2:int);
grunt&amp;gt; B = FOREACH A GENERATE col1/(float)col2;       
grunt&amp;gt; DUMP B;
(1.5)
(0.8)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这与我们的通常做法是一致的，因此，你要做除法运算的时候，需要注意这一点。&lt;/p&gt;

&lt;p&gt;（25）UNION的一个例子
假设有两个数据文件为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat 1.txt 
0 3
1 5
0 8
 
[root@localhost ~]# cat 2.txt 
1 6
0 9
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在要求出：在第一列相同的情况下，第二列的和分别为多少？
例如，第一列为 1 的时候，第二列有5和6两个值，和为11。同理，第一列为0的时候，第二列的和为 3+8+9=20。
计算此问题的Pig代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (a: int, b: int); 
B = LOAD &#39;2.txt&#39; AS (c: int, d: int); 
C = UNION A, B;
D = GROUP C BY $0; 
E = FOREACH D GENERATE FLATTEN(group), SUM(C.$1);
DUMP E;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(0,20)
(1,11)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们来看看每一步分别做了什么：
①第1行、第2行代码分别加载数据到关系A、B中，没什么好说的。
②第3行代码，将关系A、B合并起来了。合并后的数据结构为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; DESCRIBE C;
C: {a: int,b: int}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其数据为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; DUMP C;
(0,3)
(1,5)
(0,8)
(1,6)
(0,9)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;③第4行代码按第1列（即$0）进行分组，分组后的数据结构为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; DESCRIBE D;
D: {group: int,C: {a: int,b: int}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其数据为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; DUMP D;
(0,{(0,9),(0,3),(0,8)})
(1,{(1,5),(1,6)})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;④最后一行代码，遍历D，将D中每一行里的所有bag(即C)的第2列(即$1)进行累加，就得到了我们要的结果。&lt;/p&gt;

&lt;p&gt;（26）错误“ERROR org.apache.pig.tools.grunt.Grunt - ERROR 2042: Error in new logical plan. Try -Dpig.usenewlogicalplan=false.”的可能原因
①Pig的bug，详见此链接；
②其他原因。我遇到并解决了一例。具体的代码不便在此陈列，但是基本可以说是由于自己写的Pig代码对复杂数据结构的处理不当导致的，后来我尝试更改了一种实现方式，就绕过了这个问题。关于这点，确实还是要具体问题具体分析的，在这里没有实例的话，无法给大家一个明确的解决问题的指南。&lt;/p&gt;

&lt;p&gt;（27）如何在Pig中使用正则表达式对字符串进行匹配
假设你有如下数据文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat a.txt 
1 http://ui.qq.com/abcd.html
5 http://tr.qq.com/743.html
8 http://vid.163.com/trees.php
9 http:auto.qq.com/us.php
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在要找出该文件中，第二列符合“&lt;em&gt;//&lt;/em&gt;.qq.com/*”模式的所有行（此处只有前两行符合条件），怎么做？
Pig代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;a.txt&#39; AS (col1: int, col2: chararray);
B = FILTER A BY col2 matches &#39;.*//.*\\.qq\\.com/.*&#39;;  
DUMP B;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们看到，matches关键字对 col2 进行了正则匹配，它使用的是Java格式的正则表达式匹配规则。
. 表示任意字符，* 表示字符出现任意次数；. 对 . 进行了转义，表示匹配 . 这个字符；/ 就是表示匹配 / 这个字符。
这里需要注意的是，在引号中，用于转义的字符 \ 需要打两个才能表示一个，所以上面的 \. 就是与正则中的 . 是一样的，即匹配 . 这个字符。所以，如果你要匹配数字的话，应该用这种写法（\d表示匹配数字，在引号中必须用\d）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;B = FILTER A BY (col matches &#39;\\d.*&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后输出结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(1,http://ui.qq.com/abcd.html)
(5,http://tr.qq.com/743.html)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见结果是正确的。&lt;/p&gt;

&lt;p&gt;（28）如何截取一个字符串中的某一段
在处理数据时，如果你想提取出一个日期字符串的年份，例如提取出“2011-10-26”中的“2011”，可以用内置函数 SUBSTRING 来实现：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SUBSTRING
Returns a substring from a given string.
Syntax
SUBSTRING(string, startIndex, stopIndex)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面举一个例子。假设有数据文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat a.txt 
2010-05-06  abc
2008-06-18  uio
2011-10-11  tyr
2010-12-23  fgh
2011-01-05  vbn
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一列是日期，现在要找出所有不重复的年份有哪些，可以这样做：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;a.txt&#39; AS (dateStr: chararray, flag: chararray);
B = FOREACH A GENERATE SUBSTRING(dateStr, 0, 4);
C = DISTINCT B;
DUMP C;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(2008)
(2010)
(2011)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见达到了我们想要的效果。
上面的代码太简单了，不必多言，唯一需要说明一下的是 SUBSTRING 函数，它的第一个参数是要截取的字符串，第二个参数是起始索引（从0开始），第三个参数是结束索引。&lt;/p&gt;

&lt;p&gt;（29）如何拼接两个字符串
假设有以下数据文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat 1.txt 
abc 123
cde 456
fgh 789
ijk 200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在要把第一列和第二列作为字符串拼接起来，例如第一行会变成“abc123”，那么使用CONCAT这个求值函数（eval function）就可以做到：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (col1: chararray, col2: int);
B = FOREACH A GENERATE CONCAT(col1, (chararray)col2);
DUMP B;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(abc123)
(cde456)
(fgh789)
(ijk200)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意这里故意在加载数据的时候把第二列指定为int类型，这是为了说明数据类型不一致的时候CONCAT会出错（你可以试验一下）：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1045: Could not infer the matching function for org.apache.pig.builtin.CONCAT as multiple or none of them fit. Please use an explicit cast.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;所以在后面CONCAT的时候，对第二列进行了类型转换。
另外，如果数据文件内容为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat 1.txt 
5 123
7 456
8 789
0 200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么，如果对两列整数CONCAT：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (col1: int, col2: int);
B = FOREACH A GENERATE CONCAT(col1, col2);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同样也会出错：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1045: Could not infer the matching function for org.apache.pig.builtin.CONCAT as multiple or none of them fit. Please use an explicit cast.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;要注意这一点。
有人可能会问：要拼接几个字符串的话怎么办？CONCAT 套 CONCAT 就要可以了（有点笨，但管用）： CONCAT(a, CONCAT(b, c))&lt;/p&gt;

&lt;p&gt;（30）如何求两个数据集的重合 &amp;amp; 不同的数据类型JOIN会失败
假设有以下两个数据文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat 1.txt 
123
456
789
200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以及：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat 2.txt 
200
333
789
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在要找出两个文件中，相同的数据有多少行，怎么做？这也就是所谓的求两个数据集的重合。
用关系操作符JOIN，我们可以达到这个目的。在处理海量数据时，经常会有求重合的需求。所以JOIN是Pig中一个极其重要的操作。
在本例中，两个文件中有两个相同的数据行：789以及200，因此，结果应该是2。
我们先来看看正确的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (a: int);   
B = LOAD &#39;2.txt&#39; AS (b: int);
C = JOIN A BY a, B BY b;
D = GROUP C ALL;
E = FOREACH D GENERATE COUNT(C);
DUMP E;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;解释一下：
①第一、二行是加载数据，不必多言。
②第三行按A的第1列、B的第二列进行“结合”，JOIN之后，a、b两列不相同的数据就被剔除掉了。C的数据结构为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C: {A::a: int,B::b: int}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;C的数据为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(200,200)
(789,789)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;③由于我们要统计的是数据行数，所以上面的Pig代码中的第4、5行就进行了计数的运算。
④如果文件 2.txt 多一行数据“200”，结果会是什么？答案是：结果为3行。这个时候C的数据为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(200,200)
(200,200)
(789,789)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;所以如果你要去除重复的，还需要用DISTINCE对C处理一下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (a: int);
B = LOAD &#39;2.txt&#39; AS (b: int);
C = JOIN A BY a, B BY b;
uniq_C = DISTINCT C;
D = GROUP uniq_C ALL;
E = FOREACH D GENERATE COUNT(uniq_C);
DUMP E;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样得到的结果就是2了。&lt;/p&gt;

&lt;p&gt;尤其需要注意的是，如果JOIN的两列具有不同的数据类型，是会失败的。例如以下代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (a: int);   
B = LOAD &#39;2.txt&#39; AS (b: chararray);
C = JOIN A BY a, B BY b;
D = GROUP C ALL;
E = FOREACH D GENERATE COUNT(C);
DUMP E;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在语法上是没有错误的，但是一运行就会报错：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1107: Cannot merge join keys, incompatible types&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这是因为a、b具有不同的类型：int和chararray。
（31）使用三目运算符“ ? : ”有时候必须加括号
假设有以下数据文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat a.txt 
5 8 9
6   0
4 3 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，第二行的第二列数据是有缺失的，因此，加载数据之后，它会成为null。顺便废话一句，在处理海量数据时，数据有缺失是经常遇到的现象。
现在，我们如果要把所有缺失的数据填为 -1， 可以使用三目运算符来操作：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;a.txt&#39; AS (col1:int, col2:int, col3:int);
B = FOREACH A GENERATE col1, ((col2 is null)? -1 : col2), col3;
DUMP B;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(5,8,9)
(6,-1,0)
(4,3,1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;((col2 is null)? -1 : col2) 的含义不用解释你也知道，就是当col2为null的时候将其置为-1，否则就保持原来的值，但是注意，它最外面是用括号括起来的，如果去掉括号，写成 (col2 is null)? -1 : col2，那么就会有语法错误：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1000: Error during parsing. Encountered “ “is” “is “” at line 1, column 36.
Was expecting one of （后面省略）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;错误提示有点不直观。所以，有时候使用三目运算符是必须要使用括号的。
（32）如何补上缺失的数据
通过前面的文章，我们已经知道了如何按自己的需求补上缺失的数据，那么这里还有一个例子，可以让你多了解一些特殊的情况。
数据文件如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat 1.txt 
1 (4,9)
5 
8 (3,0)
5 (9,2)
6 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这些数据的布局比较怪，我们要把它加载成什么样的schema呢？答：第一列为一个int，第二列为一个tuple，此tuple又含两个int。加载成这样的模式不是为了制造复杂度，而是为了说明后面的问题而设计的。
同时，我们也注意到，第二列数据是有缺失的。
问题：怎样求在第一列数据相同的情况下，第二列数据中的第一个整数的和分别为多少？
例如，第一列为1的数据只有一行（即第一行），因此，第二列的第一个整数的和就是4。
但是对最后一行，也就是第一列为6时，由于其第二列数据缺失，我们希望它输出的结果是0。
先来看看Pig代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (a:int, b:tuple(x:int, y:int));
B = FOREACH A GENERATE a, FLATTEN(b);
C = GROUP B BY a;
D = FOREACH C GENERATE group, SUM(B.x);
DUMP D;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(1,4)
(5,9)
(6,)
(8,3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们注意到，(5,9) 这一行是由数据文件 1.txt 的第 2、4行计算得到的，其中，第2行数据有缺失，但这并不影响求和计算，因为另一行数据没有缺失。你可以这样想：一个包（bag）中有多个数，当其中一个为null，而其他不为null时，把它们相加会自动忽略null。
然而，第三行 (6,) 是不是太刺眼了？没错，因为数据文件 1.txt 的最后一行缺失了第二列，所以，在 SUM(B.x) 中的 B.x 为null就会导致计算结果为null，从而什么也输出不了。
这就与我们期望的输出有点不同了。我们希望这种缺失的数据不要空着，而是输出0。该怎么做呢？&lt;/p&gt;

&lt;p&gt;想法1：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;D = FOREACH C GENERATE group, ((IsEmpty(B.x)) ? 0 : SUM(B.x));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(1,4)
(5,9)
(6,)
(8,3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见行不通。从这个结果我们知道，IsEmpty(B.x) 为false，即B.x不是empty的，所以不能这样做。
想法2：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;D = FOREACH C GENERATE group, ((B.x is null) ? 0 : SUM(B.x));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果还是与上面一样！仍然行不通。这更奇怪了：B.x既非empty，也非null，那么它是什么情况？按照我的理解，当group为6时，它应该是一个非空的包（bag），里面有一个null的东西，所以，这个包不是empty的，它也非null。我不知道这样理解是否正确，但是它看上去就像是这样的。
想法3：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;D = FOREACH C GENERATE group, SUM(B.x) AS s;
E = FOREACH D GENERATE group, ((s is null) ? -1 : s);
DUMP E;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(1,4)
(5,9)
(6,-1)
(8,3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见达到了我们想要的结果。这与本文前面部分的做法是一致的，即：先得到含null的结果，再把这个结果中的null替换为指定的值。
有人会问：就没有办法在生成数据集D的时候，就直接通过判断语句来实现这个效果吗？据我目前所知是不行的，如果哪位读者知道，不妨告知。&lt;/p&gt;

&lt;p&gt;（33）DISTINCT操作用于去重，正因为它要把数据集合到一起，才知道哪些数据是重复的，因此，它会产生reduce过程。同时，在map阶段，它也会利用combiner来先去除一部分重复数据以加快处理速度。&lt;/p&gt;

&lt;p&gt;（34）如何将Pig job的优先级设为HIGH
嫌Pig job运行太慢？只需在Pig脚本的开头加上一句：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;set job.priority HIGH;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;即可将Pig job的优先级设为高了。&lt;/p&gt;

&lt;p&gt;（35）“Scalars can be only used with projections”错误的原因
这个错误提示比较不直观，光看这句话是不容易发现错误所在的，但是，只要你一Google，可能就找到原因了，例如这个链接里的反馈。
在这里，我也想用一个简单的例子给大家用演示一下产生这个错误的原因之一。
假设有如下数据文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]$ cat 1.txt 
a 1
b 8
c 3
c 3
d 6
d 3
c 5
e 7
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在要统计：在第1列的每一种组合下，第二列为3和6的数据分别有多少条？
例如，当第1列为 c 时，第二列为3的数据有2条，为6的数据有0条；当第1列为d时，第二列为3的数据有1条，为6的数据有1条。其他的依此类推。
Pig代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (col1:chararray, col2:int);
B = GROUP A BY col1;
C = FOREACH B {
  D = FILTER A BY col2 == 3;
  E = FILTER A BY col2 == 6;
  GENERATE group, COUNT(D), COUNT(E);
};
DUMP C;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(a,0,0)
(b,0,0)
(c,2,0)
(d,1,1)
(e,0,0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见结果是正确的。&lt;/p&gt;

&lt;p&gt;那么，如果我在上面的代码中，把“D = FILTER A BY col2 == 3”不小心写成了“D = FILTER B BY col2 == 3”，就肯定会得到“Scalars can be only used with projections”的错误提示。
说白了，还是要时刻注意你每一步生成的数据的结构，眼睛睁大，千万不要用错了relation。&lt;/p&gt;

&lt;p&gt;（36）什么是嵌套的FOREACH/内部的FOREACH
嵌套的（nested）FOREACH和内部的（inner）FOREACH是一个意思，正如你在本文第(35)条中所见，一个FOREACH可以对每一条记录施以多种不同的关系操作，然后再GENERATE得到想要的结果，这就是嵌套的/内部的FOREACH。&lt;/p&gt;

&lt;p&gt;（37）错误“Could not infer the matching function for org.apache.pig.builtin.CONCAT”的原因之一
如果你遇到这个错误，那么有可能是你在多级CONCAT嵌套的时候，没有写对语句，例如“CONCAT(CONCAT(CONCAT(a, b), c), d)”这样的嵌套，由于括号众多，所以写错了是一点也不奇怪的。我遇这个错误的时候，是由于CONCAT太多，自己多写了一个都没有发现。希望我的提醒能给你一点解决问题的提示。&lt;/p&gt;

&lt;p&gt;（38）用Pig加载HBase数据时遇到的错误“ERROR 2999: Unexpected internal error. could not instantiate ‘com.twitter.elephantbird.pig.load.HBaseLoader’ with arguments XXX”的原因之一
请看这个链接：《Apache Pig中文教程（进阶）》&lt;/p&gt;

&lt;p&gt;（39）错误“ERROR 1039: In alias XX, incompatible types in EqualTo Operator left hand side:XXX right hand side:XXX”的原因
其实这个错误提示太明显了，就是类型不匹配造成的。上面的XXX可以指代不同的类型。
这说明，前面可能有一个类型为long的字段，后面你却把它当chararray来用了，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (col1: int, col2: long);
B = FILTER A BY col2 == &#39;123456789&#39;;
C = GROUP B ALL;
D = FOREACH C GENERATE COUNT(B);
DUMP D;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就会出错：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ERROR 1039: In alias B, incompatible types in EqualTo Operator left hand side:long right hand side:chararray&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;只要把col2强制类型转换一下（或者一开始就将其类型指定为chararray）就可以解决问题。&lt;/p&gt;

&lt;p&gt;不仅在进行数据比较中，在JOIN时也经常出现数据类型不匹配导致的错误问题。我在实际工作中发现，有的同学写了比较长的Pig代码，出现了这样的错误却不会仔细去看错误提示，而是绞尽脑汁地逐句去检查语法（语法是没有错的），结果费了很大的劲才知道是类型问题，得不偿失，还不如仔细看错误提示想想为什么。&lt;/p&gt;

&lt;p&gt;（40）在grunt交互模式下，如何在编辑Pig代码的时候跳到行首和行末/行尾
在grunt模式下，如果你写了一句超长的Pig代码，那么，你想通过HOME/END键跳到行首和行末是做不到的。
按HOME时，Pig会在你的光标处插入一个“1~”：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (col: int1~);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;按END时，Pig会在你的光标处插入一个“4~”：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (col: int4~);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正确的做法是：按Ctrl+A 和 Ctrl+E 代替 HOME 和 END，就可以跳到行首和行末了。&lt;/p&gt;

&lt;p&gt;（41）不能对同一个关系（relation）进行JOIN
假设有如下文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat 1.txt 
1 a
2 e
3 v
4 n
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我想对第一列这样JOIN：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (col1: int, col2: chararray); 
B = JOIN A BY col1, A BY col1;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么当你试图 DUMP B 的时候，会报如下的错：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1108: Duplicate schema alias: A::col1 in “B”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这是因为Pig会弄不清JOIN之后的字段名——两个字段均为A::col1，使得一个关系（relation）中出现了重复的名字，这是不允许的。&lt;/p&gt;

&lt;p&gt;要解决这个问题，只需将数据LOAD两次，并且给它们起不同的名字就可以了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;1.txt&#39; AS (col1: int, col2: chararray);
grunt&amp;gt; B = LOAD &#39;1.txt&#39; AS (col1: int, col2: chararray);
grunt&amp;gt; C = JOIN A BY col1, B BY col1;                   
grunt&amp;gt; DESCRIBE C;
C: {A::col1: int,A::col2: chararray,B::col1: int,B::col2: chararray}
grunt&amp;gt; DUMP C;
(1,a,1,a)
(2,e,2,e)
(3,v,3,v)
(4,n,4,n)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的 C 的schema，你可以看出来，如果对同一个关系A的第一列进行JOIN，会导致schema中出现相同的字段名，所以当然会出错。&lt;/p&gt;

&lt;p&gt;（42）外部的JOIN(outer JOIN)
初次使用JOIN时，一般人使用的都是所谓的“内部的JOIN”(inner JOIN)，也即类似于 C = JOIN A BY col1, B BY col2 这样的JOIN。Pig也支持“外部的JOIN”(outer JOIN)，下面就举一个例子。
假设有文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat 1.txt 
1 a
2 e
3 v
4 n
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以及：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat 2.txt 
9 a
2 e
3 v
0 n
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在来对这两个文件的第一列作一个outer JOIN：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;1.txt&#39; AS (col1: int, col2: chararray);
grunt&amp;gt; B = LOAD &#39;2.txt&#39; AS (col1: int, col2: chararray);
grunt&amp;gt; C = JOIN A BY col1 LEFT OUTER, B BY col1;
grunt&amp;gt; DESCRIBE C;
C: {A::col1: int,A::col2: chararray,B::col1: int,B::col2: chararray}
grunt&amp;gt; DUMP C;
(1,a,,)
(2,e,2,e)
(3,v,3,v)
(4,n,,)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在outer JOIN中，“OUTER”关键字是可以省略的。从上面的结果，我们注意到：如果换成一个inner JOIN，则两个输入文件的第一、第四行都不会出现在结果中（因为它们的第一列不相同），而在LEFT OUTER JOIN中，文件1.txt的第一、四行却被输出了，所以这就是LEFT OUTER JOIN的特点：对左边的记录来说，即使它与右边的记录不匹配，它也会被包含在输出数据中。&lt;/p&gt;

&lt;p&gt;同理可知RIGHT OUTER JOIN的功能——把上面的 LEFT 换成 RIGHT，结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(,,0,n)
(2,e,2,e)
(3,v,3,v)
(,,9,a)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，与左边的记录不匹配的右边的记录被保存了下来，而左边的记录没有保存下来（两个逗号表明其为空），这就是RIGHT OUTER JOIN的效果，与我们想像的一样。
有人会问，OUTER JOIN在实际中可以用来做什么？举一个例子：可以用来求“不在某数据集中的那些数据（即：不重合的数据）”。还是以上面的两个数据文件为例，现在我要求出 1.txt 中，第一列不在 2.txt 中的第一列的那些记录，肉眼一看就知道，1和4这两个数字在 2.txt 的第一列里没有出现，而2和3出现了，因此，我们要找的记录就是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1 a
4 n
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要实现这个效果，Pig代码及结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;1.txt&#39; AS (col1: int, col2: chararray);
grunt&amp;gt; B = LOAD &#39;2.txt&#39; AS (col1: int, col2: chararray);
grunt&amp;gt; C = JOIN A BY col1 LEFT OUTER, B BY col1;        
grunt&amp;gt; DESCRIBE C;                 
C: {A::col1: int,A::col2: chararray,B::col1: int,B::col2: chararray}
grunt&amp;gt; D = FILTER C BY (B::col1 is null); 
grunt&amp;gt; E = FOREACH D GENERATE A::col1 AS col1, A::col2 AS col2;
grunt&amp;gt; DUMP E;
(1,a)
(4,n)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，我们确实找出了“不重合的记录”。在作海量数据分析时，这种功能是极为有用的。
最后来一个总结：
假设有两个数据集（在1.txt和2.txt中），分别都只有1列，则如下代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (col1: chararray);
B = LOAD &#39;2.txt&#39; AS (col1: chararray);  
C = JOIN A BY col1 LEFT OUTER, B BY col1;
D = FILTER C BY (B::col1 is null);
E = FOREACH D GENERATE A::col1 AS col1;                 
DUMP E;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;计算结果为：在A中，但不在B中的记录。&lt;/p&gt;

&lt;p&gt;（43）JOIN的优化
请看这个链接：《Apache Pig中文教程（进阶）》&lt;/p&gt;

&lt;p&gt;（44）GROUP时按所有字段分组可以用GROUP ALL吗
假设你有如下数据文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# cat 3.txt 
1 9
2 2
3 3
4 0
1 9
1 9
4 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在要找出第1、2列的组合中，每一种的个数分别为多少，例如，(1,9)组合有3个，(4,0)组合有两个，依此类推。
显而易见，我们只需要用GROUP就可以轻易完成这个任务。于是写出如下代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;3.txt&#39; AS (col1: int, col2: int);
B = GROUP A ALL;
C = FOREACH B GENERATE group, COUNT(A);
DUMP C;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可惜，结果不是我们想要的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(all,7)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为什么呢？我们的本意是按所有列来GROUP，于是使用了GROUP ALL，但是这实际上变成了统计行数，下面的代码就是一段标准的统计数据行数的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;3.txt&#39; AS (col1: int, col2: int);
B = GROUP A ALL;
C = FOREACH B GENERATE COUNT(A);
DUMP C;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因此，上面的 C = FOREACH B GENERATE group, COUNT(A) 也无非就是多打印了一个group的名字（all）而已——group的名字被设置为“all”，这是Pig帮你做的。&lt;/p&gt;

&lt;p&gt;正确的做法很简单，只需要按所有字段GROUP，就可以了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;3.txt&#39; AS (col1: int, col2: int);
B = GROUP A BY (col1, col2);
C = FOREACH B GENERATE group, COUNT(A);
DUMP C;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;((1,9),3)
((2,2),1)
((3,3),1)
((4,0),2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这与我们前面分析的正确结果是一样的。&lt;/p&gt;

&lt;p&gt;（45）在Pig中使用中文字符串
有读者来信问我，如何在Pig中使用中文作为FILTER的条件？我做了如下测试，结论是可以使用中文。
数据文件 data.txt 内容为（每一列之间以TAB为分隔符）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1 北京市 a
2 上海市 b
3 北京市 c
4 北京市 f
5 天津市 e
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pig脚本文件 test.pig 内容为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;data.txt&#39; AS (col1: int, col2: chararray, col3: chararray);
B = FILTER A BY (col2 == &#39;北京市&#39;);
DUMP B;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先，我这两个文件的编码都是UTF-8(无BOM)，在Linux命令行下，我直接以本地模式执行Pig脚本 test.pig：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pig -x local test.pig
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;得到的输出结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(1,北京市,a)
(3,北京市,c)
(4,北京市,f)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见结果是正确的。&lt;/p&gt;

&lt;p&gt;但是，如果我在grunt交互模式下，把 test.pig 的内容粘贴进去执行，是得不到任何输出结果的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grunt&amp;gt; A = LOAD &#39;data.txt&#39; AS (col1: int, col2: chararray, col3: chararray);
grunt&amp;gt; B = FILTER A BY (col2 == &#39;北京市&#39;);
grunt&amp;gt; DUMP B;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体原因我不清楚，但是至少有一点是肯定的：可以使用中文作为FILTER的条件，只要不在交互模式下执行你的Pig脚本即可。&lt;/p&gt;

&lt;p&gt;（46）如何统计 tuple 中的 field 数，bag 中的 tuple 数，map 中的 key/value 组数
一句话：用Pig内建的 SIZE 函数：&lt;/p&gt;

&lt;p&gt;Computes the number of elements based on any Pig data type.
具体可看这个链接。&lt;/p&gt;

&lt;p&gt;（47）一个字符串为null，与它为空不一定等价
在某些情况下，要获取“不为空”的字符串，仅仅用 is not null 来判断是不够的，还应该加上 SIZE(field_name) &amp;gt; 0 的条件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;B = FILTER A BY (field_name is not null AND (SIZE(field_name) &amp;gt; 0L));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意，这只是在某些情况下需要这样做，在一般情况下，仅用 is not null 来过滤就可以了。我并没有总结出特殊情况是哪些情况，我只能说我我不是第一次遇到此情况了，所以才有了这一个结论。
注意上面使用的是“0L”，因为SIZE()返回的是long类型，如果不加L，在Pig0.10下会出现一个警告，例如：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[main] WARN  org.apache.pig.PigServer - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;（48）Pig中的各operator（操作符），哪些会触发reduce过程
①GROUP：由于GROUP操作会将所有具有相同key的记录收集到一起，所以数据如果正在map中处理的话，就会触发shuffle→reduce的过程。
②ORDER：由于需要将所有相等的记录收集到一起（才能排序），所以ORDER会触发reduce过程。同时，除了你写的那个Pig job之外，Pig还会添加一个额外的M-R job到你的数据流程中，因为Pig需要对你的数据集做采样，以确定数据的分布情况，从而解决数据分布严重不均的情况下job效率过于低下的问题。
③DISTINCT：由于需要将记录收集到一起，才能确定它们是不是重复的，因此DISTINCT会触发reduce过程。当然，DISTINCT也会利用combiner在map阶段就把重复的记录移除。
④JOIN：JOIN用于求重合，由于求重合的时候，需要将具有相同key的记录收集到一起，因此，JOIN会触发reduce过程。
⑤LIMIT：由于需要将记录收集到一起，才能统计出它返回的条数，因此，LIMIT会触发reduce过程。
⑥COGROUP：与GROUP类似（参看本文前面的部分），因此它会触发reduce过程。
⑦CROSS：计算两个或多个关系的叉积。&lt;/p&gt;

&lt;p&gt;（49）如何统计一个字符串中包含的指定字符数
这可以不算是个Pig的问题了，你可以把它认为是一个shell的问题。从本文前面部分我们已经知道，Pig中可以用 STREAM … THROUGH 来调用shell进行辅助数据处理，所以在这我们也能这样干。
假设有文本文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]$ cat 1.txt 
123 abcdef:243789174
456 DFJKSDFJ:3646:555558888
789 yKDSF:00000%0999:2343324:11111:33333
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在要统计：每一行中，第二列里所包含的冒号（“:”）分别为多少？代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = LOAD &#39;1.txt&#39; AS (col1: chararray, col2: chararray);
B = STREAM A THROUGH `awk -F&quot;:&quot; &#39;{print NF-1}&#39;` AS (colon_count: int);
DUMP B;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(1)
(2)
(4)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;（50）UDF是区分大小写的
因为UDF是由Java类来实现的，所以区分大小写，就这么简单。&lt;/p&gt;

&lt;p&gt;（51）设置Pig job的job name
在Pig脚本开头加上一句：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;set job.name &#39;My-Job-Name&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么，执行该Pig脚本之后，在Hadoop的Job Tracker中看到的“Name”就是“My-Job-Name”了。
如果不设置，显示的name是类似于“Job6245768625829738970.jar”这样的东西，job多的时候完全没有标识度，建议一定要设置一个特殊的job name。&lt;/p&gt;

</content>
   </entry>
   
 
</feed>
