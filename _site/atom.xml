<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
   <title>NingG.github.com</title>
   <link href="http://ningg.github.com/atom.xml" rel="self" type="application/atom+xml"/>
   <link href="http://ningg.github.com" rel="alternate" type="text/html" />
   <updated>2014-11-02T01:05:17+08:00</updated>
   <id>http://ningg.github.com</id>
   <author>
     <name></name>
     <email></email>
   </author>

   
   <entry>
     <title>Eclipse下搭建Kafka的开发环境</title>
     <link href="http://ningg.github.com/kafka-dev-env-with-eclipse"/>
     <updated>2014-11-01T00:00:00+08:00</updated>
     <id>http://ningg.github.com/kafka-dev-env-with-eclipse</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;最近要进行Kafka开发，在&lt;a href=&quot;http://kafka.apache.org/code.html&quot;&gt;官网&lt;/a&gt;看到可以在IDE下开发，赶紧点进去看了看，并且在本地Eclipse下搭建了个Kafka的开发环境，主要参考来源：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Developer+Setup&quot;&gt;Kafka Developer Setup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;编译环境&lt;/h2&gt;

&lt;p&gt;查看自己机器的环境：我用笔记本来编译的，是win 7（x64）操作系统；更详细的编译环境信息通过如下方式查看：&lt;code&gt;CMD&lt;/code&gt;–&amp;gt;&lt;code&gt;systeminfo&lt;/code&gt;，这个命令收集系统信息，需要花费40s，稍等一会儿，得到如下信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C:\Users\Administrator&amp;gt;systeminfo

OS 名称:          Microsoft Windows 7 旗舰版
OS 版本:          6.1.7601 Service Pack 1 Build 7601

系统类型:         x64-based PC
处理器:           安装了 1 个处理器。
	 [01]: Intel64 Family 6 Model 23 Stepping 6 GenuineIntel ~785 Mhz

物理内存总量:     2,968 MB
可用的物理内存:   819 MB
虚拟内存: 最大值: 5,934 MB
虚拟内存: 可用:   2,196 MB
虚拟内存: 使用中: 3,738 MB
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;section-2&quot;&gt;开始编译&lt;/h2&gt;

&lt;p&gt;需要提前下载几个东西：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Kafka源码包：&lt;a href=&quot;http://kafka.apache.org/downloads.html&quot;&gt;kafka-0.8.1.1-src.tgz&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Eclipse下的Scala 2.10.x IDE plugin：&lt;a href=&quot;http://scala-ide.org/download/current.html&quot;&gt;For Scala 2.10.4&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Eclipse下的IvyIDE plugin：&lt;a href=&quot;http://ant.apache.org/ivy/ivyde/download.cgi&quot;&gt; apache-ivyde-2.2.0.final-201311091524-RELEASE.zip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;eclipse&quot;&gt;Eclipse下安装插件&lt;/h3&gt;

&lt;p&gt;基本步骤：打开Eclipse–Help–Install new Software，具体见下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka-dev-env-with-eclipse/install-new-software.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka-dev-env-with-eclipse/install-plugins.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于IvyDE，如果上述办法添加插件出错，则，进行如下操作：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;IvyDE features &lt;code&gt;features/org.apache.ivyde.*.jar&lt;/code&gt; to put in your &lt;code&gt;$ECLIPSE_HOME/features&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;IvyDE plugins &lt;code&gt;plugins/org.apache.ivyde.*.jar&lt;/code&gt; to put in your &lt;code&gt;$ECLIPSE_HOME/plugins&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;eclipse-project-file&quot;&gt;生成Eclipse project file&lt;/h3&gt;

&lt;p&gt;由于我的电脑是Windowns 7，因此安装了Cygwin，下面的操作都是在Cygwin下进行的，具体是，到Kafka源码包的路径下，执行如下命令：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd $KAFKA_SRC_HOME
./gradlew eclipse
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;kafkaeclipse&quot;&gt;kafka工程导入Eclipse&lt;/h3&gt;

&lt;p&gt;将上一步生成的project导入到Eclipse中，具体：&lt;code&gt;File&lt;/code&gt; -&amp;gt; &lt;code&gt;Import&lt;/code&gt; -&amp;gt; &lt;code&gt;General&lt;/code&gt; -&amp;gt; &lt;code&gt;Existing Projects into Workspace&lt;/code&gt;，结果如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka-dev-env-with-eclipse/kafka-src.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;杂谈&lt;/h2&gt;

&lt;p&gt;今天在公司，折腾一下午，网络问题，脑袋都大了，回来后，不到30mins就搞定了，顺便还整理了下，形成了此文；没有稳定的网络，对于有追求的工程师，就如同拿着锄头的特战队员，能力再牛，照样被拿微冲的小白恐吓。&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>Flume下插件方式实现Advanced Logger Sink</title>
     <link href="http://ningg.github.com/flume-advance-logger-sink"/>
     <updated>2014-10-31T00:00:00+08:00</updated>
     <id>http://ningg.github.com/flume-advance-logger-sink</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;Flume自带的Logger sink常用于直接在console上输出event的header和body，这对test和debug很重要，但body默认只truncate 16B，无法全部展示，这对test造成很大影响，怎么办？自己实现一个Adavanced Logger sink：完全输出整个event，这样就便利多了。&lt;/p&gt;

&lt;h2 id=&quot;flumelogger-sink&quot;&gt;Flume中Logger Sink&lt;/h2&gt;

&lt;p&gt;在&lt;a href=&quot;/build-flume&quot;&gt;编译flume：使用eclipse查看flume源码&lt;/a&gt;中，已经介绍了如何在Eclipse下查看Flume的源代码，通过查看&lt;code&gt;LoggerSink&lt;/code&gt;源码发现：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// LoggerSink.java
logger.info(&quot;Event: &quot; + EventHelper.dumpEvent(event));
...

// EventHelper.java
private static final int DEFAULT_MAX_BYTES = 16;

public static String dumpEvent(Event event) {
	return dumpEvent(event, DEFAULT_MAX_BYTES);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过上面的Flume源码片段可知，Logger Sink默认限制了event的大小为16字节，这样，只需要实现一个与Logger Sink基本一致，但不对event设限制的sink就好了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：编译flume时，直接将源码当作existing maven project导入，行不行？Flume的源码全是java写的吗？还有个问题：如果使用eclipse来进行源代码的开发，最终通过git方式向repository中提交代码时，会夹带.class文件吗？&lt;/p&gt;

&lt;h2 id=&quot;sink&quot;&gt;自定义Sink&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/flume-advance-logger-sink/advanced-logger-sink.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;flume-ng-core&lt;/code&gt;工程的&lt;code&gt;src/main/java&lt;/code&gt;目录下，新建package：&lt;code&gt;com.github.ningg&lt;/code&gt;，然后新建class：&lt;code&gt;AdvancedLoggerSink&lt;/code&gt;，内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package com.github.ningg;

import org.apache.flume.Channel;
import org.apache.flume.Context;
import org.apache.flume.Event;
import org.apache.flume.EventDeliveryException;
import org.apache.flume.Transaction;
import org.apache.flume.conf.Configurable;
import org.apache.flume.event.EventHelper;
import org.apache.flume.sink.AbstractSink;
import org.apache.flume.sink.LoggerSink;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class AdvancedLoggerSink extends AbstractSink implements Configurable {

	private static final Logger logger = LoggerFactory
			.getLogger(LoggerSink.class);

	private static final int DEFAULT_MAX_BYTES = 16;
	private int maxBytes = DEFAULT_MAX_BYTES;
	
	@Override
	public void configure(Context context) {
		maxBytes = context.getInteger(&quot;maxBytes&quot;, DEFAULT_MAX_BYTES);
		logger.debug(this.getName() + &quot; maximum bytes set to &quot; + String.valueOf(maxBytes));
	}
	
	@Override
	public Status process() throws EventDeliveryException {
		Status result = Status.READY;
		Channel channel = getChannel();
		Transaction transaction = channel.getTransaction();
		Event event = null;

		try {
			transaction.begin();
			event = channel.take();

			if (event != null) {
				if (logger.isInfoEnabled()) {
					// edit this line, so you can change the output formater.
					logger.info(&quot;Event: &quot; + EventHelper.dumpEvent(event, maxBytes));
				}
			} else {
				// No event found, request back-off semantics from the sink
				// runner
				result = Status.BACKOFF;
			}
			transaction.commit();
		} catch (Exception ex) {
			transaction.rollback();
			throw new EventDeliveryException(&quot;Failed to log event: &quot; + event,
					ex);
		} finally {
			transaction.close();
		}

		return result;
	}

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接下来，将整个&lt;code&gt;com.github.ningg&lt;/code&gt;package导出为jar包：&lt;code&gt;advancedLoggerSink.jar&lt;/code&gt;；根据Flume官网的建议，将此jar包上传到&lt;code&gt;$FLUME_HOME/plugins.d&lt;/code&gt;目录下，具体：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;plugins.d/advanced-logger-sink/lib/advancedLoggerSink.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了测试效果，在&lt;code&gt;$FLUME_HOME/conf&lt;/code&gt;下新建&lt;code&gt;advancedLoggerSink.conf&lt;/code&gt;文件:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;agent.sources = net
agent.sinks = loggerSink
agent.channels = memoryChannel

# For each one of the sources, the type is defined
agent.sources.net.type = netcat
agent.sources.net.bind = localhost
agent.sources.net.port = 44444

# Each sink&#39;s type must be defined
agent.sinks.loggerSink.type = com.github.ningg.AdvancedLoggerSink
agent.sinks.loggerSink.maxBytes = 100

# Each channel&#39;s type is defined.
agent.channels.memoryChannel.type = memory
agent.channels.memoryChannel.capacity = 100


agent.sources.net.channels = memoryChannel
agent.sinks.loggerSink.channel = memoryChannel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;回到&lt;code&gt;$FLUME_HOME&lt;/code&gt;目录下，执行如下命令：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/flume-ng agent --conf conf --conf-file conf/advancedLoggerSink.conf --name agent -Dflume.root.logger=INFO,console
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当页面显示如下字样，表示flume启动成功：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Created serverSocket:sun.nio.ch.ServerSocketChannelImpl[/127.0.0.1:44444]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另开一个窗口，在当前服务器上，执行命令：&lt;code&gt;telnet localhost 44444&lt;/code&gt;，并且输入如下内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Now I&#39;m testing the Advanced Logger Sink
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;则，AdavancedSinkLogger的输出内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[INFO - com.github.ningg.AdvancedLoggerSink.process(AdvancedLoggerSink.java:44)] Event: { headers:{} 
   body: 4E 6F 77 20 49 27 6D 20 74 65 73 74 69 6E 67 20 Now I&#39;m testing
00000010 74 68 65 20 41 64 76 61 6E 63 65 64 20 4C 6F 67 the Advanced Log
00000020 67 65 72 20 53 69 6E 6B 0D                      ger Sink. }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;AdvancedLoggerSink的输出格式：每行输出16个byte，左侧是字母对应的ASCII码，右侧是字母本身。备注：如果希望定制上述的输出格式，可以直接新建类来替代&lt;code&gt;EventHelper.dumpEvent(event, maxBytes)&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;参考来源&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/20189437/flume-is-truncating-characters-when-i-use-the-source-type-as-logger-it-just-s&quot;&gt;Logger Sink truncate Event body&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLUME-2246&quot;&gt;FLUME-2246&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;杂谈&lt;/h2&gt;

&lt;p&gt;本文写完之后，我发现了：&lt;a href=&quot;https://issues.apache.org/jira/browse/FLUME-2246&quot;&gt;FLUME-2246&lt;/a&gt;，Ou，已经有人在Flume官网上讨论并解决了这个问题，看来不会使用Flume官网不行呀，之前自己阅读标记过&lt;a href=&quot;/how-to-contribute-open-source-project&quot;&gt;如何参与开源项目&lt;/a&gt;， 但是没有实际尝试参与。个人心里一个想法：玩开源的东西，要参与到开源社区中，你的问题开源社区早已涉及，只不过有些扩展功能重要程度低，虽然已解决，但并没有并入发行版本中。&lt;/p&gt;

&lt;p&gt;另，说明一点啊：遇到问题，自己先想思路，再去社区找答案，也是个好方法。&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>整合Flume、Kafka、Storm</title>
     <link href="http://ningg.github.com/combine-flume-kafka-storm"/>
     <updated>2014-10-31T00:00:00+08:00</updated>
     <id>http://ningg.github.com/combine-flume-kafka-storm</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;之前研读了&lt;a href=&quot;&quot;&gt;In-Stream Big Data Processing&lt;/a&gt;，组里将基于此实现一个实时的数据分析系统，基本选定三个组件：Flume、Kafka、Storm，其中，Flume负责数据采集，Kafka是一个MQ:负责数据采集与数据分析之间解耦，Storm负责进行流式处理。&lt;/p&gt;

&lt;p&gt;把这3个东西串起来，可以吗？可以，官网有说明&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;系统环境&lt;/h2&gt;

&lt;h2 id=&quot;flume&quot;&gt;Flume设置&lt;/h2&gt;

&lt;h2 id=&quot;kafka&quot;&gt;Kafka设置&lt;/h2&gt;

&lt;h2 id=&quot;storm&quot;&gt;Storm设置&lt;/h2&gt;

</content>
   </entry>
   
   <entry>
     <title>CentOS 6.4下LVM的使用</title>
     <link href="http://ningg.github.com/use-lvm"/>
     <updated>2014-10-29T00:00:00+08:00</updated>
     <id>http://ningg.github.com/use-lvm</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;系统有9块盘，每个320GB，之前服务器（CentOS 6.3）上磁盘分配情况：选取一块盘作为系统盘，划分&lt;code&gt;/boot&lt;/code&gt;、&lt;code&gt;swap&lt;/code&gt;、&lt;code&gt;/&lt;/code&gt;、&lt;code&gt;/home&lt;/code&gt;；然后，将剩余的8块盘，逐个格式化，并mount到系统盘的某个目录下。现在的问题是：某系统要上线，需要一个足够大的空间来存储数据，如果使用上述的方案，每个目录最大的存储空间都只有320GB，还是不够大，今后可能面临分区扩容的问题，使用静态分区，扩容有些麻烦。而LVM（Logical Volume Management，逻辑卷管理）能够将多个磁盘/分区组合在一起，抽象为一个逻辑上的分区，即，利用LVM技术，8块盘可以组成一个2.5T大小的分区，这样问题就解决了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：上面利用LVM来管理8块盘的方案，只是初步想法，不是最终方案。&lt;/p&gt;

&lt;h2 id=&quot;lvm&quot;&gt;LVM是什么&lt;/h2&gt;

&lt;p&gt;LVM(Logical Volume Management，逻辑卷管理)，一大核心功能是：对磁盘分区进行动态管理。当前无论在Linux、类Unix以及其他Windowns操作系统上，都存在LVM管理软件。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/use-lvm/lvm-arch.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;lvm-1&quot;&gt;LVM要解决的问题&lt;/h3&gt;

&lt;p&gt;LVM要解决的典型问题：一块磁盘的空间160GB，其存满数据后，需要扩容，怎么办？传统静态分区时，需要将磁盘中近160GB的数据复制到1TB的磁盘上，然后，使用1TB的磁盘替换掉原来160GB的磁盘即可（替换：只要是挂载点替换一下就可以了）。LVM有更好的思路，来解决这个问题吗？&lt;/p&gt;

&lt;h3 id=&quot;lvm-2&quot;&gt;LVM原理简介&lt;/h3&gt;

&lt;p&gt;要解决上面磁盘空间不足时，磁盘的扩容问题，LVM提供了一个基本思路：LVM将底层的磁盘封装抽象为逻辑卷（logical volume），上层应用不直接从物理磁盘分区中读数据，而是从逻辑卷中读数据；LVM负责底层磁盘到逻辑卷的映射和管理；增加底层磁盘时，通过LVM可以为逻辑卷动态扩充容量，而这对上层应用是无影响的（透明的）。说这么多，总结一点：LVM提高了磁盘管理的灵活性。&lt;/p&gt;

&lt;h2 id=&quot;lvm-3&quot;&gt;LVM原理详解&lt;/h2&gt;

&lt;p&gt;上面简要说了一点点LVM的基本原理，吃饭要吃饱、做事要做好，OK，把LVM的原理好好理解一下。有几个概念要好好说一说。&lt;/p&gt;

&lt;h3 id=&quot;pv-physical-volume&quot;&gt;PV: Physical Volume&lt;/h3&gt;

&lt;p&gt;PV（Physical Volume），物理卷&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;物理卷在LVM系统中处于最底层。&lt;/li&gt;
  &lt;li&gt;物理卷可以是整个硬盘、硬盘上的分区或从逻辑上与磁盘分区具有同样功能的设备（如：RAID）。&lt;/li&gt;
  &lt;li&gt;物理卷是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，却包含有与LVM相关的管理参数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：为什么要有PV？直接使用物理分区不行吗？&lt;/p&gt;

&lt;h3 id=&quot;vg-volume-group&quot;&gt;VG: Volume Group&lt;/h3&gt;

&lt;p&gt;VG（Volume Group），卷组&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;卷组建立在物理卷之上，它由一个或多个物理卷组成。&lt;/li&gt;
  &lt;li&gt;卷组创建之后，可以动态地添加物理卷到卷组中，在卷组上可以创建一个或多个“LVM分区”（逻辑卷）。&lt;/li&gt;
  &lt;li&gt;一个LVM系统中可以只有一个卷组，也可以包含多个卷组。&lt;/li&gt;
  &lt;li&gt;LVM的卷组类似于非LVM系统中的物理硬盘。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lg-logical-volume&quot;&gt;LG: Logical Volume&lt;/h3&gt;

&lt;p&gt;LG（Logical Volume），逻辑卷&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;逻辑卷建立在卷组之上，它是从卷组中“切出”的一块空间。&lt;/li&gt;
  &lt;li&gt;逻辑卷创建之后，其大小可以伸缩。&lt;/li&gt;
  &lt;li&gt;LVM的逻辑卷类似于非LVM系统中的硬盘分区，在逻辑卷之上可以建立文件系统（比如，/home或者/usr等）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pe-physical-extent&quot;&gt;PE: Physical Extent&lt;/h3&gt;

&lt;p&gt;PE（Physical Extent），物理区域，&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;每一个物理卷被划分为基本单元（称为PE），具有唯一编号的PE是可以被LVM寻址的最小存储单元。&lt;/li&gt;
  &lt;li&gt;PE的大小可根据实际情况在创建物理卷时指定，默认为4 MB。&lt;/li&gt;
  &lt;li&gt;PE的大小一旦确定将不能改变，同一个卷组中的所有物理卷的PE的大小需要一致。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;le-logical-extent&quot;&gt;LE: Logical Extent&lt;/h3&gt;

&lt;p&gt;LE（Logical Extent），逻辑区域&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;逻辑区域也被划分为可被寻址的基本单位（称为LE）。&lt;/li&gt;
  &lt;li&gt;在同一个卷组中，LE的大小和PE是相同的，并且一一对应。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：PE、LE，是否与文件系统中block（逻辑块）类似？而block大，能够提升磁盘IO速度；但block过大，造成磁盘空间的浪费？&lt;/p&gt;

&lt;h3 id=&quot;vgda&quot;&gt;VGDA&lt;/h3&gt;

&lt;p&gt;和非LVM系统将包含分区信息的元数据保存在位于分区的起始位置的分区表中一样，逻辑卷以及卷组相关的元数据也是保存在位于物理卷起始处的卷组描述符区域（Volume Group Descriptor Area, VGDA）中。VGDA包括以下内容：PV描述符、VG描述符、LV描述符、和一些PE描述符。&lt;/p&gt;

&lt;p&gt;注意：/boot分区不能位于卷组中，因为引导装载程序无法从逻辑卷中读取。如果你想把/分区放在逻辑卷上，必须创建一个与卷组分离的/boot分区。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;小结&lt;/h3&gt;

&lt;p&gt;我们在创建好LV以后，我们会在 /dev 目录下看到我们的LV信息，例如 /dev/vgname/lvname， 我们每创建一个VG，其会在/dev目录下创建一个以该VG名字命名的文件夹，在该VG的基础上创建好LV以后，我们会在这个VG目录下多出一个以LV名字命名的逻辑卷。&lt;/p&gt;

&lt;p&gt;下面我们来对整个LVM的工作原理进行一个总结：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;物理磁盘/物理分区，被格式化为PV，本质：空间被划分为一个个的PE&lt;/li&gt;
  &lt;li&gt;不同的PV加入到同一个VG中，不同PV的PE全部进入到了VG的PE池内&lt;/li&gt;
  &lt;li&gt;LV基于PE创建，大小为PE的整数倍，组成LV的PE可能来自不同的物理磁盘&lt;/li&gt;
  &lt;li&gt;LV现在就直接可以格式化后挂载使用了&lt;/li&gt;
  &lt;li&gt;LV的扩充缩减实际上就是增加或减少组成该LV的PE数量，其过程不会丢失原始数据&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：在创建PV时，需要物理磁盘/物理分区提前进行格式化吗？&lt;strong&gt;RE&lt;/strong&gt;：不需要格式化的，直接创建PV就行。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/use-lvm/pv-vg-lv.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;centosdoing&quot;&gt;CentOS的推荐配置doing..&lt;/h2&gt;

&lt;p&gt;使用LVM来管理磁盘时，CentOS有没有推荐的配置？&lt;/p&gt;

&lt;p&gt;LVM只有优点吗？
LVM有没有副作用？降低磁盘IO？耗费一定的磁盘空间？LVM管理时，有没有CPU、磁盘资源的浪费？&lt;/p&gt;

&lt;p&gt;（下面还没有修改，参考来源：&lt;a href=&quot;http://hily.me/blog/2008/10/understanding-lvm/&quot;&gt;理解 LVM (Logical Volume Manager)&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;是否使用 LVM？&lt;/p&gt;

&lt;p&gt;在决定是否使用 LVM 前请先了解下 LVM 的优缺点。&lt;/p&gt;

&lt;p&gt;使用 LVM 的优势：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;文件系统可以跨多个磁盘，因此大小不会受物理磁盘的限制。&lt;/li&gt;
  &lt;li&gt;可以在系统运行状态下动态地扩展文件系统大小。&lt;/li&gt;
  &lt;li&gt;可以增加新磁盘到 LVM 的存储池中。&lt;/li&gt;
  &lt;li&gt;可以以镜像的方式冗余重要数据到多个物理磁盘上。&lt;/li&gt;
  &lt;li&gt;可以很方便地导出整个卷组，并导入到另外一台机器上。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用 LVM 的限制：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;系统、文件系统出现问题时，LVM处理起来麻烦，关键要看处理者的能力&lt;/li&gt;
  &lt;li&gt;在从卷组中移除一个磁盘时必须使用 reducevg，否则会出问题。&lt;/li&gt;
  &lt;li&gt;当卷组中的一个磁盘损坏时，整个卷组都会受影响。&lt;/li&gt;
  &lt;li&gt;不能减小文件系统大小（受文件系统类型限制）。&lt;/li&gt;
  &lt;li&gt;因为加入了额外的操作，存储性能会受影响（使用 Stripe 的情况另当别论）。&lt;/li&gt;
  &lt;li&gt;使用 LVM 将获得更好的可扩展性和可操作性，但却损失了可靠性和存储性能，总的说来就是在这两者间选择。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用要点&lt;/p&gt;

&lt;p&gt;按需分配文件系统大小，不要一次性分配太大的空间给文件系统，剩余的空间可以放在存储池中，在需要时再扩充到文件系统中。
把不同的数据放在不同的卷组中，这样在做系统升级或数据迁移操作时会比较方便。&lt;/p&gt;

&lt;h2 id=&quot;linuxlvm&quot;&gt;Linux下LVM命令&lt;/h2&gt;

&lt;p&gt;LVM要实现的如下几个功能：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;创建PV、VG、LV&lt;/li&gt;
  &lt;li&gt;向VG中增加新的PV&lt;/li&gt;
  &lt;li&gt;从VG中移除PV&lt;/li&gt;
  &lt;li&gt;动态调整LV容量&lt;/li&gt;
  &lt;li&gt;删除PV、VG、LV&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：LV本质由PE组成的，那一个LV对应的所有PE是均匀分布在PV上吗？有什么策略？&lt;/p&gt;

&lt;h3 id=&quot;pvvglv&quot;&gt;PV\VG\LV的创建、删除&lt;/h3&gt;

&lt;p&gt;来个表格吧：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;命令&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;pvcreate&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;创建PV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;pvdisplay&lt;/code&gt;/&lt;code&gt;pvs&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;查询PV详情&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;pvremove&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;删除PV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;vgcreate&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;创建VG&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;vgdisplay&lt;/code&gt;/&lt;code&gt;vgs&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;查询VG详情&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;vgremove&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;删除VG&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;lvcreate&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;基于VG创建LV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;lvdisplay&lt;/code&gt;/&lt;code&gt;lvs&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;查询LV详情&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;lvremove&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;删除LV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;mkfs&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;格式化LV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;mount&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;挂载LV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;umount&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;卸载LV&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：先删除LV，再删除VG，最后删除PV。&lt;/p&gt;

&lt;h3 id=&quot;lvdoing&quot;&gt;LV的动态调整doing…&lt;/h3&gt;

&lt;p&gt;LV的动态调整：参考&lt;a href=&quot;http://www.cnblogs.com/xiaoluo501395377/archive/2013/05/24/3097785.html&quot;&gt;LVM逻辑卷的拉伸及缩减&lt;/a&gt;，&lt;a href=&quot;http://labs.chinamobile.com/mblog/854855_181800&quot;&gt;简单理解LVM(Logical Volume Manager)的基本原理&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;参考资料&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/jimmy_zjw/article/details/8598219&quot;&gt;什么是LVM?（CentOS 5）&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/xiaoluo501395377/archive/2013/05/22/3093405.html&quot;&gt;LVM逻辑卷基本概念及LVM的工作原理&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://labs.chinamobile.com/mblog/854855_181800&quot;&gt;简单理解LVM(Logical Volume Manager)的基本原理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;杂谈&lt;/h2&gt;

&lt;p&gt;我一直坚持读第一手的资料，因此，这次我直接就想到了CentOS官网的文章；不过读起来还是有些羞涩的，第一次接触LVM，很多东西云里雾里，相反查到的几篇blog还是不错的，有配图、有简洁的表述；因此，个人感觉，对于很生疏的东西，查看网上的blog反倒是入门的好方法；有了简单的入门知识，又希望深入理解的，那再去查第一手的资料就好了。&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>Understanding LVM</title>
     <link href="http://ningg.github.com/understanding-lvm"/>
     <updated>2014-10-28T00:00:00+08:00</updated>
     <id>http://ningg.github.com/understanding-lvm</id>
     <content type="html">&lt;blockquote&gt;
  &lt;p&gt;原文地址：&lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/sn-partitioning-lvm.html&quot;&gt;Understanding LVM&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;LVM (Logical Volume Management) partitions provide a number of advantages over standard partitions. （LVM，Logical Volume Management，逻辑卷管理）：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One or more physical volumes are combined to form a volume group. （n个physical volume，组成一个volume group）&lt;/li&gt;
  &lt;li&gt;Each volume group’s total storage is then divided into one or more logical volumes.（volume group被分割为n个logical volume）&lt;/li&gt;
  &lt;li&gt;The logical volumes function much like standard partitions. （在user看来，logical volume跟standard partition一样）&lt;/li&gt;
  &lt;li&gt;LVM partitions are formatted as physical volumes. They have a file system type, such as &lt;code&gt;ext4&lt;/code&gt;, and a mount point.（logical volume有自己的file system type，以及mount point）&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;The /boot Partition and LVM&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;On most architectures, the boot loader cannot read LVM volumes. You must make a standard, non-LVM disk partition for your &lt;code&gt;/boot&lt;/code&gt; partition.（绝大多数architecture下，boot loader不能读取LVM volume；因此，需要为&lt;code&gt;/boot&lt;/code&gt;单独分区，并指定一个non-LVM的分区）&lt;/p&gt;

  &lt;p&gt;However, on System z, the &lt;code&gt;zipl&lt;/code&gt; boot loader supports &lt;code&gt;/boot&lt;/code&gt; on LVM logical volumes with linear mapping.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To understand LVM better, imagine the physical volume as a pile of &lt;code&gt;blocks&lt;/code&gt;. A block is simply a storage unit used to store data. Several piles of blocks can be combined to make a much larger pile, just as physical volumes are combined to make a volume group. The resulting pile can be subdivided into several smaller piles of arbitrary size, just as a volume group is allocated to several logical volumes.&lt;/p&gt;

&lt;p&gt;An administrator may grow or shrink logical volumes without destroying data, unlike standard disk partitions. If the physical volumes in a volume group are on separate drives or RAID arrays then administrators may also spread a logical volume across the storage devices.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：LVM有两个优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;动态调整logical volume&lt;/strong&gt;：动态的grow or shrink Logical volume，数据不会损坏；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;并发写drives&lt;/strong&gt;：如果physical volume是多个drives 或者 RAID arrays，则 a logical volume能够横跨这些storage devices，带来一个好处，向某一目录写数据时，能够向多个磁盘并发写，加快写数据的速度；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You may lose data if you shrink a logical volume to a smaller capacity than the data on the volume requires. To ensure maximum flexibility, create logical volumes to meet your current needs, and leave excess storage capacity unallocated. You may safely grow logical volumes to use unallocated space, as your needs dictate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：当将logical volume大小调整为小于其所存储数据的大小时，会丢失数据；通常，按照当前需求分配logical volume大小，其余的存储空间不分配，今后根据需要动态的增加logical volume的大小。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;LVM and the Default Partition Layout&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;By default, the installation process creates &lt;code&gt;/&lt;/code&gt; and &lt;code&gt;swap&lt;/code&gt; partitions within LVM volumes, with a separate &lt;code&gt;/boot&lt;/code&gt; partition.&lt;/p&gt;
&lt;/blockquote&gt;

</content>
   </entry>
   
   <entry>
     <title>安装CentOS 6.4</title>
     <link href="http://ningg.github.com/centos-installation"/>
     <updated>2014-10-26T00:00:00+08:00</updated>
     <id>http://ningg.github.com/centos-installation</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;1. 简介&lt;/h2&gt;

&lt;p&gt;CentOS（Community Enterprise Operating System，企业社区操作系统）是Linux发行版本之一。Red Hat Enterpris Linux（RHEL，红帽企业级Linux）依照开放源码规定，开源了每个RHEL版本的源代码，CentOS正是基于RHEL的源代码重新编译而成的[1]，并且在RHEL基础上修复了一些已知的bug，相对与其他Linux发行版本，CentOS稳定性值得信赖。当前，很多企业都在服务器上安装CentOS系统，来支撑线上应用。
CentOS与RHEL的最大区别在于：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;RHEL中包含了部分封闭源码的工具，而CentOS包含的所有工具都是开源的；&lt;/li&gt;
  &lt;li&gt;RHEL提供技术服务，以此来收费；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;值得注意的是，2014年初，CentOS宣布加入Red Hat[2]。&lt;/p&gt;

&lt;p&gt;备注：CentOS的版本与RHEL版本基本一一对应，举例，CentOS 6.4对应RHEL 6.4的源代码。&lt;/p&gt;

&lt;h2 id=&quot;centos-6&quot;&gt;2. 安装CentOS 6&lt;/h2&gt;

&lt;p&gt;说到安装Linux系统，不要着急，官网肯定有操作手册来说明这个事，嗯，CentOS应用这么广泛，帮助手册总该有吧，要不然与其身份也不相符合。很不幸，&lt;a href=&quot;http://www.centos.org/docs/&quot;&gt;CentOS的官网&lt;/a&gt;中，并没有CentOS 6的操作手册，欧，赶快查查什么原因：CentOS完全基于RHEL源码编译而来，并且版本基本一一对应，因此，直接使用RHEL的官网文档即可[3]。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;特别说明&lt;/strong&gt;：本文所有安装CentOS 6的步骤、配置，都参考自RHEL 6官方文档[5]。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;2.1.	基本设置&lt;/h3&gt;

&lt;p&gt;这一部分，主要演示几点：如何通过CD/DVD光驱来重装系统。&lt;/p&gt;

&lt;p&gt;步骤 1. 	重启系统，出现图1界面时，点击”F11”按钮，目的：设置Boot Menu。
说明：当点击完”F11”按钮之后，如图1界面最下端所示，”F11”按钮背景由黑色变为白色。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/001.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;步骤 2. 	当出现图2所示界面时，选择”1”，目标：从光驱中加载系统。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/002.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;稍等一会儿，有可能出现图3所示界面，不要管他，等一段时间即可
备注：如果长时间停留在图3界面，则敲击Enter。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/003.png&quot; alt=&quot;图 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;步骤 3. 	出现如图4时，选择“Install sytem with basic video driver”（第二项），目标：重装系统。
备注：也可选择“Install or upgrade an existing system”（第一项），但，有可能显示器画面出现倾斜异常（显卡驱动问题），因此推荐 “Install sytem with basic video driver”（第二项）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/004.png&quot; alt=&quot;&quot; /&gt;
图 4&lt;/p&gt;

&lt;p&gt;步骤 4. 	出现如图5所示界面后，通过”Tab”键，选择“Skip”选项，并使用“Space”键来确认即可。目标：在安装之前，不进行磁盘、网卡、内存等硬件设备的测试。（因为太浪费时间了）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/005.png&quot; alt=&quot;&quot; /&gt;
图 5&lt;/p&gt;

&lt;p&gt;选择”Skip”之后，可能会出现图6所示界面，稍等一会儿，会自动跳入下个页面（如图7）。等待时间：几十秒~几分钟。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/006.png&quot; alt=&quot;&quot; /&gt; 
图 6&lt;/p&gt;

&lt;p&gt;步骤 5. 	出现如图7所示页面后，点击”Next”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/007.png&quot; alt=&quot;&quot; /&gt;
图 7&lt;/p&gt;

&lt;p&gt;步骤 6. 	在如图8所示界面，选择安装CentOS过程中，页面的显示语言，当安装服务器时，建议选择“English（English）”。
备注：这一步选定哪种语言，貌似对安装系统没有影响，而实际测试发现，有些细微差异，例如，安装完系统后，系统环境变量LANG会有细微差异。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/008.png&quot; alt=&quot;&quot; /&gt;
图 8&lt;/p&gt;

&lt;p&gt;步骤 7. 	参照下图9~15，一步步安装下去即可。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/009.png&quot; alt=&quot;&quot; /&gt;
图 9&lt;/p&gt;

&lt;p&gt;图9：选择系统键盘语言，选“U.S. English”即可。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/010.png&quot; alt=&quot;&quot; /&gt;
图 10&lt;/p&gt;

&lt;p&gt;图10：选择系统安装的磁盘，选“Basic Storage Devices”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/011.png&quot; alt=&quot;&quot; /&gt; 
图 11&lt;/p&gt;

&lt;p&gt;特别说明：有可能会出现图11界面，如果没有出现，则忽略图11。&lt;/p&gt;

&lt;p&gt;图11：是否覆盖掉所有系统数据，如果是重装系统，数据已经做过备份，则直接选“Fresh Installation”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/012.png&quot; alt=&quot;&quot; /&gt;
图 12&lt;/p&gt;

&lt;p&gt;图12：设定主机名（hostname），按照要求进行设置即可。&lt;/p&gt;

&lt;p&gt;备注：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;在图11页面的左下角，也可以通过“配置网络”按钮来设定网络，但不建议在此通过页面来配置网络（因为可能碰到乱七八糟的问题），而建议安装完系统后，通过简单命令来配置网络。&lt;/li&gt;
  &lt;li&gt;也可以安装完系统后，打开文件”/etc/sysconfig/network”，修改其中HOSTNAME字段。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/013.png&quot; alt=&quot;&quot; /&gt;
图 13&lt;/p&gt;

&lt;p&gt;图13：选定时区，选定“Asia/Shanghai”即可。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/014.png&quot; alt=&quot;&quot; /&gt; 
图 14&lt;/p&gt;

&lt;p&gt;图14：设定root密码&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/015.png&quot; alt=&quot;&quot; /&gt; 
图 15：选“Use Anyway”&lt;/p&gt;

&lt;p&gt;图15：提示密码不够安全，直接点击“Use Anyway”（无论如何都使用）即可。&lt;/p&gt;

&lt;p&gt;特别说明：至此，安装并没有结束，下面“2.2磁盘分区”部分才是重点。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;2.2.	磁盘分区&lt;/h3&gt;

&lt;p&gt;从图16开始，我们将进行磁盘分区，这一部分有些配置的东西，需要认真看了。&lt;/p&gt;

&lt;p&gt;备注：在此之前，需要补充一点理论知识：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.	为什么要进行磁盘分区？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;磁盘分区两点考虑，也就是说两个好处：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;数据安全：不同磁盘分区之间相互独立，某个分区损坏，不会影响其他分区内的数据；&lt;/li&gt;
  &lt;li&gt;读写性能：读写数据时，磁盘分区对应一段连续的磁柱，由于磁柱集中，提升数据的读写效率；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.	磁盘分区要分为几个区？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;磁盘分区方案，官网建议[7]，应该包含如下几个分区：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;分区&lt;/th&gt;
      &lt;th&gt;作用&lt;/th&gt;
      &lt;th&gt;官方建议大小&lt;/th&gt;
      &lt;th&gt;此次安装使用&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;/boot&lt;/td&gt;
      &lt;td&gt;存放OS kernel，以及系统bootstrap过程要使用的其他文件&lt;/td&gt;
      &lt;td&gt;&amp;gt;250MB&lt;/td&gt;
      &lt;td&gt;500MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;swap&lt;/td&gt;
      &lt;td&gt;虚拟内存：当内存空间不足时使用此空间&lt;/td&gt;
      &lt;td&gt;至少4GB，推荐为内存的1~2倍&lt;/td&gt;
      &lt;td&gt;128GB （系统内存64GB）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;/&lt;/td&gt;
      &lt;td&gt;存放：系统安装文件&lt;/td&gt;
      &lt;td&gt;3~5GB&lt;/td&gt;
      &lt;td&gt;60GB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;/home&lt;/td&gt;
      &lt;td&gt;存放：user data \n单独分区的目标：将user data与系统文件隔离&lt;/td&gt;
      &lt;td&gt;没有&lt;/td&gt;
      &lt;td&gt;100GB（实际是sda磁盘的剩余空间）&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;步骤 8. 	在图16界面，选择“Use All Space”，同时，勾选左下的“Review and modify partitioning layout”，目标：进入磁盘分区设置页面，调整磁盘分区。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/016.png&quot; alt=&quot;&quot; /&gt;
图 16：选“Use All Space”和勾选“Review and modify partitioning layout”&lt;/p&gt;

&lt;p&gt;中间可能要等待一段时间&lt;/p&gt;

&lt;p&gt;步骤 9. 	在图17所示页面，选择要进行分区的的磁盘，通常将“Data Storage Devicess”中所有磁盘都添加到“Install Target Devices”中，添加结果如图18所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/017.png&quot; alt=&quot;&quot; /&gt; 
图 17&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/018.png&quot; alt=&quot;&quot; /&gt; 
图 18&lt;/p&gt;

&lt;p&gt;图18：将“Data Storage Devicess”中所有磁盘都添加到“Install Target Devices”后的结果。 &lt;/p&gt;

&lt;p&gt;步骤 10. 	在图19所示页面，删除磁盘sda默认的分区：LVM Volume groups下的vg_cib61、sda下sda1和sda2；删除结果如图20所示。&lt;/p&gt;

&lt;p&gt;特别说明：要删除sda2分区，需要先删除LVM Volume groups下的vg_cib61。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/019.png&quot; alt=&quot;&quot; /&gt; 
图 19&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/020.png&quot; alt=&quot;&quot; /&gt;
图 20&lt;/p&gt;

&lt;p&gt;图20：删除sda上所有分区之后的结果。 &lt;/p&gt;

&lt;p&gt;步骤 11. 	在图20页面，按照提前规划的分区方案，在sda磁盘的Free空间上，依次划分/boot、swap、/、/home共计4个分区。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/021.png&quot; alt=&quot;&quot; /&gt; 
图 21&lt;/p&gt;

&lt;p&gt;图21：选择sda下Free空间，” Create” “Standard Partition”，即可进行创建分区，具体“/boot、swap、/、/home”的分区操作，依次参考图22、图23、图24、图25。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/022.png&quot; alt=&quot;&quot; /&gt; 
图 22&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/023.png&quot; alt=&quot;&quot; /&gt;
图 23&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/024.png&quot; alt=&quot;&quot; /&gt;
图 24&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/025.png&quot; alt=&quot;&quot; /&gt;
图 25&lt;/p&gt;

&lt;p&gt;步骤 12. 	这一步是进行LVM设置，如果没有LVM创建LV的需要，请直接跳过这一步，直接参考“步骤13”。 &lt;/p&gt;

&lt;p&gt;在此之前，补充一点LVM相关的理论知识：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.	为什么要用LVM？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LVM要解决的典型问题&lt;/strong&gt;：一块磁盘的空间160GB，其存满数据后，需要扩容，怎么办？传统静态分区时，需要将磁盘中近160GB的数据复制到1TB的磁盘上，然后，使用1TB的磁盘替换掉原来160GB的磁盘。（这个是传统扩容的基本原理，还有其他的原理吗？）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LVM基本原理&lt;/strong&gt;：要解决上面磁盘空间不足时，磁盘的扩容问题，LVM提供了一个基本思路：LVM将底层的磁盘封装抽象为逻辑卷（logical volume），上层应用不直接从物理磁盘分区中读数据，而是从逻辑卷中读数据；LVM负责底层磁盘到逻辑卷的映射和管理；增加底层磁盘时，通过LVM可以为逻辑卷动态扩充容量，而这对上层应用是无影响的（透明的）。&lt;/p&gt;

&lt;p&gt;说这么多，总结一点：LVM能够将多个小磁盘抽象为一个大逻辑卷，并且支持磁盘的动态扩容，提高了磁盘管理的灵活性。&lt;/p&gt;

&lt;p&gt;图26、图27、图28、图29：展示了在sdb1、sdc1、sdd1上创建一个大小约为850GB大小的VG（命名为vg_cib61），并且在这一VG上创建一个500GB大小的LV（lv_00）的基本过程。脑袋疼，不想多说，请自行查找其他资料。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/026.png&quot; alt=&quot;&quot; /&gt; 
图 26&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/027.png&quot; alt=&quot;&quot; /&gt;
图 27&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/028.png&quot; alt=&quot;&quot; /&gt;
图 28&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/029.png&quot; alt=&quot;&quot; /&gt;
图 29&lt;/p&gt;

&lt;p&gt;图29：创建Logical Volume时，并没有设置Mount Point，因为当前并不能确定挂载目录，装完系统之后，可以通过命令进行挂载。&lt;/p&gt;

&lt;p&gt;步骤 13. 	设置完磁盘分区后，到达图30所示界面，直接点击“Next”。&lt;/p&gt;

&lt;p&gt;特别说明：如果没有在步骤12中设置LVM，则没有图30中的“LVM Volume Groups”部分。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/030.png&quot; alt=&quot;&quot; /&gt;
图 30&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/031.png&quot; alt=&quot;&quot; /&gt;
图 31：选“Write changes to disk”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/032.png&quot; alt=&quot;&quot; /&gt;
图 32&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/033.png&quot; alt=&quot;&quot; /&gt;
图 33&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/034.png&quot; alt=&quot;&quot; /&gt;
图 34：选“Basic Server”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/035.png&quot; alt=&quot;&quot; /&gt;
图 35&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/centos-installation/036.png&quot; alt=&quot;&quot; /&gt;
图 36&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;3.	配置网络&lt;/h2&gt;

&lt;p&gt;安装完系统之后，需要进行网络配置，目标：保证机器能够入网。&lt;/p&gt;

&lt;p&gt;通常直接修改/etc/sysconfig/network-scripts/ifcfg-eth0文件即可，此次使用的是静态配置IP方式，因此需要进行如下修改（保持ifcfg-eth0文件中其他字段不变）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ONBOOT=yes
BOOTPROTO=static
IPADDR=168.7.2.111
NETMASK=255.255.255.0
GATEWAY=168.7.2.126
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;特别说明：服务器上有eth0–eth5，共计6个网口，需要根据具体情况，修改配置文件，上例中修改的是ifcfg-eth0文件，而在其他服务器上，如果网线插在eth3口，则需要修改ifcfg-eth3文件。&lt;/p&gt;

&lt;p&gt;有个小问题，值得说一下：服务器通常带有eth0–eth5多个网口，如何将eth0~5与实际的物理网口对应起来？&lt;/p&gt;

&lt;p&gt;RE：需要借助工具：ethtool，执行命令&lt;code&gt;ethtool -p eth0&lt;/code&gt;，再去看看那排网口，会有发现的~执行Ctrl + C，即可终止此命令。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;4.	格式化磁盘并挂载&lt;/h2&gt;

&lt;p&gt;场景 1.	格式化单个磁盘，并进行挂载，命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 格式化磁盘
mkfs -t ext3 /dev/sdb1
# 新建挂载点
mkdir -p /srv/hadoop/data1
# 挂载磁盘
mount /dev/sdb1 /srv/hadoop/data1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;场景 2.	批量格式化多个磁盘，并进行挂载，本质上就是重复“场景1”，只不过使用shell脚本来实现，脚本如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in {b..k}; do mkfs -t ext3 /dev/sd${i}1; done

for i in {1..10}; do mkdir -p /srv/hadoop/data${i}; done

array=(b c d e f g h i j k)
for((i=0;i&amp;lt;${#array[@]};i++)); do mount /dev/sd${array[i]}1 /srv/hadoop/data$(($i+1)); done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;场景 3.	设置开机自动挂载磁盘&lt;/p&gt;

&lt;p&gt;上面两个场景中，都涉及到mount磁盘到某个目录，但如果系统一不小心重启了，这些磁盘就需要重新挂载。解决办法：在fstab文件中设置开机自动挂载磁盘。
通过命令：man  fstab就可以查看fstab文件每列的含义：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;th&gt;6&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;special device&amp;gt;&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;mount point&amp;gt;&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;fs type&amp;gt;&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;mount options&amp;gt;&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;dump&amp;gt;&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code&gt;&amp;lt;fsck&amp;gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;上述/etc/fstab文件每行数据，都有6个字段，如上图所示，简要说明几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;间隔符号：不同字段之间使用 ”空格” 或者 “Tab” 键来间隔&lt;/li&gt;
  &lt;li&gt;special device：要挂载的设备，例如：/dev/sdb1;&lt;/li&gt;
  &lt;li&gt;mount point：设备挂载的目标目录；&lt;/li&gt;
  &lt;li&gt;fs type：要挂载的设备上文件系统的类型；&lt;/li&gt;
  &lt;li&gt;options：mount命令进行挂载时，输入的参数；&lt;/li&gt;
  &lt;li&gt;dump：是否要对此文件系统进行备份，0代表不做dump备份，1代表需要dump备份，2代表也需要dump备份，但2的重要程度低于1；&lt;/li&gt;
  &lt;li&gt;fsck：系统启动时，是否检测文件系统的完整性，0代表不检测，根目录/需要设置为1，其他需要开机扫描的文件系统设置为2；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;来个fstab文件的样例，朝着这个格式来做就可以：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/dev/sdb1  /srv/hadoop/data1  ext3  defaults  0  0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置完fstab文件，一定要来一条命令：&lt;code&gt;mount -a&lt;/code&gt;
含义：&lt;code&gt;Mount all filesystems (of the given types) mentioned in fstab.&lt;/code&gt;
这一命令可用于检查fstab文件中的配置是否正确。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;5.	参考来源&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.centos.org/about/&quot;&gt;CentOS简介&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.redhat.com/en/about/press-releases/red-hat-and-centos-join-forces&quot;&gt;Red Hat and CentOS Project Join Forces to Speed Open Source Innovation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://lists.centos.org/pipermail/centos/2012-November/130123.html&quot;&gt;CentOS 6 docs参考RHEL 6即可&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/&quot;&gt;RHEL官方文档&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/index.html&quot;&gt;RHEL 6官文文档“Installation Guide”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/s1-x86-bootloader.html&quot;&gt;设定bootloader&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/s2-diskpartrecommend-x86.html&quot;&gt;Recommended Partitioning Schema&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;section-6&quot;&gt;6.	附录&lt;/h2&gt;

&lt;p&gt;几个有用的命令：&lt;/p&gt;

&lt;p&gt;命令 1. 	&lt;code&gt;dmidecode -t 1&lt;/code&gt;，查看当前服务器的序列号。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost ~]# dmidecode -t 1
# dmidecode 2.11
SMBIOS 2.7 present.

Handle 0x0100, DMI type 1, 27 bytes
System Information
		Manufacturer: HP
		Product Name: ProLiant ********
		Version: Not Specified
		Serial Number: ********
		UUID: ****-****-****-****-****
		Wake-up Type: Power Switch
		SKU Number: ****-****
		Family: ProLiant
&lt;/code&gt;&lt;/pre&gt;

</content>
   </entry>
   
   <entry>
     <title>Flume 1.5.0.1 User Guide：Event Serializers</title>
     <link href="http://ningg.github.com/flume-user-guide-event-serializer"/>
     <updated>2014-10-25T00:00:00+08:00</updated>
     <id>http://ningg.github.com/flume-user-guide-event-serializer</id>
     <content type="html">&lt;p&gt;The &lt;code&gt;file_roll sink&lt;/code&gt; and the &lt;code&gt;hdfs sink&lt;/code&gt; both support the &lt;code&gt;EventSerializer&lt;/code&gt; interface. Details of the &lt;code&gt;EventSerializers&lt;/code&gt; that ship with Flume are provided below.
（Event serializer，事件序列化，）&lt;/p&gt;

&lt;h2 id=&quot;body-text-serializer&quot;&gt;Body Text Serializer&lt;/h2&gt;

&lt;p&gt;Alias: text. This interceptor writes the body of the event to an output stream without any transformation or modification. The event headers are ignored. Configuration options are as follows:&lt;/p&gt;

&lt;p&gt;Property Name	Default	Description
appendNewline	true	Whether a newline will be appended to each event at write time. The default of true assumes that events do not contain newlines, for legacy reasons.
Example for agent named a1:&lt;/p&gt;

&lt;p&gt;a1.sinks = k1
a1.sinks.k1.type = file_roll
a1.sinks.k1.channel = c1
a1.sinks.k1.sink.directory = /var/log/flume
a1.sinks.k1.sink.serializer = text
a1.sinks.k1.sink.serializer.appendNewline = false
Avro Event Serializer&lt;/p&gt;

&lt;p&gt;Alias: avro_event. This interceptor serializes Flume events into an Avro container file. The schema used is the same schema used for Flume events in the Avro RPC mechanism. This serializers inherits from the AbstractAvroEventSerializer class. Configuration options are as follows:&lt;/p&gt;

&lt;p&gt;Property Name	Default	Description
syncIntervalBytes	2048000	Avro sync interval, in approximate bytes.
compressionCodec	null	Avro compression codec. For supported codecs, see Avro’s CodecFactory docs.
Example for agent named a1:&lt;/p&gt;

&lt;p&gt;a1.sinks.k1.type = hdfs
a1.sinks.k1.channel = c1
a1.sinks.k1.hdfs.path = /flume/events/%y-%m-%d/%H%M/%S
a1.sinks.k1.serializer = avro_event
a1.sinks.k1.serializer.compressionCodec = snappy&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>Flume 1.5.0.1 User Guide：Flume Channels</title>
     <link href="http://ningg.github.com/flume-user-guide-channel"/>
     <updated>2014-10-25T00:00:00+08:00</updated>
     <id>http://ningg.github.com/flume-user-guide-channel</id>
     <content type="html">&lt;p&gt;Channels are the repositories where the events are staged on a agent. Source adds the events and Sink removes it.
（agent中events存储在channels中：source将events添加到channels，sink从channels中读取events）&lt;/p&gt;

&lt;h2 id=&quot;memory-channel&quot;&gt;Memory Channel&lt;/h2&gt;

&lt;p&gt;The events are stored in an in-memory queue with configurable max size. It’s ideal for flows that need higher throughput and are prepared to lose the staged data in the event of a agent failures. Required properties are in bold.
（events被储存在in-memory queue中，queue的大小可以设定；适用场景：高吞吐量、在agent fail时允许lose data。）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;type&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be &lt;code&gt;memory&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;capacity&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;The maximum number of events stored in the channel&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;transactionCapacity&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;The maximum number of events the channel will take from a source or give to a sink per transaction&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;keep-alive&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Timeout in seconds for adding or removing an event&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;byteCapacityBufferPercentage&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;Defines the percent of buffer between byteCapacity and the estimated total size of all events in the channel, to account for data in headers. See below.&lt;strong&gt;（什么意思？）&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;byteCapacity&lt;/td&gt;
      &lt;td&gt;see description&lt;/td&gt;
      &lt;td&gt;Maximum total bytes of memory allowed as a sum of all events in this channel. The implementation only counts the Event &lt;code&gt;body&lt;/code&gt;, which is the reason for providing the &lt;code&gt;byteCapacityBufferPercentage&lt;/code&gt; configuration parameter as well. Defaults to a computed value equal to 80% of the maximum memory available to the JVM (i.e. 80% of the -Xmx value passed on the command line). Note that if you have multiple memory channels on a single JVM, and they happen to hold the same physical events (i.e. if you are using a replicating channel selector from a single source) then those event sizes may be double-counted for channel byteCapacity purposes. Setting this value to 0 will cause this value to fall back to a hard internal limit of about 200 GB.（设置为0，则参数取值为a hard internal limit，通常为200GB；）&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：&lt;code&gt;byteCapacityBufferPercentage&lt;/code&gt;参数的含义？event是由header和body构成的，参数&lt;code&gt;byteCapacity&lt;/code&gt;约束的只是&lt;code&gt;body&lt;/code&gt;，因此，新增了&lt;code&gt;byteCapacityBufferPercentage&lt;/code&gt;参数，表示&lt;code&gt;header&lt;/code&gt;的占用空间的的比例。&lt;/p&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.channels = c1
a1.channels.c1.type = memory
a1.channels.c1.capacity = 10000
a1.channels.c1.transactionCapacity = 10000
a1.channels.c1.byteCapacityBufferPercentage = 20
a1.channels.c1.byteCapacity = 800000
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;jdbc-channel&quot;&gt;JDBC Channel&lt;/h2&gt;

&lt;p&gt;The events are stored in a persistent storage that’s backed by a database. The JDBC channel currently supports embedded Derby. This is a durable channel that’s ideal for flows where recoverability is important. Required properties are in bold.
（将events持久化存储在database中，当前JDBC channel支持embeded Derby；适用于数据流可恢复性要求较高的场景。）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;type&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be jdbc&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;db.type&lt;/td&gt;
      &lt;td&gt;DERBY&lt;/td&gt;
      &lt;td&gt;Database vendor, needs to be DERBY.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;driver.class&lt;/td&gt;
      &lt;td&gt;org.apache.derby.jdbc.EmbeddedDriver&lt;/td&gt;
      &lt;td&gt;Class for vendor’s JDBC driver&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;driver.url&lt;/td&gt;
      &lt;td&gt;(constructed from other properties)&lt;/td&gt;
      &lt;td&gt;JDBC connection URL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;db.username&lt;/td&gt;
      &lt;td&gt;“sa”&lt;/td&gt;
      &lt;td&gt;User id for db connection&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;db.password&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;password for db connection&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;connection.properties.file&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;JDBC Connection property file path&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;create.schema&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;If true, then creates db schema if not there&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;create.index&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;Create indexes to speed up lookups&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;create.foreignkey&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;transaction.isolation&lt;/td&gt;
      &lt;td&gt;“READ_COMMITTED”&lt;/td&gt;
      &lt;td&gt;Isolation level for db session READ_UNCOMMITTED, READ_COMMITTED, SERIALIZABLE, REPEATABLE_READ&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;maximum.connections&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;Max connections allowed to db&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;maximum.capacity&lt;/td&gt;
      &lt;td&gt;0 (unlimited)&lt;/td&gt;
      &lt;td&gt;Max number of events in the channel&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;sysprop.*&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;DB Vendor specific properties&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;sysprop.user.home&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Home path to store embedded Derby database&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.channels = c1
a1.channels.c1.type = jdbc
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;file-channel&quot;&gt;File Channel&lt;/h2&gt;

&lt;p&gt;（todo）&lt;/p&gt;

&lt;h2 id=&quot;spillable-memory-channel&quot;&gt;Spillable Memory Channel&lt;/h2&gt;

&lt;p&gt;The events are stored in an in-memory queue and on disk. The in-memory queue serves as the primary store and the disk as overflow. The disk store is managed using an embedded File channel. When the in-memory queue is full, additional incoming events are stored in the file channel. This channel is ideal for flows that need high throughput of memory channel during normal operation, but at the same time need the larger capacity of the file channel for better tolerance of intermittent sink side outages or drop in drain rates. The throughput will reduce approximately to file channel speeds during such abnormal situations. In case of an agent crash or restart, only the events stored on disk are recovered when the agent comes online. &lt;strong&gt;This channel is currently experimental and not recommended for use in production&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：Spillable Memory Channel当前还是试验阶段，不推荐在生产环境中使用。&lt;/p&gt;

&lt;h2 id=&quot;pseudo-transaction-channel&quot;&gt;Pseudo Transaction Channel&lt;/h2&gt;

&lt;p&gt;Warning The Pseudo Transaction Channel is only for unit testing purposes and is NOT meant for production use.
Required properties are in bold.
（&lt;strong&gt;Warning&lt;/strong&gt;：Pseudo Transaction Channel，当前用于unit testing；不要用于生产环境）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;type&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be &lt;code&gt;org.apache.flume.channel.PseudoTxnMemoryChannel&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;capacity&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;The max number of events stored in the channel&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;keep-alive&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Timeout in seconds for adding or removing an event&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;custom-channel&quot;&gt;Custom Channel&lt;/h2&gt;

&lt;p&gt;A custom channel is your own implementation of the Channel interface. A custom channel’s class and its dependencies must be included in the agent’s classpath when starting the Flume agent. The type of the custom channel is its FQCN. Required properties are in bold.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Property Name&lt;/th&gt;
      &lt;th&gt;Default&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;type&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;–&lt;/td&gt;
      &lt;td&gt;The component type name, needs to be a &lt;code&gt;FQCN&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Example for agent named a1:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.channels = c1
a1.channels.c1.type = org.example.MyChannel
&lt;/code&gt;&lt;/pre&gt;

</content>
   </entry>
   
   <entry>
     <title>JSON简介以及JAVA API</title>
     <link href="http://ningg.github.com/json-java-api"/>
     <updated>2014-10-24T00:00:00+08:00</updated>
     <id>http://ningg.github.com/json-java-api</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;最近做个数据采集的东西，初步决定使用JSON作为数据交换格式，OK，学习整理一下。&lt;/p&gt;

&lt;h2 id=&quot;json&quot;&gt;JSON简介&lt;/h2&gt;

&lt;p&gt;JSON（JavaScript Object Notation），轻量级的数据交换格式，易于阅读和编写，同时机器也很容易输出JSON格式、解析JSON格式。JSON是完全独立于语言的文本格式，这使其成为理想的数据交换语言。&lt;/p&gt;

&lt;p&gt;JSON中两类基本结构：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;key:value&lt;/code&gt;：键-值对，通过key来标识value；&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;array&lt;/code&gt;：有序的数组；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;JSON利用上述的两类基本结构，实现了集中基本数据类型：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Object&lt;/strong&gt;：An object is an unordered set of name/value pairs. An object begins with { (left brace) and ends with } (right brace). Each name is followed by : (colon) and the name/value pairs are separated by , (comma).
（无序的key-value对，以&lt;code&gt;{&lt;/code&gt;开头，以&lt;code&gt;}&lt;/code&gt;结尾，其内部以&lt;code&gt;,&lt;/code&gt;逗号分隔）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/json-java-api/object.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Array&lt;/strong&gt;：An array is an ordered collection of values. An array begins with &lt;code&gt;[&lt;/code&gt; (left bracket) and ends with &lt;code&gt;]&lt;/code&gt; (right bracket). Values are separated by , (comma).
（有序的value序列，以&lt;code&gt;[&lt;/code&gt;开头，以&lt;code&gt;]&lt;/code&gt;结尾，其内部以&lt;code&gt;,&lt;/code&gt;逗号分隔）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/json-java-api/array.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Value&lt;/strong&gt;：A value can be a string in double quotes, or a number, or true or false or null, or an object or an array. These structures can be nested.
（Value表示的内容比较广，既可以是”“包含起来的String，也可以是数字，或者&lt;code&gt;true&lt;/code&gt;`false&lt;code&gt;；另一方面，也可以是&lt;/code&gt;Object`或者array）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/json-java-api/value.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;String&lt;/strong&gt;：A string is a sequence of zero or more Unicode characters, wrapped in double quotes, using backslash escapes. A character is represented as a single character string. A string is very much like a C or Java string.
（&lt;code&gt;&quot;&quot;&lt;/code&gt;双引号包含起来的Unicode 字符，其中可以使用&lt;code&gt;backslash&lt;/code&gt;来标识转义字符）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/json-java-api/string.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Number&lt;/strong&gt;：A number is very much like a C or Java number, except that the octal and hexadecimal formats are not used.
（不支持octal和hexadecimal formats）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/json-java-api/number.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Whitespace can be inserted between any pair of tokens. Excepting a few encoding details, that completely describes the language.
（任何符号之间都可插入空格&lt;code&gt;whitespace&lt;/code&gt;）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：JSON中&lt;code&gt;key&lt;/code&gt;能否重复？&lt;/p&gt;

&lt;h2 id=&quot;jsonjava-api&quot;&gt;处理JSON的JAVA API&lt;/h2&gt;

&lt;p&gt;处理JSON格式数据，无非两条路：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;JDK 自带的 Java API；（官方）&lt;/li&gt;
  &lt;li&gt;第三方jar包提供的java API；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;特别说明&lt;/strong&gt;：&lt;a href=&quot;https://jcp.org/en/jsr/detail?id=353&quot;&gt;JSR 353&lt;/a&gt;指出，今后的Java SE 6以及Java EE 7中要添加API来支持JSON格式数据的解析和转换。当前个人查证，在JDK6u30中没有java API来解析JSON；Java EE 7中，已经提供了&lt;code&gt;javax.json&lt;/code&gt;包来支持解析JSON。&lt;/p&gt;

&lt;p&gt;当前项目需求，在JDK5以及之上的版本都能进行JSON字符串与JSON对象之间的转换，OK，那直接上第三方jar包得了。&lt;/p&gt;

&lt;h3 id=&quot;javajsonjar&quot;&gt;java解析JSON的第三方jar包&lt;/h3&gt;

&lt;p&gt;从[JSON 主页][介绍 JSON]可知，当前，有很多的第三方jar包：org.json、org.json.me、jsonp、&lt;a href=&quot;http://jackson.codehaus.org/&quot;&gt;Jackson Json Processor&lt;/a&gt;、&lt;a href=&quot;http://code.google.com/p/google-gson/&quot;&gt;google-gson&lt;/a&gt;、Json-lib…，有点多呀，到底选哪个呢？当前初步考虑在如下两个中选：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spring中使用的是&lt;a href=&quot;http://jackson.codehaus.org/&quot;&gt;org.codehaus.jackson&lt;/a&gt;详细版本号&lt;code&gt;1.9.13&lt;/code&gt;（后来Spring 3.2中已经支持Jackson2了）&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://code.google.com/p/google-gson/&quot;&gt;google-gson&lt;/a&gt;的官方网站打不开，不过在maven中央仓库找到了gson的&lt;a href=&quot;http://repo1.maven.org/maven2/com/google/code/gson/gson/2.2.3/&quot;&gt;jar包&lt;/a&gt;，虽然无法查看官网的文档，不过maven中央仓库的javadoc、source文件也可以用来学习。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最终决定采用gson，其基本的JSON操作，参考：&lt;a href=&quot;http://blog.csdn.net/lk_blog/article/details/7685169&quot;&gt;JSON转换利器:Gson&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;json-1&quot;&gt;解析JSON字符串的效率问题&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://ifeve.com/json-java-api/&quot;&gt;处理JSON的Java API ：JSON的简介&lt;/a&gt;中提到解析JSON的API分为两类：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对象模型API&lt;/li&gt;
  &lt;li&gt;流API&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这两种方式在原理、效率上都有差异，TODO&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;参考来源&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.json.org/json-zh.html&quot;&gt;介绍 JSON&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://ifeve.com/json-java-api/&quot;&gt;处理JSON的Java API ：JSON的简介&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jcp.org/en/jsr/detail?id=353&quot;&gt;JSR 353&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/lk_blog/article/details/7685169&quot;&gt;JSON转换利器:Gson&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>Flume 1.5.0.1：如何将flume聚合的数据送入Kafka</title>
     <link href="http://ningg.github.com/flume-with-kafka"/>
     <updated>2014-10-24T00:00:00+08:00</updated>
     <id>http://ningg.github.com/flume-with-kafka</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;Flume收集分布在不同机器上的日志信息，聚合之后，将信息送入Kafka消息队列，问题来了：如何将Flume输出的信息送入Kafka中？&lt;/p&gt;

&lt;p&gt;定一个场景：flume读取apache的访问日志，然后送入Kafka中，最终消息从Kafka中取出，显示在终端屏幕上（stdout）。&lt;/p&gt;

&lt;h2 id=&quot;flume&quot;&gt;Flume复习&lt;/h2&gt;

&lt;p&gt;整理一下Flume的基本知识，参考来源有两个：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://flume.apache.org/documentation.html&quot;&gt;Flume Documentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Book: &lt;a href=&quot;http://files.hii-tech.com/Book/Hadoop/PacktPub.Apache.Flume.Distributed.Log.Collection.for.Hadoop.Jul.2013.pdf&quot;&gt;apache-flume-distributed-log-collection-hadoop&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-1&quot;&gt;几个概念&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Flume &lt;strong&gt;event&lt;/strong&gt;: a unit of data flow, having a byte payload and an optional set of string attributes.（event中包含了，payload和attributes）&lt;/li&gt;
  &lt;li&gt;Flume &lt;strong&gt;agent&lt;/strong&gt;: a (JVM) process, that hosts the components through which events flow from an external source to the next destination(hop).（agent对应JVM process）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Channel&lt;/strong&gt;:  passive store, keeps the event until it’s consumded by a Flume Sink.（Channel不会主动消费event，其等待Sink来取数据，会在本地备份Event）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sink&lt;/strong&gt;: remove the event from the channel and put it into external repository.（Sink主动从Channel中取出event）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/flume-user-guide/UserGuide_image00.png&quot; alt=&quot;&quot; /&gt; &lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;练习&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;场景&lt;/strong&gt;：Flume收集apache访问日志，然后，在标准终端（stdout）显示。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分析&lt;/strong&gt;：Flume官方文档中，已经给出了一个demo，flume从&lt;code&gt;localhost:port&lt;/code&gt;收集数据，并在标准终端上显示。基于这一场景，只需要修改Source即可。&lt;/p&gt;

&lt;h4 id=&quot;section-3&quot;&gt;构造实例&lt;/h4&gt;

&lt;p&gt;通过参阅Flume官网，得知&lt;code&gt;ExecSource&lt;/code&gt;可用于捕获命令的输出，并将输出结果按行构造event，&lt;code&gt;tail -F [local file]&lt;/code&gt;命令用于查阅文件&lt;code&gt;[local file]&lt;/code&gt;的新增内容；在&lt;code&gt;$FLUME_HOME/conf&lt;/code&gt;目录下，新建文件&lt;code&gt;apache_log_scan.log&lt;/code&gt;，内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a1.sources = r1
a1.sinks = k1
a1.channels = c1

a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /var/log/httpd/access_log

a1.sinks.k1.type = logger

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动Flume agent，命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[ningg@localhost flume]$ cd conf
[ningg@localhost  conf]$ sudo ../bin/flume-ng agent --conf ../conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console
...
...
 Component type: SOURCE, name: r1 started
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后访问一下Apache承载的网站，可以看到上面的窗口也在输出信息，即，已经在捕获Apache访问日志&lt;code&gt;access_log&lt;/code&gt;的增量了。（可以另起一个窗口，通过&lt;code&gt;tail -F access_log&lt;/code&gt;查看日志的实际内容）&lt;/p&gt;

&lt;h4 id=&quot;section-4&quot;&gt;存在的问题&lt;/h4&gt;

&lt;p&gt;通过比较Flume上sink的输出、&lt;code&gt;tail -F access_log&lt;/code&gt;命令的输出，发现输出有差异：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Flume上logger类型sink的输出
Event: { headers:{} body: 31 36 38 2E 35 2E 31 33 30 2E 31 37 35 20 2D 20 168.5.130.175 -  }

# access_log原始文件上的新增内容（长度超过上面logger sink的输出）
168.5.130.175 - - [23/Oct/2014:16:34:59 +0800] &quot;GET /...&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;思考：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;logger类型的sink，遇到&lt;code&gt;[&lt;/code&gt;字符就结束？&lt;/li&gt;
  &lt;li&gt;logger类型的sink，有字符长度的限制吗？&lt;/li&gt;
  &lt;li&gt;channel有长度限制？channel中存储的event是什么形式存储的？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过&lt;code&gt;vim access_log&lt;/code&gt;，向文件最后添加一行内容，发现应该是logger类型的sink，对于event的长度有限制；或者，memory类型的channel对于存储的event有限制。
&lt;strong&gt;RE&lt;/strong&gt;：上述问题已经解决，Logger sink输出内容不完整，详情可参考&lt;a href=&quot;/flume-advance-logger-sink&quot;&gt;Advanced Logger Sink&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;kafka&quot;&gt;Kafka复习&lt;/h2&gt;

&lt;p&gt;下面Kafka的相关总结都参考自：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://kafka.apache.org/documentation.html&quot;&gt;Kafka 0.8.1 Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-5&quot;&gt;几个概念&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka-documentation/producer_consumer.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;消息队列&lt;/strong&gt;：Kafka充当消息队列，producer将message放入Kafka集群，consumer从Kafka集群中读取message；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;内部结构&lt;/strong&gt;：按照topic来存放message，每个topic对应一个partitioned log，其中包含多个partition，每个都是一个有序的、message队列；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;消息存活时间&lt;/strong&gt;：在设定的时间内，kafka始终保存所有的message，即使message已经被consume；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;consume message&lt;/strong&gt;：每个consumer，只需保存在log中的offset，并且这个offset完全由consumer控制，可自由调整；鉴于此，cousumer之间相互基本没有影响；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka-documentation/log_anatomy.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;针对上面每个topic对应的partitioned log，其中包含了多个partition，这样设计有什么好处？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;single server上，单个log的大小由文件系统限制，而采用多partition模式，虽然单个partition也受限，但partition的个数不受限制；&lt;/li&gt;
  &lt;li&gt;多个partition时，每个partition都可作为一个unit，以此来支撑并发处理；&lt;/li&gt;
  &lt;li&gt;partition是分布式存储的，即，某个server上的partition可能也存在其他的server上，两点好处：
    &lt;ul&gt;
      &lt;li&gt;方便不同server之间的partition共享；&lt;/li&gt;
      &lt;li&gt;配置每个partition的复制份数，提升系统可靠性；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;partition对应的server，分为两个角色：&lt;code&gt;leader&lt;/code&gt;和&lt;code&gt;follower&lt;/code&gt;：
    &lt;ul&gt;
      &lt;li&gt;每个partition都对应一个server担当&lt;code&gt;leader&lt;/code&gt;角色：负责所有的read、write；&lt;/li&gt;
      &lt;li&gt;其他server担&lt;code&gt;follower&lt;/code&gt;角色：重复&lt;code&gt;leader&lt;/code&gt;的操作；&lt;/li&gt;
      &lt;li&gt;如果&lt;code&gt;leader&lt;/code&gt;崩溃，则自动推选一个&lt;code&gt;follower&lt;/code&gt;升级为&lt;code&gt;leader&lt;/code&gt;；&lt;/li&gt;
      &lt;li&gt;server只对其上的部分partition担当&lt;code&gt;leader&lt;/code&gt;角色，方便cluster的均衡；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Producer产生的数据放到topic的哪个partition下？集中方式：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;轮询：保证每个partition以均等的机会存储message，均衡负载；&lt;/li&gt;
  &lt;li&gt;函数：根据key in the message来确定partition；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Consumer读取message有两种模式：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;queueing：多个consumer构成一个pool，然后，每个message只被其中一个consumer处理；&lt;/li&gt;
  &lt;li&gt;publish-subscribe：向所有的consumer广播message；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kafka中通过将consumer泛化为consumer group来实现，来支持上述两种模式，关于此，详细说一下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;consumer都标记有consumer group name，每个message都发送给对应consumer group中的一个consumer instance，consumer instance可以是不同的进程，也可以分布在不同的物理机器上；&lt;/li&gt;
  &lt;li&gt;若所有的consumer instances都属于同一个consume group，则为queuing轮询的均衡负载；&lt;/li&gt;
  &lt;li&gt;若所有的consumer instances都属于不同的consume group，则为publish-subscribe，message广播到所有的consumer；&lt;/li&gt;
  &lt;li&gt;实际场景下，topic对应为数不多的几个consumer group，即，consumer group类似&lt;code&gt;logical subscriber&lt;/code&gt;；每个group中有多个consumer，目的是提升可扩展性和容错能力。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka-documentation/consumer-groups.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：几个问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;consumer group是与topic对应的？还是partition对应？&lt;/li&gt;
  &lt;li&gt;consumer group方式能够提升可扩展性和容错能力？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ordering guarantee，Kafka保证message按序处理，同时也保证并行处理，几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;单个partition中的message保证按序处理，同时一个partition只能对应一个consumer instance；&lt;/li&gt;
  &lt;li&gt;不同partition之间，不保证顺序处理，多个partition实现了并行处理；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：同一个partition中的message，当其中一个message A被指派给一个consumer instance后，在message A被处理完之前，message B是否会被指派出去？&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;小结&lt;/h3&gt;

&lt;p&gt;Kafka通过 partition data by key 和 pre-partition ordering，满足了大部分需求。如果要保证所有message都顺序处理，则将topic设置为only one partition，此时，变为串行处理。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：单个partition是以什么形式存储在server上的？纯粹的文档文件？&lt;/p&gt;

&lt;h2 id=&quot;section-7&quot;&gt;参考来源&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://flume.apache.org/documentation.html&quot;&gt;Flume Documentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Book: &lt;a href=&quot;http://files.hii-tech.com/Book/Hadoop/PacktPub.Apache.Flume.Distributed.Log.Collection.for.Hadoop.Jul.2013.pdf&quot;&gt;apache-flume-distributed-log-collection-hadoop&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
 
</feed>
