<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
   <title>NingG.github.com</title>
   <link href="http://ningg.github.com/atom.xml" rel="self" type="application/atom+xml"/>
   <link href="http://ningg.github.com" rel="alternate" type="text/html" />
   <updated>2015-01-05T21:51:15+08:00</updated>
   <id>http://ningg.github.com</id>
   <author>
     <name></name>
     <email></email>
   </author>

   
   <entry>
     <title>存在感</title>
     <link href="http://ningg.github.com/natural-law"/>
     <updated>2015-01-03T00:00:00+08:00</updated>
     <id>http://ningg.github.com/natural-law</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;最近看来一个现实咋骗案例：&lt;a href=&quot;http://video.sina.com.cn/p/news/s/v/2015-01-03/232964466971.html&quot;&gt;团伙冒充国防部诈骗 办公室豪华惊呆民警&lt;/a&gt;，&lt;/p&gt;

&lt;div&gt;&lt;object id=&quot;ssss&quot; width=&quot;480&quot; height=&quot;370&quot;&gt;&lt;param name=&quot;allowScriptAccess&quot; value=&quot;always&quot; /&gt;&lt;embed pluginspage=&quot;http://www.macromedia.com/go/getflashplayer&quot; src=&quot;http://you.video.sina.com.cn/api/sinawebApi/outplayrefer.php/video_id=249210699/s.swf&quot; type=&quot;application/x-shockwave-flash&quot; name=&quot;ssss&quot; allowfullscreen=&quot;true&quot; allowscriptaccess=&quot;always&quot; width=&quot;480&quot; height=&quot;370&quot; /&gt;&lt;/object&gt;&lt;/div&gt;

&lt;h2 id=&quot;section-1&quot;&gt;几点回顾&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;事出反常，必为妖：利润超出常理，高普通利润2~20倍；&lt;/li&gt;
  &lt;li&gt;假作真时，真亦假：假的东西，精心准备之后，比真的更真；&lt;/li&gt;
  &lt;li&gt;几个基本心理特点：
    &lt;ul&gt;
      &lt;li&gt;突发情况的警惕：保持警惕，认为不可能的事情，特别是凭空出来的好运、好机会，保持警惕，及时拒绝进一步了解这一“好运”；&lt;/li&gt;
      &lt;li&gt;观点的坚持：选择动作发生后，通常会因为选择而坚持，无法随着条件的变化，重新客观的审视问题；&lt;/li&gt;
      &lt;li&gt;以貌取人：涉及利润时，一定排除因为身份、装扮带来的信任感；&lt;/li&gt;
      &lt;li&gt;利令智昏：利润达到一定程度时，无法客观思考，或者倾向性思考，总向好的方面打算；而，真正应该做的是：往最坏的方面思考和打算；&lt;/li&gt;
      &lt;li&gt;时机：错过的不是机会，机会不会错过，宁愿放弃机会，也不在稀里糊涂中做决定；&lt;/li&gt;
      &lt;li&gt;自我认识：通常一个人会高估自己、低估他人，当高估自己时，会产生自己掌控全局的幻想，此时，更易被利用；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;意识到人共有的心里特点，并在做决断时，提醒自己有这些因素，可能导致一些结果。&lt;/p&gt;

&lt;p&gt;突然想起来，某人说：做事情先看人，人是否值得信任，人对了，才考虑接下来的事情；否则，基本不考虑。&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>IntelliJ IDEA</title>
     <link href="http://ningg.github.com/intellij-idea"/>
     <updated>2014-12-30T00:00:00+08:00</updated>
     <id>http://ningg.github.com/intellij-idea</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;显示帮助信息&lt;/h2&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;alt + h&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;显示帮助列表&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;通过&lt;code&gt;alt + h&lt;/code&gt;快捷操作显示出的帮助列表，很重要，下面给个截图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/intellij-idea/help-menu.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Help Topics：完整的帮助文档，分为不同的topics，各种各样的帮助内容；&lt;/li&gt;
  &lt;li&gt;Tip of the Day：很多快捷操作，值得每天一看；&lt;/li&gt;
  &lt;li&gt;Productivity Guide：根据具体的操作，以及操作对应的频率，给出改进建议；&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;首次登录，几个窗口&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;快捷操作&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;alt + 1&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Open Project View&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + -&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;双击&lt;code&gt;shift&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;search everywhere&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + shift + N&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;open a file by name&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + shift + A&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Find Action（什么意思？）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + E&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;open recent files&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;alt + Home&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;open Navigation Bar&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;alt + F4&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;关闭窗口&lt;em&gt;（Windows 系统自带）&lt;/em&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ESC&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;光标聚焦，返回到Edit窗口&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;shift + ESC&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;光标聚焦返回到Edit窗口，同时关闭其他窗口&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;shift + F10&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;运行 main&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;shift + F9&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Debug方式运行main&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;alt + Enter&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;显示出错信息的提示&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;alt + Right/Left&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;左右切换当前Edit View中的窗口&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + alt + U&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;show Diagram&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code&gt;ctrl + alt + shift + U&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;show Diagram popup&lt;em&gt;(新窗口中打开Diagram关系图)&lt;/em&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;几点疑问：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如何在编辑窗口中，关闭一个打开的java文件；&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ctrl + n&lt;/code&gt;和&lt;code&gt;ctrl + shift + n&lt;/code&gt;两个命令都能按照name来查找class，有什么区别？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;几点情况：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;打开Project Structure，两种方式：
    &lt;ul&gt;
      &lt;li&gt;Projcet View中&lt;code&gt;F4&lt;/code&gt;；&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;ctrl + alt + shift + S&lt;/code&gt;；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;创建class、package、Directory等，快捷操作：
    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;alt + Insert&lt;/code&gt;；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;特别说明&lt;/strong&gt;：IntelliJ IDEA中只要有list列表，就可以直接输入查询&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>Storm：Setting up a Storm cluster</title>
     <link href="http://ningg.github.com/setting-up-a-storm-cluster"/>
     <updated>2014-12-14T00:00:00+08:00</updated>
     <id>http://ningg.github.com/setting-up-a-storm-cluster</id>
     <content type="html">&lt;p&gt;This page outlines the steps for getting a Storm cluster up and running. If you’re on AWS, you should check out the &lt;a href=&quot;https://github.com/nathanmarz/storm-deploy/wiki&quot;&gt;storm-deploy&lt;/a&gt; project. &lt;a href=&quot;https://github.com/nathanmarz/storm-deploy/wiki&quot;&gt;storm-deploy&lt;/a&gt; completely automates the provisioning, configuration, and installation of Storm clusters on EC2. It also sets up Ganglia for you so you can monitor CPU, disk, and network usage.&lt;/p&gt;

&lt;p&gt;If you run into difficulties with your Storm cluster, first check for a solution is in the &lt;a href=&quot;http://storm.apache.org/documentation/Troubleshooting.html&quot;&gt;Troubleshooting&lt;/a&gt; page. Otherwise, email the mailing list.&lt;/p&gt;

&lt;p&gt;Here’s a summary of the steps for setting up a Storm cluster:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Set up a Zookeeper cluster&lt;/li&gt;
  &lt;li&gt;Install dependencies on Nimbus and worker machines&lt;/li&gt;
  &lt;li&gt;Download and extract a Storm release to Nimbus and worker machines&lt;/li&gt;
  &lt;li&gt;Fill in mandatory configurations into &lt;code&gt;storm.yaml&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Launch daemons under supervision using “storm” script and a supervisor of your choice&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;set-up-a-zookeeper-cluster&quot;&gt;Set up a Zookeeper cluster&lt;/h2&gt;

&lt;p&gt;Storm uses Zookeeper for coordinating the cluster. Zookeeper &lt;strong&gt;is not&lt;/strong&gt; used for message passing, so the load Storm places on Zookeeper is quite low. Single node Zookeeper clusters should be sufficient for most cases, but if you want failover or are deploying large Storm clusters you may want larger Zookeeper clusters. Instructions for deploying Zookeeper are &lt;a href=&quot;http://zookeeper.apache.org/doc/r3.3.3/zookeeperAdmin.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A few notes about Zookeeper deployment:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It’s critical that you run Zookeeper under supervision, since Zookeeper is fail-fast and will exit the process if it encounters any error case. See &lt;a href=&quot;http://zookeeper.apache.org/doc/r3.3.3/zookeeperAdmin.html#sc_supervision&quot;&gt;here&lt;/a&gt; for more details.&lt;/li&gt;
  &lt;li&gt;It’s critical that you set up a cron to compact Zookeeper’s data and transaction logs. The Zookeeper daemon does not do this on its own, and if you don’t set up a cron, Zookeeper will quickly run out of disk space. See &lt;a href=&quot;http://zookeeper.apache.org/doc/r3.3.3/zookeeperAdmin.html#sc_maintenance&quot;&gt;here&lt;/a&gt; for more details.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;install-dependencies-on-nimbus-and-worker-machines&quot;&gt;Install dependencies on Nimbus and worker machines&lt;/h2&gt;

&lt;p&gt;Next you need to install Storm’s dependencies on Nimbus and the worker machines. These are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Java 6&lt;/li&gt;
  &lt;li&gt;Python 2.6.6&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are the versions of the dependencies that have been tested with Storm. Storm may or may not work with different versions of Java and/or Python.&lt;/p&gt;

&lt;h2 id=&quot;download-and-extract-a-storm-release-to-nimbus-and-worker-machines&quot;&gt;Download and extract a Storm release to Nimbus and worker machines&lt;/h2&gt;

&lt;p&gt;Next, download a Storm release and extract the zip file somewhere on Nimbus and each of the worker machines. The Storm releases can be downloaded &lt;a href=&quot;http://storm.apache.org/downloads.html&quot;&gt;from here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;fill-in-mandatory-configurations-into-stormyaml&quot;&gt;Fill in mandatory configurations into storm.yaml&lt;/h2&gt;

&lt;p&gt;The Storm release contains a file at &lt;code&gt;conf/storm.yaml&lt;/code&gt; that configures the Storm daemons. You can see the default configuration values &lt;a href=&quot;https://github.com/apache/incubator-storm/blob/master/conf/defaults.yaml&quot;&gt;here&lt;/a&gt;. &lt;code&gt;storm.yaml&lt;/code&gt; overrides anything in &lt;code&gt;defaults.yaml&lt;/code&gt;. There’s a few configurations that are mandatory to get a working cluster:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;storm.zookeeper.servers&lt;/strong&gt;: This is a list of the hosts in the Zookeeper cluster for your Storm cluster. It should look something like:&lt;/p&gt;

    &lt;p&gt;storm.zookeeper.servers:
   - “111.222.333.444”
   - “555.666.777.888”&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If the &lt;strong&gt;port&lt;/strong&gt; that your Zookeeper cluster uses is different than the default, you should set &lt;strong&gt;storm.zookeeper.port&lt;/strong&gt; as well.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;storm.local.dir&lt;/strong&gt;: The Nimbus and Supervisor daemons require a directory on the local disk to store small amounts of state (like jars, confs, and things like that). You should create that directory on each machine, give it proper permissions, and then fill in the directory location using this config. For example:&lt;/p&gt;

    &lt;p&gt;storm.local.dir: “/mnt/storm”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;nimbus.host&lt;/strong&gt;: The worker nodes need to know which machine is the master in order to download topology jars and confs. For example:&lt;/p&gt;

    &lt;p&gt;nimbus.host: “111.222.333.44”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;supervisor.slots.ports&lt;/strong&gt;: For each worker machine, you configure how many workers run on that machine with this config. Each worker uses a single port for receiving messages, and this setting defines which ports are open for use. If you define five ports here, then Storm will allocate up to five workers to run on this machine. If you define three ports, Storm will only run up to three. By default, this setting is configured to run 4 workers on the ports &lt;code&gt;6700&lt;/code&gt;, &lt;code&gt;6701&lt;/code&gt;, &lt;code&gt;6702&lt;/code&gt;, and &lt;code&gt;6703&lt;/code&gt;. For example:&lt;/p&gt;

    &lt;p&gt;supervisor.slots.ports:
     - 6700
     - 6701
     - 6702
     - 6703&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;launch-daemons-under-supervision-using-storm-script-and-a-supervisor-of-your-choice&quot;&gt;Launch daemons under supervision using “storm” script and a supervisor of your choice&lt;/h2&gt;

&lt;p&gt;The last step is to launch all the Storm daemons. It is critical that you run each of these daemons under supervision. Storm is a &lt;strong&gt;fail-fast&lt;/strong&gt; system which means the processes will halt whenever an unexpected error is encountered. Storm is designed so that it can safely halt at any point and recover correctly when the process is restarted. This is why Storm keeps no state in-process – if Nimbus or the Supervisors restart, the running topologies are unaffected. Here’s how to run the Storm daemons:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Nimbus&lt;/strong&gt;: Run the command &lt;code&gt;bin/storm nimbus&lt;/code&gt; under supervision on the master machine.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Supervisor&lt;/strong&gt;: Run the command &lt;code&gt;bin/storm supervisor&lt;/code&gt; under supervision on each worker machine. The supervisor daemon is responsible for starting and stopping worker processes on that machine.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: Run the Storm UI (a site you can access from the browser that gives diagnostics on the cluster and topologies) by running the command &lt;code&gt;bin/storm ui&lt;/code&gt; under supervision. The UI can be accessed by navigating your web browser to &lt;code&gt;http://{nimbus host}:8080&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;notes(ningg)&lt;/strong&gt;：上述启动Storm UI时，需要在nimbus上启动吗？还是在supervisor上也可以？&lt;strong&gt;RE&lt;/strong&gt;：只要是Storm cluster内的节点，执行&lt;code&gt;bin/storm ui&lt;/code&gt;就可以在当前节点上启动Storm UI。&lt;/p&gt;

&lt;p&gt;As you can see, running the daemons is very straightforward. The daemons will log to the &lt;code&gt;logs/&lt;/code&gt; directory in wherever you extracted the Storm release.&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>Storm：Running topologies on a production cluster</title>
     <link href="http://ningg.github.com/running-topol-on-a-prod-cluster"/>
     <updated>2014-12-13T00:00:00+08:00</updated>
     <id>http://ningg.github.com/running-topol-on-a-prod-cluster</id>
     <content type="html">&lt;p&gt;Running topologies on a production cluster is similar to running in &lt;a href=&quot;http://storm.apache.org/documentation/Local-mode.html&quot;&gt;Local mode&lt;/a&gt;. Here are the steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define the topology (Use &lt;a href=&quot;http://storm.apache.org/apidocs/backtype/storm/topology/TopologyBuilder.html&quot;&gt;TopologyBuilder&lt;/a&gt; if defining using Java)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use &lt;a href=&quot;http://storm.apache.org/apidocs/backtype/storm/StormSubmitter.html&quot;&gt;StormSubmitter&lt;/a&gt; to submit the topology to the cluster. &lt;code&gt;StormSubmitter&lt;/code&gt; takes as input the &lt;code&gt;name&lt;/code&gt; of the topology, a &lt;code&gt;configuration&lt;/code&gt; for the topology, and the topology itself. For example:&lt;/p&gt;

    &lt;p&gt;Config conf = new Config();
  conf.setNumWorkers(20);
  conf.setMaxSpoutPending(5000);
  StormSubmitter.submitTopology(“mytopology”, conf, topology);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Create a &lt;code&gt;jar&lt;/code&gt; containing your code and all the dependencies of your code (except for Storm – the Storm jars will be added to the classpath on the worker nodes).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you’re using Maven, the &lt;a href=&quot;http://maven.apache.org/plugins/maven-assembly-plugin/&quot;&gt;Maven Assembly Plugin&lt;/a&gt; can do the packaging for you. Just add this to your &lt;code&gt;pom.xml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;plugin&amp;gt;
	&amp;lt;artifactId&amp;gt;maven-assembly-plugin&amp;lt;/artifactId&amp;gt;
	&amp;lt;configuration&amp;gt;
	  &amp;lt;descriptorRefs&amp;gt;  
		&amp;lt;descriptorRef&amp;gt;jar-with-dependencies&amp;lt;/descriptorRef&amp;gt;
	  &amp;lt;/descriptorRefs&amp;gt;
	  &amp;lt;archive&amp;gt;
		&amp;lt;manifest&amp;gt;
		  &amp;lt;mainClass&amp;gt;com.path.to.main.Class&amp;lt;/mainClass&amp;gt;
		&amp;lt;/manifest&amp;gt;
	  &amp;lt;/archive&amp;gt;
	&amp;lt;/configuration&amp;gt;
  &amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then run &lt;code&gt;mvn assembly:assembly&lt;/code&gt; to get an appropriately packaged jar. Make sure you &lt;a href=&quot;http://maven.apache.org/plugins/maven-assembly-plugin/examples/single/including-and-excluding-artifacts.html&quot;&gt;exclude&lt;/a&gt; the Storm jars since the cluster already has Storm on the classpath.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Submit the topology to the cluster using the &lt;code&gt;storm&lt;/code&gt; client, specifying the path to your jar, the classname to run, and any arguments it will use:&lt;/p&gt;

    &lt;p&gt;storm jar path/to/allmycode.jar org.me.MyTopology arg1 arg2 arg3&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;storm jar&lt;/code&gt; will submit the jar to the cluster and configure the &lt;code&gt;StormSubmitter&lt;/code&gt; class to talk to the right cluster. In this example, after uploading the jar, &lt;code&gt;storm jar&lt;/code&gt; calls the main function on &lt;code&gt;org.me.MyTopology&lt;/code&gt; with the arguments “arg1”, “arg2”, and “arg3”.&lt;/p&gt;

&lt;p&gt;You can find out how to configure your &lt;code&gt;storm&lt;/code&gt; client to talk to a Storm cluster on &lt;a href=&quot;http://storm.apache.org/documentation/Setting-up-development-environment.html&quot;&gt;Setting up development environment&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;common-configurations&quot;&gt;Common configurations&lt;/h2&gt;

&lt;p&gt;There are a variety of configurations you can set per topology. A list of all the configurations you can set can be found here. The ones prefixed with “TOPOLOGY” can be overridden on a topology-specific basis (the other ones are cluster configurations and cannot be overridden). Here are some common ones that are set for a topology:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;Config.TOPOLOGY_WORKERS&lt;/code&gt;: This sets the number of worker processes to use to execute the topology. For example, if you set this to 25, there will be 25 Java processes across the cluster executing all the tasks. If you had a combined 150 parallelism across all components in the topology, each worker process will have 6 tasks running within it as threads.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Config.TOPOLOGY_ACKERS&lt;/code&gt;: This sets the number of tasks that will track tuple trees and detect when a spout tuple has been fully processed. Ackers are an integral part of Storm’s reliability model and you can read more about them on &lt;a href=&quot;http://storm.apache.org/documentation/Guaranteeing-message-processing.html&quot;&gt;Guaranteeing message processing&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Config.TOPOLOGY_MAX_SPOUT_PENDING&lt;/code&gt;: This sets the maximum number of spout tuples that can be pending on a single spout task at once (pending means the tuple has not been acked or failed yet). It is highly recommended you set this config to prevent queue explosion.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS&lt;/code&gt;: This is the maximum amount of time a spout tuple has to be fully completed before it is considered failed. This value defaults to 30 seconds, which is sufficient for most topologies. See &lt;a href=&quot;http://storm.apache.org/documentation/Guaranteeing-message-processing.html&quot;&gt;Guaranteeing message processing&lt;/a&gt; for more information on how Storm’s reliability model works.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Config.TOPOLOGY_SERIALIZATIONS&lt;/code&gt;: You can register more serializers to Storm using this config so that you can use custom types within tuples.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;killing-a-topology&quot;&gt;Killing a topology&lt;/h2&gt;

&lt;p&gt;To kill a topology, simply run:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;storm kill {stormname}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Give the same name to &lt;code&gt;storm kill&lt;/code&gt; as you used when submitting the topology.&lt;/p&gt;

&lt;p&gt;Storm won’t kill the topology immediately. Instead, it deactivates all the spouts so that they don’t emit any more tuples, and then Storm waits &lt;code&gt;Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS&lt;/code&gt; seconds before destroying all the workers. This gives the topology enough time to complete any tuples it was processing when it got killed.&lt;/p&gt;

&lt;h2 id=&quot;updating-a-running-topology&quot;&gt;Updating a running topology&lt;/h2&gt;

&lt;p&gt;To update a running topology, the only option currently is to kill the current topology and resubmit a new one. A planned feature is to implement a &lt;code&gt;storm swap&lt;/code&gt; command that swaps a running topology with a new one, ensuring minimal downtime and no chance of both topologies processing tuples at the same time.&lt;/p&gt;

&lt;h2 id=&quot;monitoring-topologies&quot;&gt;Monitoring topologies&lt;/h2&gt;

&lt;p&gt;The best place to monitor a topology is using the &lt;code&gt;Storm UI&lt;/code&gt;. The Storm UI provides information about errors happening in tasks and fine-grained stats on the throughput and latency performance of each component of each running topology.&lt;/p&gt;

&lt;p&gt;You can also look at the worker logs on the cluster machines.&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>jmxtrans入门</title>
     <link href="http://ningg.github.com/intro-to-jmxtrans"/>
     <updated>2014-12-12T00:00:00+08:00</updated>
     <id>http://ningg.github.com/intro-to-jmxtrans</id>
     <content type="html">&lt;p&gt;（doing…）&lt;/p&gt;

&lt;p&gt;几个方面：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;jmxtrans有什么作用？&lt;/li&gt;
  &lt;li&gt;如何安装？
    &lt;ul&gt;
      &lt;li&gt;从&lt;a href=&quot;https://github.com/jmxtrans/jmxtrans/downloads&quot;&gt;jmxtrans download&lt;/a&gt;下载了一个rpm包，下文将参考&lt;a href=&quot;https://github.com/jmxtrans/jmxtrans/wiki/Installation&quot;&gt;jmxtrans Installation&lt;/a&gt;来安装jmxtrans；&lt;/li&gt;
      &lt;li&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;基本使用？（通过jmxtrans向Ganglia发送数据）
    &lt;ul&gt;
      &lt;li&gt;基本原理&lt;/li&gt;
      &lt;li&gt;jmxtrans涉及的配置&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;installing-the-rpm&quot;&gt;Installing the RPM&lt;/h2&gt;

&lt;p&gt;There is a &lt;code&gt;.rpm&lt;/code&gt; file which you can download and install on an Fedora/CentOS/RHEL machine. This makes setting up the application trivial and is highly recommended. It also makes upgrades painless as well.&lt;/p&gt;

&lt;p&gt;To install it:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Download the &lt;a href=&quot;https://github.com/jmxtrans/jmxtrans/downloads&quot;&gt;.rpm package&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;As root: &lt;code&gt;rpm -i jmxtrans_239-0.noarch.rpm&lt;/code&gt; (replace the version number)&lt;/li&gt;
  &lt;li&gt;Enter in the JVM heap size you want: &lt;code&gt;512 (megs)&lt;/code&gt; is the default. The more JVM’s you need to monitor, the more memory you will probably need. If you are getting OutOfMemoryError’s, then increase this value by editing &lt;code&gt;/etc/sysconfig/jmxtrans&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The application is installed in: &lt;code&gt;/usr/share/jmxtrans&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Configuration options are stored in: &lt;code&gt;/etc/sysconfig/jmxtrans&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;There is an init script in: &lt;code&gt;/etc/init.d/jmxtrans&lt;/code&gt; (this wraps the &lt;code&gt;jmxtrans.sh&lt;/code&gt; discussed below)&lt;/li&gt;
  &lt;li&gt;Put your .json files into: &lt;code&gt;/var/lib/jmxtrans&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;running-jmx-transformer&quot;&gt;Running Jmx Transformer&lt;/h2&gt;

&lt;p&gt;There is a &lt;code&gt;jmxtrans.sh&lt;/code&gt; script included with the distribution. This should be used to start the application running. If you read through the script, you will see that all of the options are customizable by exporting environment variables without having to edit the &lt;code&gt;.sh&lt;/code&gt; script. You can even create a &lt;code&gt;jmxtrans.conf&lt;/code&gt; file to put the options into so that you don’t need to setup environment variables yourself.&lt;/p&gt;

&lt;p&gt;To run jmxtrans:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./jmxtrans.sh start [optional path to one json file]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To stop jmxtrans:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./jmxtrans.sh stop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Options you may want to configure:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;JSON_DIR - Location of your .json files. Defaults to ‘.’&lt;/li&gt;
  &lt;li&gt;LOG_DIR - Location of where the log files get written. Defaults to ‘.’&lt;/li&gt;
  &lt;li&gt;SECONDS_BETWEEN_RUNS - How often jobs run. Defaults to 60.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面这些参数都可以在&lt;code&gt;/etc/sysconfig/jmxtrans&lt;/code&gt;中进行配置；另外，上面通过shell方式启动jmxtrans没有问题，为了方便可以，可以将jmxtrans加入到系统服务，具体如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@ningg ~]# chkconfig --add jmxtrans
[root@ningg ~]# service start jmxtrans
Starting jmxtrans: Cannot execute /usr/bin/jps -l!
[root@ningg ~]# which jps
/usr/java/default/bin/jps
[root@ningg ~]# vim /etc/sysconfig/jmxtrans
#增加JAVA_HOME的配置(与上面jps的位置对应)
export JAVA_HOME=/usr/java/default
[root@ningg ~]# service jmxtrans start
Starting jmxtrans:                           [  OK  ]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;enabling-jmx-for-a-jvm&quot;&gt;Enabling JMX for a JVM&lt;/h2&gt;

&lt;p&gt;In order to use jmxtrans, you must first enable Java Management Extensions (JMX) on your Java Virtual Machine (JVM). We recommend that you connect to Java 6 (or greater) JVM’s because there are improvements to the JMX protocol that we can take advantage of, such as wildcard (&lt;code&gt;*&lt;/code&gt;) queries.&lt;/p&gt;

&lt;p&gt;For applications behind a firewall that do not need security, add these arguments to the startup of the JVM in order to enable remote JMX connections:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-Dcom.sun.management.jmxremote.port=1105 \
-Dcom.sun.management.jmxremote.authenticate=false \
-Dcom.sun.management.jmxremote.ssl=false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You should set the port number to any free port number on your machine that is above 1024.&lt;/p&gt;

&lt;p&gt;For more details on enabling the agent, please read:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://download.oracle.com/javase/6/docs/technotes/guides/management/agent.html&quot;&gt;JMX Agent Configuration&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://download.oracle.com/javase/6/docs/technotes/guides/management/&quot;&gt;Monitoring and Management&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;jconsole&quot;&gt;JConsole&lt;/h2&gt;

&lt;p&gt;If you are going to use jmxtrans, it is helpful to gain an understanding of JConsole. This is a good visual tool for viewing attributes in a JVM. Using this tool will help you write your jmxtrans queries.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://download.oracle.com/javase/6/docs/technotes/guides/management/jconsole.html&quot;&gt;JConsole Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;using-ant-vars&quot;&gt;Using Ant Vars&lt;/h2&gt;

&lt;p&gt;Ant like variables could be used in json files since v239, so you could avoid hardcoding some values, like graphite servers.&lt;/p&gt;

&lt;h3 id=&quot;before&quot;&gt;Before&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;servers&quot; : [ {
    &quot;port&quot; : &quot;1099&quot;,
    &quot;host&quot; : &quot;w2&quot;,
    &quot;queries&quot; : [ {
      &quot;obj&quot; : &quot;java.lang:type=Memory&quot;,
      &quot;attr&quot; : [ &quot;HeapMemoryUsage&quot;, &quot;NonHeapMemoryUsage&quot; ],
      &quot;outputWriters&quot; : [ {
        &quot;@class&quot; : &quot;com.googlecode.jmxtrans.model.output.GraphiteWriter&quot;,
        &quot;settings&quot; : {
          &quot;port&quot; : 2003,
          &quot;host&quot; : &quot;192.168.192.133&quot;
        }
      } ]
    } ]
  } ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;now&quot;&gt;Now&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;servers&quot; : [ {
    &quot;port&quot; : &quot;${myserverport}&quot;,
    &quot;host&quot; : &quot;${myserverhost}&quot;,
    &quot;queries&quot; : [ {
      &quot;obj&quot; : &quot;java.lang:type=Memory&quot;,
      &quot;attr&quot; : [ &quot;HeapMemoryUsage&quot;, &quot;NonHeapMemoryUsage&quot; ],
      &quot;outputWriters&quot; : [ {
        &quot;@class&quot; : &quot;com.googlecode.jmxtrans.model.output.GraphiteWriter&quot;,
        &quot;settings&quot; : {
          &quot;port&quot; : &quot;${mygraphiteport}&quot;,
          &quot;host&quot; : &quot;${mygraphitehost}&quot;
        }
      } ]
    } ]
  } ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;notice&quot;&gt;Notice&lt;/h3&gt;

&lt;p&gt;Double-quotes (&lt;code&gt;&quot;&lt;/code&gt;) should be using even when providing int values, like port, it’s mandatory for StringResolver, String to Int conversion will be done internally.&lt;/p&gt;

&lt;p&gt;Variables should be provided via &lt;code&gt;-D&lt;/code&gt; for example via &lt;code&gt;JMXTRANS_OPTS&lt;/code&gt; in &lt;code&gt;jmxtrans.conf&lt;/code&gt; :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;JMXTRANS_OPTS=&quot;-Dmyserverport=1099 -Dmyserverhost=w2 -Dmygraphiteport=2003 -Dmygraphitehost=192.168.192.133&quot;
&lt;/code&gt;&lt;/pre&gt;

</content>
   </entry>
   
   <entry>
     <title>Ganglia监控Flume、Kafka、Storm</title>
     <link href="http://ningg.github.com/ganglia-with-flume-kafka-storm"/>
     <updated>2014-12-12T00:00:00+08:00</updated>
     <id>http://ningg.github.com/ganglia-with-flume-kafka-storm</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;通常利用Flume、Kafka、Storm来搭建实时的日志分析系统，那如何对这一系统运行状态进行监控呢？赶快调研一下，看看业内其他人怎么做的监控，当前能够查到的唯品会工程师&lt;code&gt;Yaobaniu&lt;/code&gt;对外分享的实时日志分析平台材料，初步可以推断其使用Zabbix进行的监控，因为&lt;code&gt;baniu&lt;/code&gt;在PPTV工作时，主要工作就是专注利用Zabbix进行集群监控，并且在&lt;code&gt;baniu&lt;/code&gt;的其他分享资料中，见到过Zabbix监控界面的截图，so，初步推断是Zabbix。不过，本文将采用Ganglia来进行监控，原因很简单：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;没有Zabbix的使用经验；&lt;/li&gt;
  &lt;li&gt;Flume官网中有利用Ganglia监控Flume运行状态的介绍；&lt;/li&gt;
  &lt;li&gt;Kafka、Storm的ecosystem中也见到了与Ganglia结合的身影；&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;前期准备&lt;/h2&gt;

&lt;p&gt;在阅读本文之前，要求对Ganglia的安装配置有一个基本的了解，具体要了解几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;安装Ganglia集群；&lt;/li&gt;
  &lt;li&gt;gmond的配置文件&lt;code&gt;gmond.conf&lt;/code&gt;；&lt;/li&gt;
  &lt;li&gt;gmetad的配置文件&lt;code&gt;gmetad.conf&lt;/code&gt;；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面的内容，可以参考自己之前的几篇博文：&lt;/p&gt;

&lt;p&gt;（ganglia的整个系列）&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;软件版本&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;软件&lt;/th&gt;
      &lt;th&gt;版本&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Flume&lt;/td&gt;
      &lt;td&gt;apache-flume-1.5.0.1-bin.tar.gz&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Kafka&lt;/td&gt;
      &lt;td&gt;kafka_2.9.2-0.8.1.1.tgz&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Storm&lt;/td&gt;
      &lt;td&gt;apache-storm-0.9.2-incubating.tar.gz&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ganglia&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;ganglia-with-flume&quot;&gt;Ganglia with Flume&lt;/h2&gt;

&lt;p&gt;Flume的官网上&lt;a href=&quot;https://flume.apache.org/FlumeUserGuide.html#monitoring&quot;&gt;Monitoring&lt;/a&gt;部分，显示通过简单配置，即可完成Ganglia对Flume的监控，关于具体细节，参考阅读&lt;a href=&quot;/flume-user-guide-monitoring&quot;&gt;Flume user-guide-monitoring&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;同时Flume的监控问题，在JIRA上也有较广泛的讨论，为开拓思路，也可以看看&lt;a href=&quot;https://issues.apache.org/jira/browse/FLUME&quot;&gt;jira Flume&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;ganglia-with-kafka&quot;&gt;Ganglia with Kafka&lt;/h2&gt;

&lt;p&gt;本文将描述一下，围绕“利用Ganglia监控Kafka”这一问题，如何思考、如何分析、如何搜索解决方案。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;分析&lt;/h3&gt;

&lt;p&gt;直接列一下，分析、查找途径：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;查看Kafka的&lt;a href=&quot;http://kafka.apache.org/documentation.html#monitoring&quot;&gt;官方文档&lt;/a&gt;其中提到了Monitoring，是利用&lt;code&gt;Yammer Metrics&lt;/code&gt;来收集数据的，并且列出了一些需要着重关注的指标；&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem&quot;&gt;Kafka ecosystem&lt;/a&gt;中查看到&lt;a href=&quot;https://github.com/adambarthelson/kafka-ganglia&quot;&gt;Ganglia Integration&lt;/a&gt;；&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Index&quot;&gt;Ganglia cwiki&lt;/a&gt;中查看到&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/JMX+Reporters&quot;&gt;JMX reporters&lt;/a&gt;，并在其下查看到&lt;a href=&quot;https://github.com/criteo/kafka-ganglia&quot;&gt;kafka-ganglia&lt;/a&gt;；&lt;/li&gt;
  &lt;li&gt;浏览&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA&quot;&gt;jira Kafka&lt;/a&gt;，大部分涉及到Kafka Ganglia的内容为bug修复，版本升级；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面是对整个Kafka官网的初步查询结果，从中可以看到，已经有利用Ganglia监控Kafka的监控方案了，具体有两个：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/adambarthelson/kafka-ganglia&quot;&gt;Ganglia Integration&lt;/a&gt;；
    &lt;ul&gt;
      &lt;li&gt;利用JMXTrans来收集Kafka运行状态；&lt;/li&gt;
      &lt;li&gt;通过Json来配置，收集指定的Kafka运行状态数据；&lt;/li&gt;
      &lt;li&gt;调整gweb页面；&lt;/li&gt;
      &lt;li&gt;最后更新时间：2013.06&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/criteo/kafka-ganglia&quot;&gt;kafka-ganglia&lt;/a&gt;；
    &lt;ul&gt;
      &lt;li&gt;利用Kafka官网提到的Yammer Metrics收集到的数据；&lt;/li&gt;
      &lt;li&gt;利用metrics-ganglia.jar将Yammer Metrics收集的数据发送到Ganglia展示；&lt;/li&gt;
      &lt;li&gt;最后更新时间：2014.01&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;kafka-gangliacriteo&quot;&gt;kafka-ganglia(criteo)&lt;/h3&gt;

&lt;p&gt;由于最新工程对当前版本兼容性可能更好，以及与Kafka利用Yammer Metrics机制保持一致，初步决定采用&lt;a href=&quot;https://github.com/criteo/kafka-ganglia&quot;&gt;kafka-ganglia&lt;/a&gt;工程。拿到这一工程后，利用Maven对其进行构建，不过我本地测试需要调整一下&lt;code&gt;artifactId=scalatest_2.9.2&lt;/code&gt;的版本：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.scalatest&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;scalatest_2.9.2&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;1.7.2&amp;lt;/version&amp;gt;
  &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不过其中涉及到一个情况：ganglia web上显示收集到的Kafka指标过多，近&lt;code&gt;1k+&lt;/code&gt;，过于臃肿，需要进行定制和过滤；&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;筛选出能够反映Kafka集群运行状态的关键指标；&lt;/li&gt;
  &lt;li&gt;如果指标为Yammer metrics中的meter类别，针对单个指标分析需要过滤的项，并定制进行过滤，不要显示在ganglia web上；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;经过自己简单分析，上面两个问题都有解决的办法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;依照官网&lt;a href=&quot;http://kafka.apache.org/documentation.html#monitoring&quot;&gt;Kafka doc：Monitoring&lt;/a&gt;中提到的特别需要关注的参数，进行提炼之后，借助&lt;a href=&quot;https://github.com/criteo/kafka-ganglia&quot;&gt;kafka-ganglia&lt;/a&gt;中的&lt;code&gt;exclude.regex&lt;/code&gt;机制来过滤掉不需要的参数，另外，需要特别注意criteo在实现的时候，利用的是&lt;code&gt;matcher.matches()&lt;/code&gt;方法，其尝试匹配整个Metric name；&lt;em&gt;（利用matcher.find()方法时，匹配的是是否找到这一参数）&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;定制&lt;a href=&quot;https://github.com/criteo/kafka-ganglia&quot;&gt;kafka-ganglia&lt;/a&gt;中的&lt;code&gt;exclude.regex&lt;/code&gt;机制，如果需要监控的参数很少，则实现&lt;code&gt;include&lt;/code&gt;机制，可以利用Regular Exp，也可以使用Set机制；&lt;/li&gt;
  &lt;li&gt;对于筛选出的特定参数，如果其是Yammer Metrics中的meter类型，则其中包含了&lt;code&gt;count&lt;/code&gt;、&lt;code&gt;mean rate&lt;/code&gt;、&lt;code&gt;1-min rate&lt;/code&gt;、&lt;code&gt;5-min rate&lt;/code&gt;、&lt;code&gt;15-min rate&lt;/code&gt;共计5个指标，那这些指标是有些重复的，原因是Ganglia提供了对一个参数的长期监控，例如&lt;code&gt;1-min rate&lt;/code&gt;就可以推测出&lt;code&gt;5-min rate&lt;/code&gt;等。通过初步分析，认为保留&lt;code&gt;count&lt;/code&gt;和&lt;code&gt;1-min rate&lt;/code&gt;指标即可。那代码上如何实现？初步分析，认为重写&lt;code&gt;metrics-ganglia-2.2.0.jar&lt;/code&gt;中的&lt;code&gt;com.yammer.metrics.reporting&lt;/code&gt;包内的&lt;code&gt;GangliaReporter&lt;/code&gt;类即可。&lt;em&gt;（此想法只是指出方向，并未进行实际验证）&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ganglia-integrationadambarthelson&quot;&gt;Ganglia Integration(adambarthelson)&lt;/h3&gt;

&lt;p&gt;（doing…）&lt;/p&gt;

&lt;p&gt;从上以部分发现，如果利用&lt;code&gt;metrics-ganglia-2.2.0.jar&lt;/code&gt;来实现Ganglia对Kafka的监控，有几个方面需要定制，涉及到一些定制的工作量。而&lt;a href=&quot;https://github.com/adambarthelson/kafka-ganglia&quot;&gt;Ganglia Integration&lt;/a&gt;好像可以直接通过Json文件来指定收集特定的参数，涉及到的定制可能会较少。&lt;/p&gt;

&lt;p&gt;（doing…）&lt;/p&gt;

&lt;p&gt;初步计划，在配置完Ganglia对Storm的监控时，学习一下jmxtrans的基本知识，然后回过头来，再来尝试一下&lt;a href=&quot;https://github.com/adambarthelson/kafka-ganglia&quot;&gt;Ganglia Integration&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;ganglia-with-storm&quot;&gt;Ganglia with Storm&lt;/h2&gt;

&lt;p&gt;如何找到Ganglia监控Storm的方法？找到方法后，具体如何进行操作？&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;分析&lt;/h3&gt;

&lt;p&gt;对于ASF（Apache Software Foundation，Apache软件基金会）下的opensource项目，我个人认为有几个信息源：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;open-source项目的官网：&lt;code&gt;http://***.apache.org&lt;/code&gt;；&lt;/li&gt;
  &lt;li&gt;Apache的Confluence网站：&lt;code&gt;http://cwiki.apache.org/&lt;/code&gt;；&lt;/li&gt;
  &lt;li&gt;Apache在Jira上进行的问题讨论：&lt;code&gt;https://issues.apache.org/&lt;/code&gt;；&lt;/li&gt;
  &lt;li&gt;google search；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此次查询如何利用Ganglia来监控Storm，还按照这几个信息源来查询：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;官网中，只找到如下几个来源，monitoring Storm相关：
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/documentation/Setting-up-a-Storm-cluster.html&quot;&gt;setup a storm cluster&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/documentation/Running-topologies-on-a-production-cluster.html&quot;&gt;running topol on prod cluster&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;google查到相关内容如下：
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.safaribooksonline.com/library/view/learning-storm/9781783981328/&quot;&gt;BOOK-Learning Storm&lt;/a&gt;&lt;em&gt;（通过某种合法方式，拿到了这本书的草稿版）&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://blog.relateiq.com/monitoring-storm/&quot;&gt;Monitoring Storm&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中&lt;a href=&quot;https://www.safaribooksonline.com/library/view/learning-storm/9781783981328/&quot;&gt;BOOK-Learning Storm&lt;/a&gt;详细介绍了Ganglia监控Storm的具体操作步骤，其基本原理是利用jmxtrans&lt;em&gt;（从哪收集的运行数据？谁负责发送给Ganglia？）&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;gangliastorm&quot;&gt;Ganglia监控Storm&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;这一部分参考自&lt;a href=&quot;https://www.safaribooksonline.com/library/view/learning-storm/9781783981328/&quot;&gt;BOOK-Learning Storm&lt;/a&gt;，细微的地方做出调整。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Storm doesn’t have built-in support to monitor the Storm cluster using Ganglia. However, with
jmxtrans, you can enable Storm monitoring using Ganglia. The &lt;code&gt;jmxtrans&lt;/code&gt; tool allows you to
connect to any JVM and fetches its JVM metrics without writing a single line of code. The JVM
metrics exposed via JMX can be displayed on Ganglia using jmxtrans. Hence, jmxtrans acts as a
bridge between Storm and Ganglia.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/learning-storm/jmxtrans-ganglia.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;需要在Storm运行的节点上安装jmxtrans：&lt;/p&gt;

&lt;p&gt;（自己有一篇单独介绍jmxtrans的博客，给个链接）&lt;/p&gt;

&lt;h4 id=&quot;supervisorjson&quot;&gt;supervisor.json&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;servers&quot;: [
    {
	  &quot;port&quot;: &quot;12346&quot;, 
	  &quot;host&quot;: &quot;IP_OF_SUPERVISOR_MACHINE&quot;, 
	  &quot;queries&quot;: [
	  	{
	  	  &quot;outputWriters&quot;: [
	  	  	{
	  	  	  &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.GangliaWriter&quot;, 
	  	  	  &quot;settings&quot;: {
	  	  	  	&quot;groupName&quot;: &quot;supervisor&quot;, 
	  	  	  	&quot;host&quot;: &quot;IP_OF_GANGLIA_GMOND_SERVER&quot;, 
	  	  	  	&quot;port&quot;: &quot;8649&quot;
	  	  	  }
	  	  	}
	  	  ], 
	  	  &quot;obj&quot;: &quot;java.lang:type=Memory&quot;, 
	  	  &quot;resultAlias&quot;: &quot;supervisor&quot;, 
	  	  &quot;attr&quot;: [
	  	  	&quot;ObjectPendingFinalizationCount&quot;
	  	  ]
	  	}, 
	  	{
	  	  &quot;outputWriters&quot;: [
	  	  	{
	  	  	  &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.GangliaWriter&quot;, 
	  	  	  &quot;settings&quot;: {
	  	  	  	&quot;groupName&quot;: &quot; supervisor &quot;, 
	  	  	  	&quot;host&quot;: &quot;IP_OF_GANGLIA_GMOND_SERVER&quot;, 
	  	  	  	&quot;port&quot;: &quot;8649&quot;
	  	  	  }
	  	  	}
	  	  ], 
	  	  &quot;obj&quot;: &quot;java.lang:name=Copy,type=GarbageCollector&quot;, 
	  	  &quot;resultAlias&quot;: &quot; supervisor &quot;, 
	  	  &quot;attr&quot;: [
	  	  	&quot;CollectionCount&quot;, 
	  	  	&quot;CollectionTime&quot;
	  	  ]
	  	}, 
	  	{
	  	  &quot;outputWriters&quot;: [
	  	  	{
	  	  	  &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.GangliaWriter&quot;, 
	  	  	  &quot;settings&quot;: {
	  	  	  	&quot;groupName&quot;: &quot;supervisor &quot;, 
	  	  	  	&quot;host&quot;: &quot;IP_OF_GANGLIA_GMOND_SERVER&quot;, 
	  	  	  	&quot;port&quot;: &quot;8649&quot;
	  	  	  }
	  	  	}
	  	  ], 
	  	  &quot;obj&quot;: &quot;java.lang:name=Code Cache,type=MemoryPool&quot;, 
	  	  &quot;resultAlias&quot;: &quot;supervisor &quot;, 
	  	  &quot;attr&quot;: [
	  	  	&quot;CollectionUsageThreshold&quot;, 
	  	  	&quot;CollectionUsageThresholdCount&quot;, 
	  	  	&quot;UsageThreshold&quot;, 
	  	  	&quot;UsageThresholdCount&quot;
	  	  ]
	  	}, 
	  	{
	  	  &quot;outputWriters&quot;: [
	  	  	{
	  	  	  &quot;@class&quot;: &quot;com.googlecode.jmxtrans.model.output.GangliaWriter&quot;, 
	  	  	  &quot;settings&quot;: {
	  	  	  	&quot;groupName&quot;: &quot;supervisor &quot;, 
	  	  	  	&quot;host&quot;: &quot;IP_OF_GANGLIA_GMOND_SERVER&quot;, 
	  	  	  	&quot;port&quot;: &quot;8649&quot;
	  	  	  }
	  	  	}
	  	  ], 
	  	  &quot;obj&quot;: &quot;java.lang:type=Runtime&quot;, 
	  	  &quot;resultAlias&quot;: &quot;supervisor&quot;, 
	  	  &quot;attr&quot;: [
	  	  	&quot;StartTime&quot;, 
	  	  	&quot;Uptime&quot;
	  	  ]
	  	}
	  ], 
	  &quot;numQueryThreads&quot;: 2
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;section-5&quot;&gt;杂谈&lt;/h2&gt;

&lt;p&gt;“见自己，见天地，见众生”，突然想到这句话，说是排rank大多是年轻人的想法，而实际上绝大部分有点成绩的人最后都殊途同归：见众生；做对众生有用、有益的事情。&lt;/p&gt;

</content>
   </entry>
   
   <entry>
     <title>Yammer Metrics的使用</title>
     <link href="http://ningg.github.com/yammer-metrics"/>
     <updated>2014-12-09T00:00:00+08:00</updated>
     <id>http://ningg.github.com/yammer-metrics</id>
     <content type="html">&lt;h2 id=&quot;yammer-metrics&quot;&gt;Yammer Metrics简介&lt;/h2&gt;

&lt;p&gt;最近用到的某个框架，其官网提到利用Yammer Metrics来测量系统运行状态，需要对其统计的具体参数有个基本的了解，OK，那就需要弄清几个简单的问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Yammer Metrics是什么？&lt;/li&gt;
  &lt;li&gt;Yammer Metrics收集哪些数据？&lt;/li&gt;
  &lt;li&gt;Yammer Metrics收集数据的基本过程、原理？&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;yammer-metrics-1&quot;&gt;Yammer Metrics的官网&lt;/h3&gt;

&lt;p&gt;上述列了几个问题，但有个最基本的问题：官网地址在哪？为什么说这个最基础、最重要，因为这是信息源，其他所有的网络信息都是以此为基础的。
在google中输入&lt;code&gt;yammer metrics wiki&lt;/code&gt;没有搜到类似一个明显的官网，到时找到了github上的两个工程：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/dropwizard/metrics&quot;&gt;dropwizard/metrics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/codahale/metrics&quot;&gt;codahale/metrics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一时间有点蒙，赶紧去查看了一下当前Eclipse下使用的metrics-core-2.2.0.jar包，主要是其jar内的META-INF信息，查询得知jar包为coda在2012年编译的，再到google上一查，大部分人都在使用metrics 2.2.0版本，再理一下上面两个github工程的关系，初步肯定：&lt;a href=&quot;https://github.com/codahale/metrics&quot;&gt;codahale/metrics&lt;/a&gt;是较早之前的版本，而且现在已经变为metrics的go语言实现版本，同时&lt;a href=&quot;https://github.com/codahale/metrics&quot;&gt;codahale/metrics&lt;/a&gt;也指出java实现的metrics已经移到&lt;a href=&quot;https://github.com/dropwizard/metrics&quot;&gt;dropwizard/metrics&lt;/a&gt;。当前算是找到yammer metrics的官方地址了，赶快打开看一下，发现其已经是3.1.0版本了，心里有个小疑问，会不会有很多东西与2.2.0版本不同？不用担心，&lt;a href=&quot;https://dropwizard.github.io/metrics/3.1.0/&quot;&gt;Metrics doc 3.x&lt;/a&gt;的URL上，修改一下版本的位置，即可看到2.2.0版本的官方文档&lt;a href=&quot;http://dropwizard.github.io/metrics/2.2.0/&quot;&gt;Metrics doc 2.x&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;备注&lt;/strong&gt;：maven central repo中yammer metrics的两个位置：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://repo1.maven.org/maven2/com/yammer/metrics/&quot;&gt;repo: yammer metrics 2.x&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://repo1.maven.org/maven2/io/dropwizard/metrics/&quot;&gt;repo: yammer metrics 3.x&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;yammer-metrics-2&quot;&gt;Yammer metrics的作用&lt;/h3&gt;

&lt;p&gt;为什么要用Metrics？&lt;a href=&quot;https://dropwizard.github.io/metrics/3.1.0/&quot;&gt;Metrics doc 3.x&lt;/a&gt;中有句话很经典：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Metrics is a Java library which gives you unparalleled insight into what your code does in production.（注：unparalleled，空前的、无与伦比的）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;yammer-metrics-3&quot;&gt;Yammer Metrics相关术语&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;特别说明&lt;/strong&gt;：从&lt;a href=&quot;https://dropwizard.github.io/metrics/3.1.0/&quot;&gt;Yammer metrics官网&lt;/a&gt;可知，当前为3.1.0版本，但是当前在项目中广泛使用的是2.2.0版本，因此，本文将主要关注&lt;a href=&quot;http://dropwizard.github.io/metrics/2.2.0/&quot;&gt;http://dropwizard.github.io/metrics/2.2.0/&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;http://www.javacodegeeks.com/2012/12/yammer-metrics-a-new-way-to-monitor-your-application.html&quot;&gt;intro to yammer metrics&lt;/a&gt;中有个基本的总结：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Gauges&lt;/strong&gt;: an instantaneous measurement of a discrete value.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Counters&lt;/strong&gt;: a value that can be incremented and decremented. Can be used in queues to monitorize the remaining number of pending jobs.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Meters&lt;/strong&gt;: measure the rate of events over time. You can specify the rate unit, the scope of events or event type.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Histograms&lt;/strong&gt;: measure the statistical distribution of values in a stream of data.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Timers&lt;/strong&gt;: measure the amount of time it takes to execute a piece of code and the distribution of its duration.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Healthy checks&lt;/strong&gt;: as his name suggests, it centralize our service’s healthy checks of external systems.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gauges&quot;&gt;Gauges&lt;/h3&gt;

&lt;p&gt;A gauge is an instantaneous measurement of a value. For example, we may want to measure the number of pending jobs in a queue:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Metrics.newGauge(QueueManager.class, &quot;pending-jobs&quot;, new Gauge&amp;lt;Integer&amp;gt;() {
	@Override
	public Integer value() {
		return queue.size();
	}
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Every time this gauge is measured, it will return the number of jobs in the queue.&lt;/p&gt;

&lt;p&gt;For most queue and queue-like structures, you won’t want to simply return &lt;code&gt;queue.size()&lt;/code&gt;. Most of &lt;code&gt;java.util&lt;/code&gt; and &lt;code&gt;java.util.concurrent&lt;/code&gt; have implementations of &lt;code&gt;#size()&lt;/code&gt; which are &lt;code&gt;O(n)&lt;/code&gt;, which means your gauge will be slow (potentially while holding a lock).&lt;/p&gt;

&lt;h3 id=&quot;counters&quot;&gt;Counters&lt;/h3&gt;

&lt;p&gt;A counter is just a gauge for an &lt;code&gt;AtomicLong&lt;/code&gt; instance. You can increment or decrement its value. For example, we may want a more efficient way of measuring the pending job in a queue:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private final Counter pendingJobs = Metrics.newCounter(QueueManager.class, &quot;pending-jobs&quot;);

public void addJob(Job job) {
	pendingJobs.inc();
	queue.offer(job);
}

public Job takeJob() {
	pendingJobs.dec();
	return queue.take();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Every time this counter is measured, it will return the number of jobs in the queue.&lt;/p&gt;

&lt;h3 id=&quot;meters&quot;&gt;Meters&lt;/h3&gt;

&lt;p&gt;A meter measures the rate of events over time (e.g., “requests per second”). In addition to the mean rate, meters also track &lt;code&gt;1-&lt;/code&gt;, &lt;code&gt;5-&lt;/code&gt;, and &lt;code&gt;15-&lt;/code&gt;minute moving averages.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private final Meter requests = Metrics.newMeter(RequestHandler.class, &quot;requests&quot;, &quot;requests&quot;, TimeUnit.SECONDS);

public void handleRequest(Request request, Response response) {
	requests.mark();
	// etc
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This meter will measure the rate of requests in requests per second.&lt;/p&gt;

&lt;h3 id=&quot;histograms&quot;&gt;Histograms&lt;/h3&gt;

&lt;p&gt;A histogram measures the statistical distribution of values in a stream of data. In addition to minimum, maximum, mean, etc., it also measures median, 75th, 90th, 95th, 98th, 99th, and 99.9th percentiles.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private final Histogram responseSizes = Metrics.newHistogram(RequestHandler.class, &quot;response-sizes&quot;);

public void handleRequest(Request request, Response response) {
	// etc
	responseSizes.update(response.getContent().length);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This histogram will measure the size of responses in bytes.&lt;/p&gt;

&lt;h3 id=&quot;timers&quot;&gt;Timers&lt;/h3&gt;

&lt;p&gt;A timer measures both the rate that a particular piece of code is called and the distribution of its duration.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private final Timer responses = Metrics.newTimer(RequestHandler.class, &quot;responses&quot;, TimeUnit.MILLISECONDS, TimeUnit.SECONDS);

public String handleRequest(Request request, Response response) {
	final TimerContext context = responses.time();
	try {
		// etc;
		return &quot;OK&quot;;
	} finally {
		context.stop();
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This timer will measure the amount of time it takes to process each request in milliseconds and provide a rate of requests in requests per second.&lt;/p&gt;

&lt;h3 id=&quot;health-checks&quot;&gt;Health Checks&lt;/h3&gt;

&lt;p&gt;Metrics also has the ability to centralize your service’s health checks. First, implement a &lt;code&gt;HealthCheck&lt;/code&gt; instance:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import com.yammer.metrics.core.HealthCheck.Result;

public class DatabaseHealthCheck extends HealthCheck {
	private final Database database;

	public DatabaseHealthCheck(Database database) {
		super(&quot;database&quot;);
		this.database = database;
	}

	@Override
	public Result check() throws Exception {
		if (database.isConnected()) {
			return Result.healthy();
		} else {
			return Result.unhealthy(&quot;Cannot connect to &quot; + database.getUrl());
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then register an instance of it with Metrics:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;HealthChecks.register(new DatabaseHealthCheck(database));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To run all of the registered health checks:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;final Map&amp;lt;String, Result&amp;gt; results = HealthChecks.runHealthChecks();
for (Entry&amp;lt;String, Result&amp;gt; entry : results.entrySet()) {
	if (entry.getValue().isHealthy()) {
		System.out.println(entry.getKey() + &quot; is healthy&quot;);
	} else {
		System.err.println(entry.getKey() + &quot; is UNHEALTHY: &quot; + entry.getValue().getMessage());
		final Throwable e = entry.getValue().getError();
		if (e != null) {
			e.printStackTrace();
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Metrics comes with a pre-built health check: &lt;code&gt;DeadlockHealthCheck&lt;/code&gt;, which uses Java 1.6’s built-in thread deadlock detection to determine if any threads are deadlocked.&lt;/p&gt;

&lt;h2 id=&quot;yammer-metrics-4&quot;&gt;Yammer metrics原理与具体用法&lt;/h2&gt;

&lt;p&gt;（doing…）&lt;/p&gt;

&lt;p&gt;进一步的内容将参考：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://dropwizard.github.io/metrics/2.2.0/&quot;&gt;Metrics doc 2.x&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/scutshuxue/article/details/8350135&quot;&gt;JAVA Metrics度量工具的使用&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面将针对java中Yammer Metrics的用法进行简要介绍，此次我使用的是Maven来管理的java工程，具体pom.xml中的配置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  		&amp;lt;groupId&amp;gt;com.yammer.metrics&amp;lt;/groupId&amp;gt;
  		&amp;lt;artifactId&amp;gt;metrics-core&amp;lt;/artifactId&amp;gt;
  		&amp;lt;version&amp;gt;2.2.0&amp;lt;/version&amp;gt;
  	&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;给一个工程的截图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/yammer-metrics/learn-metrics.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;gauge&quot;&gt;gauge&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;package io.github.ningg.gauge;

import java.util.LinkedList;
import java.util.List;
import java.util.concurrent.TimeUnit;

import com.yammer.metrics.Metrics;
import com.yammer.metrics.core.Gauge;
import com.yammer.metrics.reporting.ConsoleReporter;

public class LearnGauge {
	
	private List&amp;lt;String&amp;gt; stringList = new LinkedList&amp;lt;String&amp;gt;();
	
	Gauge&amp;lt;Integer&amp;gt; gauge = Metrics.newGauge(LearnGauge.class, &quot;list-size-gauge&quot;, new Gauge&amp;lt;Integer&amp;gt;() {
		@Override
		public Integer value() {
			return stringList.size();
		}
	});
	
	public void inputElement(String input){
		stringList.add(input);
	}
	
	
	public static void main(String[] args) throws InterruptedException{

		// periodically report all registered metrics to the console
		ConsoleReporter.enable(1,TimeUnit.SECONDS);
		LearnGauge learnGauge = new LearnGauge();
		
		for(int i = 0; i &amp;lt; 10; i++){
			learnGauge.inputElement(String.valueOf(i));
			Thread.sleep(1000);
		}
		
	}
	
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;14-12-10 19:35:27 ==============================================================
io.github.ningg.gauge.LearnGauge:
  list-size-gauge:
	value = 3
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;counter&quot;&gt;counter&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;package io.github.ningg.counter;

import java.util.LinkedList;
import java.util.List;
import java.util.concurrent.TimeUnit;

import com.yammer.metrics.Metrics;
import com.yammer.metrics.core.Counter;
import com.yammer.metrics.reporting.ConsoleReporter;

public class LearnCounter {

	private List&amp;lt;String&amp;gt; stringList = new LinkedList&amp;lt;String&amp;gt;();
	
	private Counter listSizeCounter = Metrics.newCounter(LearnCounter.class, &quot;string-list-counter&quot;);
	
	private void push(String input){
		listSizeCounter.inc();
		stringList.add(input);
	}
	
	private void pop(String output){
		listSizeCounter.dec();
		stringList.remove(output);
	}
	
	
	public static void main(String[] args) throws InterruptedException{
		
		ConsoleReporter.enable(1, TimeUnit.SECONDS);
		LearnCounter learnCounter = new LearnCounter();
		
		for(int times = 0; times &amp;lt; 5; times++){
			learnCounter.push(String.valueOf(times));
			Thread.sleep(1000);
		}
		
		for(int times = 0; times &amp;lt; 5; times++){
			learnCounter.pop(String.valueOf(times));
			Thread.sleep(1000);
		}
		
	}
	
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;14-12-10 19:49:02 ==============================================================
io.github.ningg.counter.LearnCounter:
  string-list-counter:
	count = 3



14-12-10 19:49:03 ==============================================================
io.github.ningg.counter.LearnCounter:
  string-list-counter:
	count = 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;meter&quot;&gt;meter&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;package io.github.ningg.meter;

import java.util.concurrent.TimeUnit;

import com.yammer.metrics.Metrics;
import com.yammer.metrics.core.Meter;
import com.yammer.metrics.reporting.ConsoleReporter;

public class LearnMeter {
	
	private Meter meter = Metrics.newMeter(LearnMeter.class, &quot;meter-event&quot;, &quot;request&quot;, TimeUnit.SECONDS);

	public void handleRequest(){
		meter.mark();
	}
	
	
	public static void main(String[] args) throws InterruptedException{
		ConsoleReporter.enable(1, TimeUnit.SECONDS);
		
		LearnMeter learnMeter = new LearnMeter();
		
		for(int times = 0; times &amp;lt; 200; times++){
			learnMeter.handleRequest();
			Thread.sleep(100);
		}
	}
	
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;14-12-10 19:49:53 ==============================================================
io.github.ningg.meter.LearnMeter:
  meter-event:
			 count = 20
		 mean rate = 9.95 request/s
	 1-minute rate = 0.00 request/s
	 5-minute rate = 0.00 request/s
	15-minute rate = 0.00 request/s
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;histogram&quot;&gt;histogram&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;package io.github.ningg.histogram;

import java.util.LinkedList;
import java.util.List;
import java.util.concurrent.TimeUnit;

import com.yammer.metrics.Metrics;
import com.yammer.metrics.core.Histogram;
import com.yammer.metrics.reporting.ConsoleReporter;

public class LearnHistogram {

	private List&amp;lt;String&amp;gt; stringList = new LinkedList&amp;lt;String&amp;gt;();
	
	private Histogram histogram = Metrics.newHistogram(LearnHistogram.class, &quot;size-histogram&quot;);
	
	public void push(String input){
		stringList.add(input);
	}
	
	public void pop(String output){
		stringList.remove(output);
	}
	
	public void updateHisto(){
		histogram.update(stringList.size());
	}
	
	
	public static void main(String[] args) throws InterruptedException{
		ConsoleReporter.enable(1, TimeUnit.SECONDS);
		LearnHistogram learnHistogram = new LearnHistogram();
		
		for(int time = 0 ; time &amp;lt; 100000 ; time++){
			learnHistogram.push(String.valueOf(time));
			
			if(time%10 == 0){
				learnHistogram.updateHisto();
			}
			
			if(time%2 == 2){
				learnHistogram.pop(String.valueOf(time));
			}
			Thread.sleep(1);
			
		}
	}
	
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;14-12-10 19:50:46 ==============================================================
io.github.ningg.histogram.LearnHistogram:
  size-histogram:
			   min = 1.00
			   max = 991.00
			  mean = 496.00
			stddev = 290.11
			median = 496.00
			  75% &amp;lt;= 748.50
			  95% &amp;lt;= 950.50
			  98% &amp;lt;= 980.80
			  99% &amp;lt;= 990.90
			99.9% &amp;lt;= 991.00
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;timer&quot;&gt;timer&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;package io.github.ningg.timer;

import java.util.concurrent.TimeUnit;

import com.yammer.metrics.Metrics;
import com.yammer.metrics.core.Timer;
import com.yammer.metrics.core.TimerContext;
import com.yammer.metrics.reporting.ConsoleReporter;

public class LearnTimer {
	
	private Timer timer = Metrics.newTimer(LearnTimer.class, &quot;response-timer&quot;, TimeUnit.MILLISECONDS, TimeUnit.SECONDS);
	
	public void handleRequest() throws InterruptedException{
		TimerContext context = timer.time();
		for(int i = 0 ; i &amp;lt; 2 ; i++){
			Thread.sleep(1);
		}
		context.stop();
	}
	
	public static void main(String[] args) throws InterruptedException{
		ConsoleReporter.enable(1, TimeUnit.SECONDS);
		LearnTimer learnTimer = new LearnTimer();
		
		for(int time = 0 ; time &amp;lt; 10000 ; time++){
			learnTimer.handleRequest();
		}
		Thread.sleep(10000);
	}

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;14-12-10 19:51:24 ==============================================================
io.github.ningg.timer.LearnTimer:
  response-timer:
			 count = 504
		 mean rate = 254.23 calls/s
	 1-minute rate = 0.00 calls/s
	 5-minute rate = 0.00 calls/s
	15-minute rate = 0.00 calls/s
			   min = 3.71ms
			   max = 3.98ms
			  mean = 3.86ms
			stddev = 0.03ms
			median = 3.86ms
			  75% &amp;lt;= 3.87ms
			  95% &amp;lt;= 3.92ms
			  98% &amp;lt;= 3.93ms
			  99% &amp;lt;= 3.94ms
			99.9% &amp;lt;= 3.98ms
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;section&quot;&gt;小结&lt;/h3&gt;

&lt;p&gt;上面可知，在Java工程中使用Yammer Metrics的gauge、counter、meter、histogram、timer时，本质上就是创建一个Metrics的Gauge、Counter、Meter、Histogram、Timer对象，然后在特定的地点触发对象，即可实现对应用状态的监控。		&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;参考来源&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://dropwizard.github.io/metrics/3.1.0/&quot;&gt;Metrics doc 3.x&lt;/a&gt;&lt;em&gt;（官方文档简洁明了，推荐阅读；唯一需要注意的是，现在官网已经是3.x版本了，而很多项目使用过2.x版本，需要留意其差异）&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;杂谈&lt;/h2&gt;

&lt;p&gt;刚看到的一个几个东西，感觉时代在进步呀，没有仔细看，看来需要不断学习、整理一些新的东西：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://dropwizard.io/index.html&quot;&gt;Dropwizard&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.infoq.com/cn/articles/zhenye-talk-java-develop/&quot;&gt;郑晔谈Java开发：新工具、新框架、新思维&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>Kafka 0.8.1：Monitoring</title>
     <link href="http://ningg.github.com/kafka-monitoring-config"/>
     <updated>2014-12-09T00:00:00+08:00</updated>
     <id>http://ningg.github.com/kafka-monitoring-config</id>
     <content type="html">&lt;blockquote&gt;
  &lt;p&gt;本文原文来自[Kafka 0.8.x Monitoring][Kafka 0.8.x Monitoring]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Kafka uses &lt;code&gt;Yammer Metrics&lt;/code&gt; for metrics reporting in both the server and the client. This can be configured to report stats using pluggable stats reporters to hook up to your monitoring system.&lt;/p&gt;

&lt;p&gt;The easiest way to see the available metrics to fire up jconsole and point it at a running kafka client or server; this will all browsing all metrics with JMX.&lt;/p&gt;

&lt;p&gt;We pay particular we do graphing and alerting on the following metrics:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Description&lt;/th&gt;
      &lt;th&gt;Mbean name&lt;/th&gt;
      &lt;th&gt;Normal value&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Message in rate&lt;/td&gt;
      &lt;td&gt;“kafka.server”: name=”AllTopicsMessagesInPerSec”, type=”BrokerTopicMetrics”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Byte in rate&lt;/td&gt;
      &lt;td&gt;“kafka.server”: name=”AllTopicsBytesInPerSec”, type=”BrokerTopicMetrics”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Request rate&lt;/td&gt;
      &lt;td&gt;“kafka.network”: name=”{Produce&lt;code&gt;|&lt;/code&gt;Fetch-consumer&lt;code&gt;|&lt;/code&gt;Fetch-follower}-RequestsPerSec”, type=”RequestMetrics”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Byte out rate&lt;/td&gt;
      &lt;td&gt;“kafka.server”: name=”AllTopicsBytesOutPerSec”, type=”BrokerTopicMetrics”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Log flush rate and time&lt;/td&gt;
      &lt;td&gt;“kafka.log”: name=”LogFlushRateAndTimeMs”, type=”LogFlushStats”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;# of under replicated partitions&lt;/td&gt;
      &lt;td&gt;(&lt;code&gt;|ISR| &amp;lt; |all replicas|&lt;/code&gt;) “kafka.server”: name=”UnderReplicatedPartitions”, type=”ReplicaManager”&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Is controller active on broker&lt;/td&gt;
      &lt;td&gt;“kafka.controller”: name=”ActiveControllerCount”, type=”KafkaController”&lt;/td&gt;
      &lt;td&gt;only one broker in the cluster should have 1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Leader election rate&lt;/td&gt;
      &lt;td&gt;“kafka.controller”: name=”LeaderElectionRateAndTimeMs”, type=”ControllerStats”&lt;/td&gt;
      &lt;td&gt;non-zero when there are broker failures&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Unclean leader election rate&lt;/td&gt;
      &lt;td&gt;“kafka.controller”: name=”UncleanLeaderElectionsPerSec”, type=”ControllerStats”&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Partition counts&lt;/td&gt;
      &lt;td&gt;“kafka.server”: name=”PartitionCount”, type=”ReplicaManager”&lt;/td&gt;
      &lt;td&gt;mostly even across brokers&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Leader replica counts&lt;/td&gt;
      &lt;td&gt;“kafka.server”: name=”LeaderCount”, type=”ReplicaManager”&lt;/td&gt;
      &lt;td&gt;mostly even across brokers&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ISR shrink rate&lt;/td&gt;
      &lt;td&gt;“kafka.server”: name=”ISRShrinksPerSec”, type=”ReplicaManager”&lt;/td&gt;
      &lt;td&gt;If a broker goes down, ISR for some of the partitions will shrink. When that broker is up again, ISR will be expanded once the replicas are fully caught up. Other than that, the expected value for both ISR shrink rate and expansion rate is 0.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ISR expansion rate&lt;/td&gt;
      &lt;td&gt;“kafka.server”: name=”ISRExpandsPerSec”, type=”ReplicaManager”&lt;/td&gt;
      &lt;td&gt;See above&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Max lag in messages btw follower and leader replicas&lt;/td&gt;
      &lt;td&gt;“kafka.server”: name=”([-.\w]+)-MaxLag”, type=”ReplicaFetcherManager”&lt;/td&gt;
      &lt;td&gt;&amp;lt; replica.lag.max.messages&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lag in messages per follower replica&lt;/td&gt;
      &lt;td&gt;“kafka.server”: name=”([-.\w]+)-ConsumerLag”, type=”FetcherLagMetrics”&lt;/td&gt;
      &lt;td&gt;&amp;lt; replica.lag.max.messages&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Requests waiting in the producer purgatory&lt;/td&gt;
      &lt;td&gt;“kafka.server”: name=”PurgatorySize”, type=”ProducerRequestPurgatory”&lt;/td&gt;
      &lt;td&gt;non-zero if ack=-1 is used&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Requests waiting in the fetch purgatory&lt;/td&gt;
      &lt;td&gt;“kafka.server”: name=”PurgatorySize”, type=”FetchRequestPurgatory”&lt;/td&gt;
      &lt;td&gt;size depends on fetch.wait.max.ms in the consumer&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Request total time&lt;/td&gt;
      &lt;td&gt;“kafka.network”: name=”{Produce&lt;code&gt;|&lt;/code&gt;Fetch-Consumer&lt;code&gt;|&lt;/code&gt;Fetch-Follower}-TotalTimeMs”,type=”RequestMetrics”&lt;/td&gt;
      &lt;td&gt;broken into queue, local, remote and response send time&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Time the request waiting in the request queue&lt;/td&gt;
      &lt;td&gt;“kafka.network”: name=”{Produce&lt;code&gt;|&lt;/code&gt;Fetch-Consumer&lt;code&gt;|&lt;/code&gt;Fetch-Follower}-QueueTimeMs”, type=”RequestMetrics”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Time the request being processed at the leader&lt;/td&gt;
      &lt;td&gt;“kafka.network”: name=”{Produce&lt;code&gt;|&lt;/code&gt;Fetch-Consumer&lt;code&gt;|&lt;/code&gt;Fetch-Follower}-LocalTimeMs”, type=”RequestMetrics”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Time the request waits for the follower&lt;/td&gt;
      &lt;td&gt;“kafka.network”: name=”{Produce&lt;code&gt;|&lt;/code&gt;Fetch-Consumer&lt;code&gt;|&lt;/code&gt;Fetch-Follower}-RemoteTimeMs”, type=”RequestMetrics”&lt;/td&gt;
      &lt;td&gt;non-zero for produce requests when ack=-1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Time to send the response&lt;/td&gt;
      &lt;td&gt;“kafka.network”: name=”{Produce&lt;code&gt;|&lt;/code&gt;Fetch-Consumer&lt;code&gt;|&lt;/code&gt;Fetch-Follower}-ResponseSendTimeMs”, type=”RequestMetrics”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Number of messages the consumer lags behind the producer by&lt;/td&gt;
      &lt;td&gt;“kafka.consumer”: name=”([-.\w]+)-MaxLag”, type=”ConsumerFetcherManager”&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We recommend monitor GC time and other stats and various server stats such as CPU utilization, I/O service time, etc. On the client side, we recommend monitor the message/byte rate (global and per topic), request rate/size/time, and on the consumer side, max lag in messages among all partitions and min fetch request rate. For a consumer to keep up, max lag needs to be less than a threshold and min fetch rate needs to be larger than 0.
Audit&lt;/p&gt;

&lt;p&gt;The final alerting we do is on the correctness of the data delivery. We audit that every message that is sent is consumed by all consumers and measure the lag for this to occur. For important topics we alert if a certain completeness is not achieved in a certain time period. The details of this are discussed in KAFKA-260.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;note(ningg)&lt;/strong&gt;：Kafka中controller，MBean，两个名词的含义？&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;参考来源&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://kafka.apache.org/documentation.html&quot;&gt;Kafka 0.8.* Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>Linux下禁止用户远程登录</title>
     <link href="http://ningg.github.com/linux-ctrl-user-login"/>
     <updated>2014-12-08T00:00:00+08:00</updated>
     <id>http://ningg.github.com/linux-ctrl-user-login</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;有些用户不安份，能不能禁止用户登录（锁定用户）？&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;分析&lt;/h2&gt;

&lt;p&gt;说实话，这个问题很小，不过思路不能丢，要禁止用户登录，涉及几个问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如何操作，会锁定用户，使其无法登录？&lt;/li&gt;
  &lt;li&gt;如何判断哪些用户已经被锁定？&lt;/li&gt;
  &lt;li&gt;如何解锁用户，允许其登录？&lt;/li&gt;
  &lt;li&gt;有没有批量锁定用户的命令？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;吹个牛，上面的几个点，就跟实际做事情的要点是一样的，即：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如何把事情做成？&lt;/li&gt;
  &lt;li&gt;如何验证事情已经做成？&lt;/li&gt;
  &lt;li&gt;如果出现差错，如何消除事情的影响？&lt;/li&gt;
  &lt;li&gt;如何又快又好的把事情做成？&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;锁定用户和解锁用户&lt;/h2&gt;

&lt;p&gt;通过命令&lt;code&gt;usermod&lt;/code&gt;即可完成对用户的锁定和解锁：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Lock a user´s password. This puts a ´!´ in front of the
// encrypted password, effectively disabling the password. 
[root@ningg ~]# usermod -L ningg

// Unlock a user´s password. This removes the ´!´ in front 
// of the encrypted password. 
[root@ningg ~]# usermod -U ningg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也可以设定用户的自动解锁时间，具体参考&lt;code&gt;man usermod&lt;/code&gt;。需要说明一点，通过&lt;code&gt;usermod -L [login]&lt;/code&gt;锁定用户&lt;code&gt;[login]&lt;/code&gt;，则，当用户尝试登录时，会提示：”incorrect password”；而root用户，则可以通过&lt;code&gt;su - ningg&lt;/code&gt;直接转换为用户ningg的身份。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;备注&lt;/strong&gt;：命令&lt;code&gt;passwd&lt;/code&gt;也可以进行用户的锁定和解锁：&lt;code&gt;passwd -l [login]&lt;/code&gt;和&lt;code&gt;passwd -u [login]&lt;/code&gt;两个命令。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;查看是否锁定用户&lt;/h2&gt;

&lt;p&gt;查看&lt;code&gt;/etc/shadow&lt;/code&gt;文件，以&lt;code&gt;:&lt;/code&gt;分割的第二行，如果以&lt;code&gt;!&lt;/code&gt;或者&lt;code&gt;*&lt;/code&gt;开头，则表示当前用户无法远程登录，只能通过root用户以su命令切换身份而来，具体，看下面的示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@ningg ~]# vim /etc/shadow
root:$6$t(省略...):16407:0:99999:7:::
bin:*:15628:0:99999:7:::
daemon:*:15628:0:99999:7:::
ftp:*:15628:0:99999:7:::
nobody:*:15628:0:99999:7:::
ningg:$6$t(省略...):16374:0:99999:7:::
flume:!!:16380::::::
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;疑问&lt;/strong&gt;：以&lt;code&gt;!&lt;/code&gt;与&lt;code&gt;*&lt;/code&gt;开头，有没有差异？&lt;/p&gt;

&lt;h2 id=&quot;shell&quot;&gt;修改shell类型&lt;/h2&gt;

&lt;p&gt;通过修改用户登录之后的shell类型实现禁止用户登录，具体命令如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// chsh - change your login shell
chsh -s /sbin/nologin ningg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用户登录，提示信息：This account is currently not available.&lt;/p&gt;

&lt;h3 id=&quot;shellsbinnologin&quot;&gt;特殊的shell：/sbin/nologin&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;/sbin/nologin&lt;/code&gt;本质是用户的login shell，不过这个nologin shell有些特殊，需要说一说。&lt;code&gt;/sbin/nologin&lt;/code&gt;使用户无法登录，本质是：用户无法使用bash或其他shell来登入系统，这个账户仍然可以使用其他系统资源，例如：www服务由帐号apache管理，其可以进行系统程序的工作，但是无法登入主机；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;疑问&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;用户登入系统、获取shell，只是获取shell时，被拒绝；那如果不去获取shell，是否可以登录？&lt;/li&gt;
  &lt;li&gt;用户的login shell是&lt;code&gt;/sbin/nologin&lt;/code&gt;，那么，这类用户如何使用其他系统资源呢？其本质还得使用shell吧，只不过这个shell不是login shell；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当用户的login shell被设置为&lt;code&gt;/sbin/nologin&lt;/code&gt;时，用户登录时，会被拒绝，并且提示信息：This account is currently not available；这个提示信息是可以定制的，具体定制方法：新建&lt;code&gt;/etc/nologin.txt&lt;/code&gt;，并在其中写入提示信息即可。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;禁止所有用户登录&lt;/h3&gt;

&lt;p&gt;如果因为系统维护升级等原因，希望禁止所有用户登录，则按照上面的方式，一个一个禁用用户，很无聊，而且容易出错，一种下面是简便的解决方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;##在/etc目录下建立一个nologin文档
touch /etc/nologin ##如果该文件存在，那么Linux上的所有用户（除了root以外）都无法登录
##在/etc/nologin（注意：这可不是3中的nologin.txt啊！）写点什么，告诉用户为何无法登录

##cat /etc/nologin
9：00－10：00 系统升级，所有用户都禁止登录！
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;解禁帐号也简单，直接将&lt;code&gt;/etc/nologin&lt;/code&gt;删除就行了！&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;比较两种方式&lt;/h2&gt;

&lt;p&gt;整理上面两种禁止用户登录的方式，其出发思路不同：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;禁用用户登录密码：&lt;code&gt;usermod -L [login]&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;此时，root用户通过&lt;code&gt;su - [login]&lt;/code&gt;仍可以切换为&lt;code&gt;login&lt;/code&gt;用户身份；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;禁用用户的login shell：&lt;code&gt;chsh -s /sbin/nologin [login]&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;此时，root用户无法通过&lt;code&gt;su&lt;/code&gt;命令切换为&lt;code&gt;[login]&lt;/code&gt;用户身份；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;重要遗留问题&lt;/strong&gt;：当设置为&lt;code&gt;/sbin/nologin&lt;/code&gt;时，这一用户如何才能调用其他系统资源？&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;参考来源&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/zero1665/archive/2010/06/06/1752492.html&quot;&gt;Linux如何禁止用户登录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://ningg.github.io/linux-user-and-group/&quot;&gt;Linux下用户和组管理&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;鸟哥的Linux私房菜（第三版） 第14章 Linux帐号管理与ACL权限设定&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>Ganglia 3.6.1：Ganglia Meta Daemon v3.6.1 Configuration</title>
     <link href="http://ningg.github.com/ganglia-gmetad-conf"/>
     <updated>2014-12-06T00:00:00+08:00</updated>
     <id>http://ningg.github.com/ganglia-gmetad-conf</id>
     <content type="html">&lt;p&gt;This is an example of a Ganglia Meta Daemon configuration file
                http://ganglia.sourceforge.net/&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;##debug_level&lt;/p&gt;

&lt;p&gt;Setting the debug_level to 1 will keep daemon in the forground and
 show only error messages. Setting this value higher than 1 will make
 gmetad output debugging information and stay in the foreground.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#default: 0
debug_level 10
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;
&lt;p&gt;What to monitor. The most important section of this file.&lt;/p&gt;

&lt;p&gt;The data_source tag specifies either a cluster or a grid to
 monitor. If we detect the source is a cluster, we will maintain a complete
 set of RRD databases for it, which can be used to create historical
 graphs of the metrics. If the source is a grid (it comes from another gmetad),
 we will only maintain summary RRDs for it.&lt;/p&gt;

&lt;p&gt;Format:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data_source &quot;my cluster&quot; [polling interval] address1:port addreses2:port ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The keyword ‘data_source’ must immediately be followed by a unique
 string which identifies the source, then an optional &lt;code&gt;polling interval&lt;/code&gt; in
 seconds. The source will be polled at this interval on average.
 If the polling interval is omitted, &lt;code&gt;15sec&lt;/code&gt; is asssumed.&lt;/p&gt;

&lt;p&gt;If you choose to set the polling interval to something other than the default,
 note that the web frontend determines a host as down if its TN value is less
 than 4 * TMAX (20sec by default).  Therefore, if you set the polling interval
 to something around or greater than 80sec, this will cause the frontend to
 incorrectly display hosts as down even though they are not.&lt;/p&gt;

&lt;p&gt;A list of machines which service the data source follows, in the
 format ip:port, or name:port. If a port is not specified then 8649
 (the default gmond port) is assumed.
 default: There is no default value&lt;/p&gt;

&lt;p&gt;data_source “my cluster” 10 localhost  my.machine.edu:8649  1.2.3.5:8655
 data_source “my grid” 50 1.3.4.7:8655 grid.org:8651 grid-backup.org:8651
 data_source “another source” 1.3.4.7:8655  1.3.4.8&lt;/p&gt;

&lt;p&gt;data_source “RT-SYS” localhost&lt;/p&gt;

&lt;p&gt;Round-Robin Archives
 You can specify custom Round-Robin archives here (defaults are listed below)&lt;/p&gt;

&lt;p&gt;Old Default RRA: Keep 1 hour of metrics at 15 second resolution. 1 day at 6 minute
 RRAs “RRA:AVERAGE:0.5:1:244” “RRA:AVERAGE:0.5:24:244” “RRA:AVERAGE:0.5:168:244” “RRA:AVERAGE:0.5:672:244” \
      “RRA:AVERAGE:0.5:5760:374”
 New Default RRA
 Keep 5856 data points at 15 second resolution assuming 15 second (default) polling. That’s 1 day
 Two weeks of data points at 1 minute resolution (average)
RRAs “RRA:AVERAGE:0.5:1:5856” “RRA:AVERAGE:0.5:4:20160” “RRA:AVERAGE:0.5:40:52704”&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;Scalability mode. If on, we summarize over downstream grids, and respect
 authority tags. If off, we take on 2.5.0-era behavior: we do not wrap our output
 in &lt;grid&gt;&lt;/grid&gt; tags, we ignore all &lt;grid&gt; tags we see, and always assume
 we are the &quot;authority&quot; on data source feeds. This approach does not scale to
 large groups of clusters, but is provided for backwards compatibility.
 default: on
 scalable off&lt;/grid&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;The name of this Grid. All the data sources above will be wrapped in a GRID
 tag with this name.
 default: unspecified
 gridname “MyGrid”&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;The authority URL for this grid. Used by other gmetads to locate graphs
 for our data sources. Generally points to a ganglia/
 website on this machine.
 default: “http://hostname/ganglia/”,
   where hostname is the name of this machine, as defined by gethostname().
 authority “http://mycluster.org/newprefix/”&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;List of machines this gmetad will share XML with. Localhost
 is always trusted.
 default: There is no default value
 trusted_hosts 127.0.0.1 169.229.50.165 my.gmetad.org&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;If you want any host which connects to the gmetad XML to receive
 data, then set this value to “on”
 default: off
 all_trusted on&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;If you don’t want gmetad to setuid then set this to off
 default: on
 setuid off&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;User gmetad will setuid to (defaults to “nobody”)
 default: “nobody”
etuid_username “ganglia”&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;Umask to apply to created rrd files and grid directory structure
 default: 0 (files are public)
 umask 022&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;The port gmetad will answer requests for XML
 default: 8651
 xml_port 8651&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;The port gmetad will answer queries for XML. This facility allows
 simple subtree and summation views of the XML tree.
 default: 8652
 interactive_port 8652&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;The number of threads answering XML requests
 default: 4
 server_threads 10&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;Where gmetad stores its round-robin databases
 default: “/var/lib/ganglia/rrds”
 rrd_rootdir “/some/other/place”&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;List of metric prefixes this gmetad will not summarize at cluster or grid level.
 default: There is no default value
 unsummarized_metrics diskstat CPU&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;In earlier versions of gmetad, hostnames were handled in a case
 sensitive manner
 If your hostname directories have been renamed to lower case,
 set this option to 0 to disable backward compatibility.
 From version 3.2, backwards compatibility will be disabled by default.
 default: 1   (for gmetad &amp;lt; 3.2)
 default: 0   (for gmetad &amp;gt;= 3.2)
ase_sensitive_hostnames 0&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;It is now possible to export all the metrics collected by gmetad directly to
 graphite by setting the following attributes.&lt;/p&gt;

&lt;p&gt;The hostname or IP address of the Graphite server
 default: unspecified
 carbon_server “my.graphite.box”&lt;/p&gt;

&lt;p&gt;The port and protocol on which Graphite is listening
 default: 2003
 carbon_port 2003&lt;/p&gt;

&lt;p&gt;default: tcp
 carbon_protocol udp&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Deprecated in favor of graphite_path&lt;/strong&gt; A prefix to prepend to the
 metric names exported by gmetad. Graphite uses dot-
 separated paths to organize and refer to metrics.
 default: unspecified
 graphite_prefix “datacenter1.gmetad”&lt;/p&gt;

&lt;p&gt;A user-definable graphite path. Graphite uses dot-
 separated paths to organize and refer to metrics.
 For reverse compatibility graphite_prefix will be prepended to this
 path, but this behavior should be considered deprecated.
 This path may include 3 variables that will be replaced accordingly:
 %s -&amp;gt; source (cluster name)
 %h -&amp;gt; host (host name)
 %m -&amp;gt; metric (metric name)
 default: graphite_prefix.%s.%h.%m
 graphite_path “datacenter1.gmetad.%s.%h.%m&lt;/p&gt;

&lt;p&gt;Number of milliseconds gmetad will wait for a response from the graphite server
 default: 500
 carbon_timeout 500&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;Memcached configuration (if it has been compiled in)
 Format documentation at http://docs.libmemcached.org/libmemcached_configuration.html
 default: “”
 memcached_parameters “–SERVER=127.0.0.1”&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;参考来源&lt;/h2&gt;

</content>
   </entry>
   
 
</feed>
